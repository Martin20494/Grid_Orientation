{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95d8ddf8",
   "metadata": {},
   "source": [
    "# 0. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa61245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For adjusting points to get correct flowdepth\n",
    "# Packages for transformation\n",
    "from numba import njit, guvectorize, float64                         # For speeding up the time of the code running\n",
    "\n",
    "# Packages for unrotating and untranslating\n",
    "from osgeo import gdal                                               # For manipulating rasters (calculating centers)\n",
    "\n",
    "# For handling raster\n",
    "import numpy as np                                                   # For all calculation and data array/matrices manipulation\n",
    "import rioxarray                                                     # For opening and reading raster files and manipulating pixel values and spatial attributes\n",
    "import xarray                                                        # For writing arrays into raster files\n",
    "import rasterio                                                      # For opening and reading raster files and manipulating transformation and crs\n",
    "\n",
    "# For handling polygons\n",
    "import fiona                                                         # For reading shape file under GeoJSON format\n",
    "from shapely.geometry import shape                                   # For converting geometry data into shapely geometry format\n",
    "from rtree import index                                              # For using spatial index function\n",
    "import geopandas as gpd                                              # For manipulating geospatial data under polygon format\n",
    "import pandas as pd                                                  # For manipulating dataframe\n",
    "from shapely.geometry import Point                                   # For converting point coordinates into shapely geometry point\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt                                      # For plotting contour and scatter\n",
    "import matplotlib.cm as cm                                           # For changing color\n",
    "import contextily as ctx                                             # For adding basemap\n",
    "\n",
    "# For other things\n",
    "import os                                                            # For creating new folders\n",
    "import pathlib                                                       # For getting path\n",
    "import time                                                          # For timing steps\n",
    "\n",
    "# For coloring\n",
    "import matplotlib.colors as mcolors                                  # For coloring\n",
    "from matplotlib_scalebar.scalebar import ScaleBar                    # For scale bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc88d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all warnings\n",
    "# Reference: https://numba.pydata.org/numba-doc/dev/reference/deprecation.html#suppressing-deprecation-warnings\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning, NumbaWarning\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb6b349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the name you have just created for the drive\n",
    "drive = \"S\"\n",
    "main_folder = \"MULTIPLE_TILES_Monte_Carlo_LISFLOOD\"\n",
    "version = \"version_12\"\n",
    "header = f\"{drive}:\\\\{main_folder}\\\\{version}\"\n",
    "\n",
    "# Create header path\n",
    "pathlib.Path(f\"{header}\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b33163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create paths\n",
    "\n",
    "#--------------------------------------------------- This is for TRANSFORMATION PART -------------------------------------------\n",
    "\n",
    "\n",
    "# 0_open_topography: Folder stores ownloaded lidar point cloud data from open topography website\n",
    "# Reference: https://portal.opentopography.org/datasets\n",
    "original_lidar_path = f\"{header}\\\\0_open_topography\"\n",
    "\n",
    "# 1_modified_lidar: Folder stores ownloaded lidar point cloud data from open topography website\n",
    "modified_lidar_path = f\"{header}\\\\1_modified_lidar\"\n",
    "\n",
    "# 2_transformation: Folder stores transformed lidar point cloud data\n",
    "rotated_lidar_path = f\"{header}\\\\2_transformation\\\\rotated_lidar\"\n",
    "translated_lidar_path = f\"{header}\\\\2_transformation\\\\translated_lidar\"\n",
    "combined_lidar_path = f\"{header}\\\\2_transformation\\\\combined_lidar\"\n",
    "\n",
    "# 3_dem_raster: Folder stores DEM rasters\n",
    "# Rotation\n",
    "# Netcdf\n",
    "rotated_nc_raster_path = f\"{header}\\\\3_dem_raster\\\\rotated_dem_raster\\\\rot_dem_raster\\\\rot_netcdf\"\n",
    "# GeoTiff\n",
    "rotated_tiff_raster_path = f\"{header}\\\\3_dem_raster\\\\rotated_dem_raster\\\\rot_dem_raster\\\\rot_tiff\"\n",
    "# Ascii\n",
    "rotated_asc_raster_path = f\"{header}\\\\3_dem_raster\\\\rotated_dem_raster\\\\rot_dem_raster\\\\rot_ascii\"\n",
    "rotated_elements_path = f\"{header}\\\\3_dem_raster\\\\rotated_dem_raster\\\\rot_elements\"\n",
    "\n",
    "# Translation\n",
    "# Netcdf\n",
    "translated_nc_raster_path = f\"{header}\\\\3_dem_raster\\\\translated_dem_raster\\\\tra_dem_raster\\\\tra_netcdf\"\n",
    "# GeoTiff\n",
    "translated_tiff_raster_path = f\"{header}\\\\3_dem_raster\\\\translated_dem_raster\\\\tra_dem_raster\\\\tra_tiff\"\n",
    "# Ascii\n",
    "translated_asc_raster_path = f\"{header}\\\\3_dem_raster\\\\translated_dem_raster\\\\tra_dem_raster\\\\tra_ascii\"\n",
    "translated_elements_path = f\"{header}\\\\3_dem_raster\\\\translated_dem_raster\\\\tra_elements\"\n",
    "\n",
    "# Combination\n",
    "# Netcdf\n",
    "combined_nc_raster_path = f\"{header}\\\\3_dem_raster\\\\combined_dem_raster\\\\com_dem_raster\\\\com_netcdf\"\n",
    "# GeoTiff\n",
    "combined_tiff_raster_path = f\"{header}\\\\3_dem_raster\\\\combined_dem_raster\\\\com_dem_raster\\\\com_tiff\"\n",
    "# Ascii\n",
    "combined_asc_raster_path = f\"{header}\\\\3_dem_raster\\\\combined_dem_raster\\\\com_dem_raster\\\\com_ascii\"\n",
    "combined_elements_path = f\"{header}\\\\3_dem_raster\\\\combined_dem_raster\\\\com_elements\"\n",
    "\n",
    "# 4_LISFLOOD: Folder stores LISFLOOD-FP output\n",
    "# LISFLOOD_FP output\n",
    "rotated_FPoutput_path = f\"{header}\\\\4_LISFLOOD_FP\\\\rotated_output\"\n",
    "translated_FPoutput_path = f\"{header}\\\\4_LISFLOOD_FP\\\\translated_output\"\n",
    "combined_FPoutput_path = f\"{header}\\\\4_LISFLOOD_FP\\\\combined_output\"\n",
    "\n",
    "# 5_flowdepth: Folder stores flowdepth extracted from LISFLOOD-FP output\n",
    "rotated_flowdepth = f\"{header}\\\\5_flowdepth\\\\rotated_flowdepth\"\n",
    "translated_flowdepth = f\"{header}\\\\5_flowdepth\\\\translated_flowdepth\"\n",
    "combined_flowdepth = f\"{header}\\\\5_flowdepth\\\\combined_flowdepth\"\n",
    "\n",
    "# 6_un_transformation: Folder stores un-transformed raster\n",
    "unrotated_path = f\"{header}\\\\6_un_transformation\\\\un_rotation\"\n",
    "untranslated_path = f\"{header}\\\\6_un_transformation\\\\un_translation\"\n",
    "uncombined_path = f\"{header}\\\\6_un_transformation\\\\un_combination\"\n",
    "\n",
    "#--------------------------------------------------- This is for ANALYSIS PART ------------------------------------------------\n",
    "\n",
    "# 7_results: Folder stores mean and standard deviation\n",
    "# Un_rotation\n",
    "csv_rotation = f\"{header}\\\\7_results\\\\un_rotation\\\\unrot_csv\"\n",
    "raster_rotation = f\"{header}\\\\7_results\\\\un_rotation\\\\unrot_raster\"\n",
    "polygon_rotation = f\"{header}\\\\7_results\\\\un_rotation\\\\unrot_polygon\"\n",
    "plot_rotation = f\"{header}\\\\7_results\\\\un_rotation\\\\unrot_plot\"\n",
    "\n",
    "# Un_translation\n",
    "csv_translation = f\"{header}\\\\7_results\\\\un_translation\\\\untra_csv\"\n",
    "raster_translation = f\"{header}\\\\7_results\\\\un_translation\\\\untra_raster\"\n",
    "polygon_translation = f\"{header}\\\\7_results\\\\un_translation\\\\untra_polygon\"\n",
    "plot_translation = f\"{header}\\\\7_results\\\\un_translation\\\\untra_plot\"\n",
    "\n",
    "# Un_combination\n",
    "csv_combination = f\"{header}\\\\7_results\\\\un_combination\\\\uncom_csv\"\n",
    "raster_combination = f\"{header}\\\\7_results\\\\un_combination\\\\uncom_raster\"\n",
    "polygon_combination = f\"{header}\\\\7_results\\\\un_combination\\\\uncom_polygon\"\n",
    "plot_combination = f\"{header}\\\\7_results\\\\un_combination\\\\uncom_plot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93878786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all paths\n",
    "neccessary_files = [\n",
    "    # 0_open_topography\n",
    "    original_lidar_path,\n",
    "    \n",
    "    # 1_modified_lidar\n",
    "    modified_lidar_path,\n",
    "    \n",
    "    # 2_transformation\n",
    "    rotated_lidar_path,\n",
    "    translated_lidar_path,\n",
    "    combined_lidar_path,\n",
    "    \n",
    "    # 3_dem_raster\n",
    "    # Rotation\n",
    "    rotated_nc_raster_path,\n",
    "    rotated_tiff_raster_path,\n",
    "    rotated_asc_raster_path,\n",
    "    rotated_elements_path,\n",
    "    \n",
    "    # Translation\n",
    "    translated_nc_raster_path,\n",
    "    translated_tiff_raster_path,\n",
    "    translated_asc_raster_path,\n",
    "    translated_elements_path,\n",
    "    \n",
    "    # Combination\n",
    "    combined_nc_raster_path,\n",
    "    combined_tiff_raster_path,\n",
    "    combined_asc_raster_path,\n",
    "    combined_elements_path,\n",
    "    \n",
    "    # 4_LISFLOOD-FP\n",
    "    rotated_FPoutput_path,\n",
    "    translated_FPoutput_path,\n",
    "    combined_FPoutput_path,\n",
    "    \n",
    "    # 5_flowdepth\n",
    "    rotated_flowdepth,\n",
    "    translated_flowdepth,\n",
    "    combined_flowdepth,\n",
    "    \n",
    "    # 6_un_transformation\n",
    "    unrotated_path,\n",
    "    untranslated_path,\n",
    "    uncombined_path,\n",
    "    \n",
    "    # 7_results\n",
    "    # Unrotation\n",
    "    csv_rotation,\n",
    "    raster_rotation,\n",
    "    polygon_rotation,\n",
    "    plot_rotation,\n",
    "    \n",
    "    # Untranslation\n",
    "    csv_translation,\n",
    "    raster_translation,\n",
    "    polygon_translation,\n",
    "    plot_translation,\n",
    "    \n",
    "    # Uncombination\n",
    "    csv_combination,\n",
    "    raster_combination,\n",
    "    polygon_combination,\n",
    "    plot_combination\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90050f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder\n",
    "# Reference: https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python\n",
    "for each_folder in neccessary_files:\n",
    "    pathlib.Path(f\"{each_folder}\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16172045",
   "metadata": {},
   "source": [
    "# 1. Getting clipped dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe130e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to get the full number of x, y values in raster array\n",
    "def array_creation(data_array, value, shape_x, shape_y):\n",
    "    '''This function is to create an array of a coordinate\n",
    "    Argument:\n",
    "                data_array:\n",
    "                            Original array to extract values\n",
    "                value:\n",
    "                            The value of original array need extracting\n",
    "                shape_x and shape_y:\n",
    "                            Shape of the new array\n",
    "    Return:\n",
    "                new_array:\n",
    "                            New array of the coordinate\n",
    "    '''\n",
    "    # Create zero array\n",
    "    new_array = np.zeros((shape_x, shape_y))\n",
    "    \n",
    "    # Read x, y values into arrays\n",
    "    arr_x = data_array.x.values\n",
    "    arr_y = data_array.y.values\n",
    "    \n",
    "    # Get full number of x or y values\n",
    "    for i in range(new_array.shape[0]):\n",
    "        for j in range(new_array.shape[0]):\n",
    "            if value == 'x':\n",
    "                new_array[j,i] = arr_x[i]\n",
    "            else:\n",
    "                new_array[i,j] = arr_y[i]\n",
    "                \n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to get x, y, z of a rotated degree raster file\n",
    "def xyz_array(transformation_selection, number, time):\n",
    "    '''This function is to create an array from flowdepth raster including x, y, z values\n",
    "    Reference: https://corteva.github.io/rioxarray/stable/examples/resampling.html\n",
    "    Argument:\n",
    "                transformation_selection:\n",
    "                            \"r\" means rotation\n",
    "                            \"t\" means translation\n",
    "                            \"c\" means combination\n",
    "                number:\n",
    "                        Ordinal number of simulation\n",
    "                time:\n",
    "                        Amount of time that BG_flood model predicted\n",
    "    Return:\n",
    "                full_dataset:\n",
    "                        A dataset contains 1D x, y, z array including padding\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        transformed = \"rotated\"\n",
    "        untransformed_path = unrotated_path\n",
    "        flowdepth_path = rotated_flowdepth\n",
    "    elif transformation_selection == 't':\n",
    "        transformed = \"translated\"\n",
    "        untransformed_path = untranslated_path\n",
    "        flowdepth_path = translated_flowdepth\n",
    "    else:\n",
    "        transformed = \"combined\"\n",
    "        untransformed_path = uncombined_path\n",
    "        flowdepth_path = combined_flowdepth\n",
    "    \n",
    "    # Read the raster\n",
    "    path = fr\"{flowdepth_path}\\\\flowdepth_{transformed}_{number}_at_{time}.nc\"\n",
    "    dataset_rioxarray = rioxarray.open_rasterio(path)\n",
    "    \n",
    "    # Create full number of values of x, y, z coordinates\n",
    "    array_x = array_creation(dataset_rioxarray, 'x', dataset_rioxarray.shape[1], dataset_rioxarray.shape[2])\n",
    "    array_y = array_creation(dataset_rioxarray, 'y', dataset_rioxarray.shape[1], dataset_rioxarray.shape[2])\n",
    "    array_z = dataset_rioxarray.isel(band=0).values\n",
    "    \n",
    "    # Flatten x, y, z arrays\n",
    "    flatten_x = array_x.flatten()\n",
    "    print(flatten_x)\n",
    "    flatten_y = array_y.flatten()\n",
    "    print(flatten_y)\n",
    "    flatten_z = array_z.flatten()\n",
    "    print(flatten_z)\n",
    "    \n",
    "    # Put all x, y, z into one array\n",
    "    full_dataset = np.vstack((flatten_x, flatten_y, flatten_z)).transpose()\n",
    "    \n",
    "    return full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616d78dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_calculation(transformation_selection, lidar=True):\n",
    "    '''This function is to calculate the center of reference DEM raster which will be used in the whole process\n",
    "    Reference: https://gis.stackexchange.com/questions/104362/how-to-get-extent-out-of-geotiff\n",
    "               https://rasterio.readthedocs.io/en/latest/quickstart.html\n",
    "    Arguments:\n",
    "                transformation_selection:\n",
    "                                        \"r\" means rotation\n",
    "                                        \"t\" means translation\n",
    "                                        \"c\" means combination\n",
    "                lidar:\n",
    "                                        True means doing rotation on LiDAR data\n",
    "                                        False means doing unrotation on model outputs\n",
    "    Return:\n",
    "                A tuple of x, y coordinates of center raster\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        transformed_nc_raster_path = rotated_nc_raster_path\n",
    "    elif transformation_selection == 't':\n",
    "        transformed_nc_raster_path = translated_nc_raster_path\n",
    "    else:\n",
    "        transformed_nc_raster_path = combined_nc_raster_path\n",
    "            \n",
    "    raster_reference_func = gdal.Open(fr\"{transformed_nc_raster_path}\\\\generated_dem_reference.nc\")\n",
    "    if lidar:\n",
    "        xmin, xpixel, _, ymax, _, ypixel = raster_reference_func.GetGeoTransform()\n",
    "        width, height = raster_reference_func.RasterXSize, raster_reference_func.RasterYSize\n",
    "        xmax = xmin + width * xpixel\n",
    "        ymin = ymax + height * ypixel\n",
    "        center_x_func = ((xmin + xmax)/2)\n",
    "        center_y_func = ((ymin + ymax)/2)\n",
    "        center_func = np.array([center_x_func, center_y_func])\n",
    "    else:\n",
    "        center_func = ((raster_reference_func.RasterXSize)/2, (raster_reference_func.RasterYSize)/2)\n",
    "    return center_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194a5062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a command for guvectorize() decorator\n",
    "# In that, float64[:,:] stands for the format of the array and float64 stands for the format of other parameters\n",
    "# (m,n) signature stands for the matrix of the array and () signature stands for other parameters\n",
    "gu_rotation = guvectorize([(float64[:,:], float64, float64, float64, float64, float64[:,:])], '(m,n),(),(),(),()->(m,n)')\n",
    "\n",
    "# Create a point rotation function\n",
    "def point_rotation(coordinates_func, angle, center_x_func, center_y_func, clockwise, new_coordinates_func):\n",
    "    '''This function is to calculate the rotated coordinates of lidar data\n",
    "    Reference: https://www.youtube.com/watch?v=RqZH-7hlI48\n",
    "               https://stackoverflow.com/questions/14607640/rotating-a-vector-in-3d-space\n",
    "               https://stackoverflow.com/questions/5954603/transposing-a-1d-numpy-array\n",
    "               https://en.wikipedia.org/wiki/Rotation_matrix\n",
    "               https://math.stackexchange.com/questions/270194/how-to-find-the-vertices-angle-after-rotation\n",
    "               \n",
    "               https://github.com/numba/numba/issues/3312\n",
    "               https://numba.pydata.org/numba-doc/latest/user/vectorize.html\n",
    "               https://numba.pydata.org/numba-doc/latest/cuda/ufunc.html\n",
    "               http://numba.pydata.org/numba-doc/0.20.0/reference/compilation.html\n",
    "               http://numba.pydata.org/numba-doc/0.12/tutorial_numpy_and_numba.html\n",
    "               https://numba.pydata.org/numba-doc/dev/reference/types.html\n",
    "    Arguments:\n",
    "               coordinates_func:\n",
    "                                An array of the coordinates of the point will be rotated\n",
    "               angle: \n",
    "                                The value of angle to rotate\n",
    "               center_x_func and center_y_func:\n",
    "                                Values of the coordinates of center of the point cloud\n",
    "               clockwise:\n",
    "                                Rotating the points in clockwise (1) or anti_clockwise (0) directions\n",
    "               new_coordinates_func:\n",
    "                                A new array of rotated x, y, z coordinates values of a point\n",
    "    '''\n",
    "    # Convert degree to radian and calculate cosine and sine    \n",
    "    if angle == 90:\n",
    "        cosine = 0\n",
    "        sine = 1\n",
    "    else:\n",
    "        radian = np.deg2rad(angle)\n",
    "        cosine = np.cos(radian)\n",
    "        sine = np.sin(radian)\n",
    "        \n",
    "    # Tolerance for floating error\n",
    "    tolerance = 9\n",
    "    num_to_round = 10**tolerance\n",
    "    \n",
    "    # Create a for loop to manipulate each row of the array\n",
    "    for i in range(coordinates_func.shape[0]): \n",
    "        # Do substraction with center coordinates\n",
    "        origin_diff_x = coordinates_func[i, 0] - center_x_func\n",
    "        origin_diff_y = coordinates_func[i, 1] - center_y_func\n",
    "        \n",
    "        # Round it up\n",
    "        diff_x = (int(origin_diff_x>0) - int(origin_diff_x<0)) * (int(abs(origin_diff_x)*num_to_round + 0.5)/num_to_round)\n",
    "        diff_y = (int(origin_diff_y>0) - int(origin_diff_y<0)) * (int(abs(origin_diff_y)*num_to_round + 0.5)/num_to_round)\n",
    "\n",
    "        # Calculate the rotated point coordinates\n",
    "        if clockwise == 0:                                                                  # Rotating in anti-clockwise direction\n",
    "            new_coordinates_func[i, 0] = diff_x*cosine - diff_y*sine + center_x_func\n",
    "            new_coordinates_func[i, 1] = diff_x*sine + diff_y*cosine + center_y_func\n",
    "            new_coordinates_func[i, 2] = coordinates_func[i, 2]\n",
    "        else:                                                                               # Rotating in clockwise direction\n",
    "            new_coordinates_func[i, 0] = diff_x*cosine + diff_y*sine + center_x_func\n",
    "            new_coordinates_func[i, 1] = diff_x*(-sine) + diff_y*cosine + center_y_func\n",
    "            new_coordinates_func[i, 2] = coordinates_func[i, 2]\n",
    "\n",
    "# Wrapping function to map later\n",
    "wrapping_point_rotation = gu_rotation(point_rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19cf976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to clip rasters (remove padding box)\n",
    "def clip(transformation_selection, dataset):\n",
    "    '''This function is to clip rasters (remove padding box)\n",
    "    Arguments:\n",
    "                transformation_selection:\n",
    "                            \"r\" means rotation\n",
    "                            \"t\" means translation\n",
    "                            \"c\" means combination\n",
    "                dataset:\n",
    "                            An array with x, y, z values\n",
    "    Return:\n",
    "                adjusted_dataset_clip:\n",
    "                            A dataset without padding and was ajusted 0.000001 to get flowdepth values later\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        transformed = \"rotated\"\n",
    "        nc_raster_path_func = rotated_nc_raster_path\n",
    "        untransformed_path = unrotated_path\n",
    "    elif transformation_selection == 't':\n",
    "        transformed = \"translated\"\n",
    "        nc_raster_path_func = translated_nc_raster_path\n",
    "        untransformed_path = untranslated_path\n",
    "    else:\n",
    "        transformed = \"combined\"\n",
    "        nc_raster_path_func = combined_nc_raster_path\n",
    "        untransformed_path = uncombined_path\n",
    "    \n",
    "    # Get boundary coordinates\n",
    "    raster_origin = rasterio.open(fr\"{nc_raster_path_func}\\\\generated_dem_no_padding.nc\")\n",
    "    x_min, y_min, x_max, y_max = raster_origin.bounds\n",
    "    \n",
    "    # Calculate coordinates of center point\n",
    "    center_point = center_calculation('c', True)\n",
    "    center_x = center_point[0]                     # Extract x coordinate of center point\n",
    "    center_y = center_point[1]                     # Extract y coordinate of center point\n",
    "    \n",
    "    # Remove padding by filtering\n",
    "    dataset_clip = dataset[(x_min <= dataset[:,0])\n",
    "                           & (x_max >= dataset[:,0])\n",
    "                           & (y_min <= dataset[:,1])\n",
    "                           & (y_max >= dataset[:,1])]\n",
    "    \n",
    "    \n",
    "    # Adjust x and y to get flowdepth values later (to avoid the case one point with two flowdepth values)\n",
    "    # Rotate -0.000001 degree\n",
    "    adjusted_dataset_clip1 = wrapping_point_rotation(dataset_clip, -0.000001, center_x, center_y, 0)\n",
    "    # Translate -0.000001 meter\n",
    "    adjusted_dataset_clip2 = adjusted_dataset_clip1.copy()\n",
    "    adjusted_dataset_clip2[:,0] = adjusted_dataset_clip1[:,0] - 0.000001\n",
    "    adjusted_dataset_clip2[:,1] = adjusted_dataset_clip1[:,1] - 0.000001\n",
    "    adjusted_dataset_clip2[:,2] = adjusted_dataset_clip1[:,2]\n",
    "    \n",
    "    return adjusted_dataset_clip2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c5ea30",
   "metadata": {},
   "source": [
    "# 2. Convert raster file into polygon shape file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7833673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to convert raster array into shape file\n",
    "def raster_array_to_shapefile(transformation_selection, number, time):\n",
    "    '''This function is to convert a raster array into a shape file\n",
    "    Reference: https://geopandas.org/docs/reference/api/geopandas.GeoDataFrame.to_crs.html\n",
    "               https://shapely.readthedocs.io/en/stable/manual.html\n",
    "               https://geopandas.org/docs/user_guide/io.html\n",
    "               https://sgillies.net/2014/01/18/getting-shapes-of-raster-features-with-rasterio.html\n",
    "               \n",
    "    Arguments: \n",
    "               transformation_selection:\n",
    "                        \"r\" means rotation\n",
    "                        \"t\" means translation\n",
    "                        \"c\" means combination\n",
    "               number:\n",
    "                        Ordinal number of simulation\n",
    "               time:\n",
    "                        Amount of time that BG_flood model predicted\n",
    "    Return:\n",
    "               clipped_raster_func:\n",
    "                        A dataset without padding\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        transformed = \"rotated\"\n",
    "        untransformed_path = unrotated_path\n",
    "        flowdepth_path = rotated_flowdepth\n",
    "    elif transformation_selection == 't':\n",
    "        transformed = \"translated\"\n",
    "        untransformed_path = untranslated_path\n",
    "        flowdepth_path = translated_flowdepth\n",
    "    else:\n",
    "        transformed = \"combined\"\n",
    "        untransformed_path = uncombined_path\n",
    "        flowdepth_path = combined_flowdepth\n",
    "    \n",
    "    # Call out and clip the raster array\n",
    "    raster_func = xyz_array(transformation_selection, number, time)\n",
    "    clipped_raster_func = clip(transformation_selection, raster_func)\n",
    "    \n",
    "    # Convert x, y coordinates array into shapely geometry\n",
    "    point_geo_values_func = [Point(clipped_raster_func[i, 0], clipped_raster_func[i, 1]) for i in range(clipped_raster_func.shape[0])]\n",
    "    \n",
    "    # Build up geopandas dataframe\n",
    "    point_data_func = {\"depth\": clipped_raster_func[:, 2]}\n",
    "    point_gdf = gpd.GeoDataFrame(data = point_data_func,\n",
    "                                 geometry = point_geo_values_func,\n",
    "                                 crs = 2193)\n",
    "    \n",
    "    shapefile_dir = pathlib.Path(os.getcwd()) / pathlib.Path(f\"{untransformed_path}\\\\shapefile_Point\")\n",
    "    if not os.path.exists(shapefile_dir):\n",
    "        os.mkdir(shapefile_dir)\n",
    "    \n",
    "    # Write geopandas dataframe into shape file\n",
    "    point_gdf.to_file(f\"{untransformed_path}\\\\shapefile_Point\\\\Point_clip.shp\",\n",
    "                      driver = \"ESRI Shapefile\")\n",
    "    \n",
    "    return clipped_raster_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedcd900",
   "metadata": {},
   "source": [
    "# 3. Getting depth values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d315dbbc",
   "metadata": {},
   "source": [
    "### 3.1. Full dataset of water depth values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d53fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to extract the flowdepth at given coordinates from any shape file\n",
    "def get_flowdepth_value(transformation_selection, angle, time):\n",
    "    '''This function is to extract the flowdepth at given coordinates from any shape file\n",
    "    Reference: https://gis.stackexchange.com/questions/102933/more-efficient-spatial-join-in-python-without-qgis-arcgis-postgis-etc/103066#103066\n",
    "               https://gis.stackexchange.com/questions/121469/get-shapefile-polygon-attribute-value-at-a-specific-point-using-python-e-g-via\n",
    "               https://stackoverflow.com/questions/59030022/checking-whether-point-is-within-polygon-returns-wrong-results-in-shapely\n",
    "               https://gis.stackexchange.com/questions/119919/maximizing-code-performance-for-shapely\n",
    "               https://gis.stackexchange.com/questions/42931/rtree-python-polygon-index\n",
    "               https://gis.stackexchange.com/questions/227474/rtree-spatial-index-does-not-result-in-faster-intersection-computation\n",
    "               \n",
    "               https://rtree.readthedocs.io/en/latest/tutorial.html\n",
    "               \n",
    "               https://sgillies.net/2014/01/18/getting-shapes-of-raster-features-with-rasterio.html\n",
    "               https://stackoverflow.com/questions/20474549/extract-points-coordinates-from-a-polygon-in-shapely\n",
    "               \n",
    "    Arguments: \n",
    "               transformation_selection:\n",
    "                        \"r\" means rotation\n",
    "                        \"t\" means translation\n",
    "                        \"c\" means combination\n",
    "               angle:\n",
    "                        Angle to unrotate\n",
    "               time:\n",
    "                        Amount of time that BG_flood model predicted \n",
    "    \n",
    "    Return:\n",
    "              flowdepth:\n",
    "                        A list of flowdepth values\n",
    "    '''\n",
    "    \n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        transformed = \"rotated\"\n",
    "        untransformed_path = unrotated_path\n",
    "        flowdepth_path = rotated_flowdepth\n",
    "    elif transformation_selection == 't':\n",
    "        transformed = \"translated\"\n",
    "        untransformed_path = untranslated_path\n",
    "        flowdepth_path = translated_flowdepth\n",
    "    else:\n",
    "        transformed = \"combined\"\n",
    "        untransformed_path = uncombined_path\n",
    "        flowdepth_path = combined_flowdepth\n",
    "        \n",
    "    # A list stores flowdepth values\n",
    "    flowdepth_list = []\n",
    "    \n",
    "    # Input polygons and points files\n",
    "    polygons_input = fiona.open(fr\"{untransformed_path}\\shapefile_{angle}\\flowdepth_un{transformed}_{angle}_at_{time}.geojson\")\n",
    "    points_input = fiona.open(f\"{untransformed_path}\\\\shapefile_Point\\\\Point_clip.shp\")\n",
    "    \n",
    "    # Read polygons and points files into geometry lists\n",
    "    values_polygons_input = [values_poly for values_poly in polygons_input]\n",
    "    values_points_input = [values_point for values_point in points_input]\n",
    "    \n",
    "    # Construct r-tree spatial index\n",
    "    indexes = index.Index()\n",
    "    \n",
    "    # Insert boundary records obtained from polygons geometry using shapely shape() function \n",
    "    # In other words, create boundaries based on the coordinates gained from polygon geometry under shapely format (left, bottom, right, top)\n",
    "    for id_poly, polygons in enumerate(values_polygons_input):\n",
    "        indexes.insert(id_poly, shape(polygons['geometry']).bounds)\n",
    "        \n",
    "    # Iterate through each point and polygon \n",
    "    # to find out the spatial index of polygon that contains the point.\n",
    "    # In other words, checking if each point fits in the given boundaries (boundaries here are just a gather of rectangle boundaries created above)\n",
    "    # After that, check if the polygon with that spatial index contains the point.\n",
    "    # The flowdepth is extracted from that polygon (assumed that all coordinates within that polygon have the same flowdepth)\n",
    "    \n",
    "    # Loop 1: Convert point under GeoJSON into shapely geometry\n",
    "    for id_point, points in enumerate(values_points_input):\n",
    "        each_point = shape(points['geometry'])\n",
    "        \n",
    "        # Loop 2: Check if the point is in any boundaries and polygons\n",
    "        for id_intersection in indexes.intersection(each_point.coords[0]): # This line will return the list of spatial indexes that have intersection between the point and any boundaries\n",
    "            # Check if the point is in the polygon identified by the spatial index.\n",
    "            # within() is used to find out the polygon the point lies in\n",
    "            if each_point.within(shape(values_polygons_input[id_intersection]['geometry'])):\n",
    "                flowdepth_value = values_polygons_input[id_intersection][\"properties\"]['depth']\n",
    "                flowdepth_list.append(flowdepth_value)\n",
    "                \n",
    "    return flowdepth_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20714f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polygons_input1 = fiona.open(r\"S:\\MULTIPLE_TILES_Monte_Carlo_LISFLOOD\\version_2\\6_un_transformation\\un_combination\\shapefile_angle_0_x_0_y_0\\flowdepth_uncombined_angle_0_x_0_y_0_at_12.shp\")\n",
    "# point_input1 = fiona.open(fr\"{uncombined_path}\\\\shapefile_Point\\\\Point_clip.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d720b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polygons_geojson = fiona.open(r\"S:\\MULTIPLE_TILES_Monte_Carlo_LISFLOOD\\version_7\\6_un_transformation\\un_combination\\shapefile_angle_0_x_0_y_0\\flowdepth_uncombined_angle_0_x_0_y_0_at_24.geojson\")\n",
    "# polygons_geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ea7f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_poly_list = [value1 for value1 in polygons_geojson]\n",
    "# val_point_list = [value2 for value2 in point_input1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f44347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_poly_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0f376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes1 = index.Index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id_poly1, poly1 in enumerate(val_poly_list):\n",
    "#     print(id_poly1)\n",
    "#     print(shape(poly1['geometry']).bounds)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id_poly1, poly1 in enumerate(val_poly_list):\n",
    "#     indexes1.insert(id_poly1, shape(poly1['geometry']).bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape(val_poly_list[0]['geometry']).bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d6106",
   "metadata": {},
   "source": [
    "### 3.2. Selected dataset of water depth values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f535b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to filter neccessary information\n",
    "def filter_dataset(dataset_func, calculation_option, filter_rate):\n",
    "    '''This function is to manipulate and select neccessary information\n",
    "    References: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.std.html\n",
    "                https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html\n",
    "    Arguments:\n",
    "                dataset_func:\n",
    "                        A full dataset including uneccessary information\n",
    "                calculation_option:\n",
    "                        \"mean\" means to calculate mean\n",
    "                        \"sd\" means to calculate standard deviation\n",
    "                        \"cv\" means to calculate coefficient of variation\n",
    "                        \"cell\" means to calculate probability of each pixel being inundated\n",
    "    Return:\n",
    "                new_dataframe:\n",
    "                        A dataframe includes x, y coordinates and filtered water depth values\n",
    "    '''\n",
    "    # Remove geometry data (x, y coordinates)\n",
    "    nogeo_data_func = dataset_func.drop(['x_coord', 'y_coord'], axis=1)\n",
    "    \n",
    "    # Calculate mean data\n",
    "    mean_data_func = nogeo_data_func.copy()\n",
    "    mean_data_func['mean'] = mean_data_func.mean(axis=1)\n",
    "    \n",
    "    # Copy mean and filter data\n",
    "    copy_mean_data_func = mean_data_func.copy()\n",
    "    copy_mean_data_func.loc[copy_mean_data_func['mean'] < filter_rate, ['mean']] = -999           # Removing pixels having lower than 0.1 m water depth values\n",
    "    \n",
    "    # Manipulate and calculate neccessary information\n",
    "    if calculation_option == \"mean\":\n",
    "        filter_data_func = copy_mean_data_func['mean']\n",
    "        \n",
    "    elif calculation_option == \"sd\":\n",
    "        # Calculate standard deviation\n",
    "        sd_data_func = nogeo_data_func.copy()\n",
    "        sd_data_func['sd'] = sd_data_func.std(axis=1)\n",
    "        \n",
    "        # Copy standard deviation and filter data\n",
    "        copy_sd_data_func = sd_data_func.copy()\n",
    "        copy_sd_data_func.loc[copy_mean_data_func['mean'] == -999, ['sd']] = -999\n",
    "        filter_data_func = copy_sd_data_func['sd']\n",
    "        \n",
    "    elif calculation_option == \"cv\":\n",
    "        # Calculate coefficient of variation\n",
    "        cv_data_func = nogeo_data_func.copy()\n",
    "        cv_data_func['mean'] = cv_data_func.mean(axis=1)\n",
    "        cv_data_func['sd'] = cv_data_func.std(axis=1)\n",
    "        cv_data_func['cv'] = cv_data_func['sd'] / cv_data_func['mean'] * 100\n",
    "        \n",
    "        # Copy coefficient of variation and filter data\n",
    "        copy_cv_data_func = cv_data_func.copy()\n",
    "        copy_cv_data_func.loc[copy_mean_data_func['mean'] == -999, ['cv']] = -999\n",
    "        filter_data_func = copy_cv_data_func['cv']\n",
    "        \n",
    "    else:\n",
    "        # Calculate probability of each location getting inundated\n",
    "        cell_data_func = nogeo_data_func.copy()\n",
    "        cell_data_func['cell'] = (nogeo_data_func.shape[1] - (nogeo_data_func <= filter_rate).sum(axis=1)) / nogeo_data_func.shape[1] * 100\n",
    "        \n",
    "        # Filter data\n",
    "        cell_data_func.loc[copy_mean_data_func['mean'] == -999, ['cell']] = -999\n",
    "        filter_data_func = cell_data_func['cell']\n",
    "        \n",
    "    \n",
    "    # Create new dataframe with calculated information\n",
    "    new_database = {'x': dataset_func['x_coord'],\n",
    "                    'y': dataset_func['y_coord'],\n",
    "                    f\"{calculation_option}\": filter_data_func}\n",
    "    new_dataframe = pd.DataFrame(new_database)\n",
    "    \n",
    "    # Return new dataframe\n",
    "    return new_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff2fd68",
   "metadata": {},
   "source": [
    "# 4. Write into files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70871f5",
   "metadata": {},
   "source": [
    "### 4.1. CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7911ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_generation(transformation_selection, dataset_func):\n",
    "    '''This function is to convert pandas dataframe into csv file to save the memory\n",
    "    Arguments:\n",
    "                transformation_selection:\n",
    "                        \"r\" means rotation\n",
    "                        \"t\" means translation\n",
    "                        \"c\" means combination\n",
    "                dataset_func:\n",
    "                        A dataset for being written into csv file\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        transformed = \"rotated\"\n",
    "        csv_path = csv_rotation\n",
    "    elif transformation_selection == 't':\n",
    "        transformed = \"translated\"\n",
    "        csv_path = csv_translation\n",
    "    else:\n",
    "        transformed = \"combined\"\n",
    "        csv_path = csv_combination\n",
    "        \n",
    "    dataset_func.to_csv(fr\"{csv_path}\\\\un_{transformed}_file_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c31a914",
   "metadata": {},
   "source": [
    "### 4.2. Raster file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8967a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to converting 1D array into gridded arrays (z values)\n",
    "def raster_conversion(x_func, y_func, z_func):\n",
    "    '''This function is used to convert dimensions of array into raster array\n",
    "    References: https://stackoverflow.com/questions/41897544/make-a-contour-plot-by-using-three-1d-arrays-in-python\n",
    "    Arguments:\n",
    "                x_func, y_func, z_func:\n",
    "                            1D x, y, z datasets\n",
    "    Return:\n",
    "                x_values_func, y_values_func, z_values_func:\n",
    "                            Values of x, y, z under raster array (gridded array)\n",
    "    '''\n",
    "    # Gather x, y, z datasets into a pandas dataframe\n",
    "    pd_dataframe = pd.DataFrame(dict(x=x_func, y=y_func, z=z_func))\n",
    "    \n",
    "    # Assign dataframe column names into variables\n",
    "    xcol, ycol, zcol = 'x', 'y', 'z'\n",
    "    \n",
    "    # Sort dataframe according to x then y values\n",
    "    pd_dataframe_sorted = pd_dataframe.sort_values(by=[xcol, ycol])\n",
    "    \n",
    "    # Getting values of x, y, z under raster array format\n",
    "    # unique() function is used to remove duplicates\n",
    "    x_values_func = pd_dataframe_sorted[xcol].unique() \n",
    "    y_values_func = pd_dataframe_sorted[ycol].unique()\n",
    "    z_values_func = pd_dataframe_sorted[zcol].values.reshape(len(x_values_func), len(y_values_func)).T\n",
    "    \n",
    "    return x_values_func, y_values_func, z_values_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d23fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to write x, y, z values into raster file\n",
    "def raster_generation(transformation_selection, x_func, y_func, z_func, filename):\n",
    "    '''This function is used to write gridded array (x, y, z) into raster file\n",
    "    References: http://xarray.pydata.org/en/stable/user-guide/io.html\n",
    "    Arguments:\n",
    "                transformation_selection:\n",
    "                            \"r\" means rotation\n",
    "                            \"t\" means translation\n",
    "                            \"c\" means combination\n",
    "                x_func, y_func, z_func:\n",
    "                            1D x, y, z datasets\n",
    "                filename:\n",
    "                            Name of raster file\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        transformed = \"rotated\"\n",
    "        nc_raster_path_func = rotated_nc_raster_path\n",
    "        raster_transformation_path = raster_rotation\n",
    "    elif transformation_selection == 't':\n",
    "        transformed = \"translated\"\n",
    "        nc_raster_path_func = translated_nc_raster_path\n",
    "        raster_transformation_path = raster_translation\n",
    "    else:\n",
    "        transformed = \"combined\"\n",
    "        nc_raster_path_func = combined_nc_raster_path\n",
    "        raster_transformation_path = raster_combination\n",
    "        \n",
    "    # Read original DEM raster without padding\n",
    "    raster_origin_func = rioxarray.open_rasterio(fr\"{nc_raster_path_func}\\\\generated_dem_no_padding.nc\")\n",
    "    \n",
    "    # Get x, y, z values under raster array (gridded array)\n",
    "    x_values_func, y_values_func, z_values_func = raster_conversion(x_func, y_func, z_func)\n",
    "    \n",
    "    # Write x, y, z values into raster array\n",
    "    raster_array = xarray.DataArray(\n",
    "        data = z_values_func,\n",
    "        dims = ['y', 'x'],\n",
    "        coords = {\n",
    "            'x': (['x'], x_values_func),\n",
    "            'y': (['y'], y_values_func)\n",
    "        },\n",
    "        attrs = raster_origin_func.attrs\n",
    "    )\n",
    "    \n",
    "    # Set up crs and nodata\n",
    "    raster_array.rio.write_crs(\"epsg:2193\", inplace=True)\n",
    "    raster_array.rio.write_nodata(-999, inplace=True)\n",
    "    \n",
    "    # Write into raster file (tiff)\n",
    "    raster_array.rio.to_raster(fr\"{raster_transformation_path}\\\\{filename}_un{transformed}_flowdepth_raster.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84142276",
   "metadata": {},
   "source": [
    "### 4.3. Polygon file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe5522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to converting dataset into polygon\n",
    "def polygon_conversion(transformation_selection, dataset_func, column):\n",
    "    '''This function is to convert dataset into polygon (to write into shapefile)\n",
    "    Arguments:\n",
    "                transformation_selection:\n",
    "                            \"r\" means rotation\n",
    "                            \"t\" means translation\n",
    "                            \"c\" means combination\n",
    "                dataset_func:\n",
    "                        A dataset that needs converting to polygon\n",
    "                column:\n",
    "                        Column name that needs converting\n",
    "    Return:\n",
    "                poly_dataframe:\n",
    "                        A geopandas dataframe\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        nc_raster_path_func = rotated_nc_raster_path\n",
    "    elif transformation_selection == 't':\n",
    "        nc_raster_path_func = translated_nc_raster_path\n",
    "    else:\n",
    "        nc_raster_path_func = combined_nc_raster_path\n",
    "    \n",
    "    # Convert 0 values into NaN\n",
    "    dataset_func.loc[dataset_func[f\"{column}\"]==-999, [f\"{column}\"]] = np.nan\n",
    "    \n",
    "    # Read original DEM raster without padding\n",
    "    poly_origin = rasterio.open(fr\"{nc_raster_path_func}\\\\generated_dem_no_padding.nc\")\n",
    "    \n",
    "    # Get information from original DEM raster\n",
    "    poly_origin_array = poly_origin.read(1)\n",
    "    poly_origin_transform = poly_origin.transform\n",
    "    poly_origin_crs = poly_origin.crs\n",
    "    \n",
    "    # Extract parameters: id and depth\n",
    "    id_pixels = np.arange(poly_origin_array.size).reshape(poly_origin_array.shape)\n",
    "    value_list = dataset_func[f\"{column}\"].tolist()\n",
    "    \n",
    "    # Vectorise features\n",
    "    vectors = rasterio.features.shapes(source = id_pixels.astype(np.int16),\n",
    "                                       transform = poly_origin_transform)\n",
    "    \n",
    "    vectors_list = list(vectors)\n",
    "    \n",
    "    # Get geometry\n",
    "    poly_geometry = [shape(polygon) for polygon, value in vectors_list]\n",
    "    \n",
    "    # Get id\n",
    "    id_poly = [id_val for id_poly, id_val in vectors_list]\n",
    "    \n",
    "    # Create database\n",
    "    poly_database = {'id': id_poly,\n",
    "                     f\"{column}\": value_list}\n",
    "    poly_dataframe = gpd.GeoDataFrame(data = poly_database,\n",
    "                                      geometry = poly_geometry,\n",
    "                                      crs = poly_origin_crs)\n",
    "    \n",
    "    return poly_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1d1ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to write polygons into shape file\n",
    "def polygon_generation(transformation_selection, dataset_func, column):\n",
    "    '''This function is to write dataframe into shape file\n",
    "    Arguments:\n",
    "                transformation_selection:\n",
    "                            \"r\" means rotation\n",
    "                            \"t\" means translation\n",
    "                            \"c\" means combination\n",
    "                dataset_func:\n",
    "                            A dataset that needs converting to polygon\n",
    "                column:\n",
    "                            Column name that needs converting\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        transformed = \"rotated\"\n",
    "        polygon_transformation_path = polygon_rotation\n",
    "    elif transformation_selection == 't':\n",
    "        transformed = \"translated\"\n",
    "        polygon_transformation_path = polygon_translation\n",
    "    else:\n",
    "        transformed = \"combined\"\n",
    "        polygon_transformation_path = polygon_combination\n",
    "        \n",
    "    # Get polygon dataframe\n",
    "    polygon_dataframe = polygon_conversion(transformation_selection, dataset_func, column)\n",
    "    \n",
    "    # Write into shape file\n",
    "    polygon_dataframe.to_file(fr\"{polygon_transformation_path}\\\\{column}_un{transformed}_flowdepth_polygon.shp\",\n",
    "                              driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef5546",
   "metadata": {},
   "source": [
    "# 5. Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb45361d",
   "metadata": {},
   "source": [
    "### 5.1. Set up coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47328965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_rgb(value_func):\n",
    "    '''This function is to convert hex to red green blue (rgb) colors. The code is based on the link in reference (by Kerry Halupka)\n",
    "    Reference:  https://towardsdatascience.com/beautiful-custom-colormaps-with-matplotlib-5bab3d1f0e72\n",
    "    Arguments:\n",
    "                value_func:\n",
    "                                 Hex color code under 6-characters string format \n",
    "    Return:\n",
    "                rgb_value_func:\n",
    "                                 A tuple of rgb values with length of 3\n",
    "    '''\n",
    "    hex_value_func = value_func.strip('#')\n",
    "    level_func = len(hex_value_func)\n",
    "    rgb_value_func = tuple(int(hex_value_func[i:i + level_func // 3], 16) for i in range(0, level_func, level_func // 3))\n",
    "    \n",
    "    return rgb_value_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ced01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_dec(value_func):\n",
    "    '''This function is to convert rgb to decimal colors (dividing each value by 256). \n",
    "       The code is based on the link in reference (by Kerry Halupka)\n",
    "    Reference:  https://towardsdatascience.com/beautiful-custom-colormaps-with-matplotlib-5bab3d1f0e72\n",
    "    Arguments:\n",
    "                value_func:\n",
    "                                A tuple of rgb color code (from 0 to 256) with length of 3\n",
    "    Return:\n",
    "                dec_value_func:\n",
    "                                A list of color decimal values with length of 3 \n",
    "    '''\n",
    "    return [val / 256 for val in value_func]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2b2c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient_cmap(hex_list_func, float_list_func=None):\n",
    "    '''This function is to create gradient colors. The code is based on the link in reference (by Kerry Halupka)\n",
    "       If float_list_func is None, colour map will graduate linearly between each color in hex_list\n",
    "       If float_list_func is not None, each color in hex_list_func is mapped to the respective location in float_list_func\n",
    "    Reference:  https://towardsdatascience.com/beautiful-custom-colormaps-with-matplotlib-5bab3d1f0e72\n",
    "    Arguments:\n",
    "                hex_list_func:\n",
    "                                A list of hex code color under string format\n",
    "                float_list_func:\n",
    "                                A lsit of floats (between 0 and 1), same length as hex_list_func. Must start with 0 and end with 1.\n",
    "    Return:\n",
    "                colour_map:\n",
    "                                Color under matplotlib color map\n",
    "    '''\n",
    "    # Get rgb list\n",
    "    rgb_list = [rgb_to_dec(hex_to_rgb(color_code)) for color_code in hex_list_func]\n",
    "    \n",
    "    # Check float list\n",
    "    if float_list_func:\n",
    "        pass\n",
    "    else:\n",
    "        float_list_func = list(np.linspace(0, 1, len(rgb_list)))\n",
    "    \n",
    "    # Build up gradient colors\n",
    "    color_dict = dict()\n",
    "    for number, color in enumerate(['red', 'green', 'blue']):\n",
    "        color_list = [[float_list_func[i], rgb_list[i][number], rgb_list[i][number]] for i in range(len(float_list_func))]\n",
    "        color_dict[color] = color_list\n",
    "        \n",
    "    color_map = mcolors.LinearSegmentedColormap('my_cmp', segmentdata=color_dict, N=256)\n",
    "    \n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5161a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking color code\n",
    "# The code is based on the link in reference (by Kerry Halupka)\n",
    "# Reference: https://towardsdatascience.com/beautiful-custom-colormaps-with-matplotlib-5bab3d1f0e72\n",
    "\n",
    "# Create x, y, z\n",
    "x, y = np.mgrid[-5:5:0.05, -5:5:0.05]\n",
    "z = (np.sqrt(x**2 + y**2) + np.sin(x**2 + y**2))\n",
    "\n",
    "# List of hex codes\n",
    "hex_list0= ['#0091ad', '#3fcdda', '#83f9f8', '#d6f6eb', '#fdf1d2', '#f8eaad', '#faaaae', '#ff57bb']\n",
    "hex_list1= [\"#8fe2ff\",\"#8dbdff\",\"#5999ff\",\"#3d50ff\",\"#6b01ff\",\"#4800c4\",\"#e200ff\"]\n",
    "hex_list2= [\"#0466C8\", \"#0353A4\", \"#023E7D\", \"#002855\", \"#001845\", \"#001233\", \"#33415C\", \"#5C677D\", \"#7D8597\", \"#979DAC\"]\n",
    "hex_list3= [\"#B7094C\", \"#A01A58\", \"#892B64\", \"#723C70\", \"#5C4D7D\", \"#455E89\", \"#2E6F95\", \"#1780A1\", \"#0091AD\"]\n",
    "hex_list4= [\"#25CED1\", \"#FFFFFF\", \"#FCEADE\", \"#FF8A5B\", \"#EA526F\"]\n",
    "hex_list5= [\"#EA698B\", \"#D55D92\", \"#C05299\", \"#AC46A1\", \"#973AA8\", \"#822FAF\", \"#6D23B6\", \"#6411AD\", \"#571089\", \"#47126B\"]\n",
    "hex_list6= [\"#25CED1\", \"#00B2CA\", \"F7C59F\", \"#FF8A5B\", \"#086375\"]\n",
    "hex_list7= [\"#B76935\", \"#A56336\", \"#935E38\", \"#815839\", \"#6F523B\",\"#5C4D3C\", \"#4A473E\", \"#38413F\", \"#263C41\", \"#143642\"]\n",
    "hex_list8= [\"#522E38\", \"#E05780\", \"#FF9EBB\", \"#A06CD5\", \"#3C096C\", \"#B298DC\", \"#979DAC\", \"#5C677D\", \"#0D1B2A\"]\n",
    "hex_list9= [\"#FF595E\", \"#FFCA3A\", \"#8AC926\", \"#1982C4\", \"#6A4C93\"]\n",
    "hex_list10=[\"#390099\", \"#9E0059\", \"#FF0054\", \"#FF5400\", \"#FFBD00\"]\n",
    "hex_list11=[\"#70D6FF\", \"#FF70A6\", \"#FF9770\", \"#FFD670\", \"#E9FF70\"]\n",
    "hex_list12=[\"#001219\", \"#005F73\", \"#0A9396\", \"#94D2BD\", \"#E9D8A6\", \"#EE9B00\", \"#CA6702\", \"#BB3E03\", \"#AE2012\", \"#9B2226\"]\n",
    "hex_list13=[\"#004B23\", \"#006400\", \"#007200\", \"#008000\", \"#38B000\", \"#70E000\", \"#9EF01A\", \"#CCFF33\"]\n",
    "hex_list14=[\"#90F1EF\", \"#FFD6E0\", \"#FFEF9F\", \"#C1FBA4\", \"#7BF1A8\"]\n",
    "hex_list15=[\"#3D348B\", \"#7678ED\", \"#F7B801\", \"#F18701\", \"#F35B04\"]\n",
    "hex_list16=[\"#54478C\", \"#2C699A\", \"#048BA8\", \"#0DB39E\", \"#16DB93\", \"#83E377\", \"#B9E769\", \"#EFEA5A\", \"#F1C453\", \"#F29E4C\"]\n",
    "hex_list17=[\"#EE6055\", \"#60D394\", \"#AAF683\", \"#FFD97D\", \"#FF9B85\"]\n",
    "hex_list18=[\"#00A6FB\" ,\"#0582CA\", \"#006494\", \"#003554\", \"#051923\"]\n",
    "hex_list19=[\"#f79256ff\", \"#fbd1a2ff\", \"#7dcfb6ff\", \"#00b2caff\", \"#1d4e89ff\"]\n",
    "hex_list20=[\"#083d77ff\", \"#ebebd3ff\", \"#f4d35eff\", \"#ee964bff\", \"#f95738ff\"]\n",
    "hex_list21=[\"#1d4e89ff\", \"#fbd1a2ff\", \"#7dcfb6ff\", \"#00b2caff\", \"#1d4e89ff\"]\n",
    "hex_list22=[\"#072ac8ff\", \"#1e96fcff\", \"#a2d6f9ff\", \"#fcf300ff\", \"#ffc600ff\"]\n",
    "hex_list23=[\"#ff499eff\", \"#d264b6ff\", \"#a480cfff\", \"#779be7ff\", \"#49b6ffff\"]\n",
    "hex_list24=[\"#d62839ff\", \"#ba324fff\", \"#175676ff\", \"#4ba3c3ff\", \"#cce6f4ff\"]\n",
    "hex_list25=[\"2d728f\",\"3b8ea5\",\"f5ee9e\",\"f49e4c\",\"ab3428\"]\n",
    "hex_list26=[\"9b5de5\",\"f15bb5\",\"fee440\",\"00bbf9\",\"00f5d4\"]\n",
    "hex_list27=[\"ef476f\",\"ffd166\",\"06d6a0\",\"118ab2\",\"073b4c\"]\n",
    "hex_list28=[\"001219\",\"005f73\",\"0a9396\",\"94d2bd\",\"e9d8a6\",\"ee9b00\",\"ca6702\",\"bb3e03\",\"ae2012\",\"9b2226\"]\n",
    "hex_list29=[\"2d00f7\",\"6a00f4\",\"8900f2\",\"a100f2\",\"b100e8\",\"bc00dd\",\"d100d1\",\"db00b6\",\"e500a4\",\"f20089\"]\n",
    "hex_list30=[\"54478c\",\"2c699a\",\"048ba8\",\"0db39e\",\"16db93\",\"83e377\",\"b9e769\",\"efea5a\",\"f1c453\",\"f29e4c\"]\n",
    "hex_list31=[\"2d728f\",\"3b8ea5\",\"f5ee9e\",\"f49e4c\",\"ab3428\"]\n",
    "hex_list32=[\"d62839\",\"ba324f\",\"175676\",\"4ba3c3\",\"cce6f4\"]\n",
    "hex_list33=[\"ff499e\",\"d264b6\",\"a480cf\",\"779be7\",\"175676\"]\n",
    "hex_list34=[\"0c0a3e\",\"7b1e7a\",\"b33f62\",\"f9564f\",\"f3c677\"]\n",
    "hex_list35=[\"ee6055\",\"60d394\",\"aaf683\",\"ffd97d\",\"ff9b85\"]\n",
    "hex_list36=[\"247ba0\",\"70c1b3\",\"b2dbbf\",\"f3ffbd\",\"ff1654\"]\n",
    "hex_list37=[\"03071e\",\"370617\",\"6a040f\",\"9d0208\",\"d00000\",\"dc2f02\",\"e85d04\",\"f48c06\",\"faa307\",\"ffba08\"]\n",
    "hex_list38=[\"3d5a80\",\"98c1d9\",\"e0fbfc\",\"ee6c4d\",\"293241\"]\n",
    "hex_list39=[\"8ecae6\",\"219ebc\",\"023047\",\"ffb703\",\"fb8500\"]\n",
    "hex_list40=[\"9b5de5\",\"f15bb5\",\"fee440\",\"F9C74F\",\"00bbf9\",\"184E77\"]\n",
    "hex_list41=[\"0c0a3e\",\"7b1e7a\",\"b33f62\",\"f9564f\",\"f3c677\"]\n",
    "hex_list42=[\"2d728f\",\"3b8ea5\",\"f5ee9e\",\"f49e4c\",\"ab3428\"]\n",
    "hex_list43=[\"6e44ff\",\"b892ff\",\"ffc2e2\",\"ff90b3\",\"BA324F\"]\n",
    "hex_list44=[\"000814\",\"001d3d\",\"003566\",\"ffc300\",\"ffd60a\"]\n",
    "hex_list45=[\"001427\",\"708d81\",\"f4d58d\",\"bf0603\",\"8d0801\"]\n",
    "\n",
    "# If the reversed hex code color is required just using index [::-1]. \n",
    "# For example, the reversed color of hex_list0 is hex_list0[::-1]\n",
    "\n",
    "# Plot colors\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "im = ax.imshow(z, cmap=get_gradient_cmap(hex_list0))\n",
    "fig.colorbar(im)\n",
    "\n",
    "# Remove axes\n",
    "ax.yaxis.set_major_locator(plt.NullLocator()) # remove y axis ticks\n",
    "ax.xaxis.set_major_locator(plt.NullLocator()) # remove x axis ticks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f03d63c",
   "metadata": {},
   "source": [
    "## 5.2. Plotting with map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbb0bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_down(number, decimals=0):\n",
    "    '''This function is to round down the number. This code is based on the link in reference (by Priyankur Sarkar)\n",
    "    Reference:  https://www.knowledgehut.com/blog/programming/python-rounding-numbers\n",
    "    Arguments:\n",
    "                number:\n",
    "                        Number needs rounding down\n",
    "                decimals:\n",
    "                        Number of decimals that the number can be rounded down to\n",
    "    Return:\n",
    "                rounded_down_number:\n",
    "                        Number that is rounded down\n",
    "    '''\n",
    "    rounded_down_number = np.floor(number * (10 ** decimals)) / (10 ** decimals)\n",
    "    return rounded_down_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3831d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to plot the water depth values along with the map\n",
    "def plotting_map(filtered_data_func, calculation_option, axis, \n",
    "                 hex_list_func, colorbar_position, \n",
    "                 extend_colorbar=None):\n",
    "    '''This function is to plot water depth on basemap\n",
    "    References: https://stackoverflow.com/questions/41897544/make-a-contour-plot-by-using-three-1d-arrays-in-python\n",
    "                https://stackoverflow.com/questions/44669616/contour-in-matplotlib-does-not-plot-specified-number-of-contours\n",
    "                https://stackoverflow.com/questions/48487346/filled-contour-using-class-labels\n",
    "                https://matplotlib.org/3.1.1/gallery/images_contours_and_fields/tricontour_smooth_user.html#sphx-glr-gallery-images-contours-and-fields-tricontour-smooth-user-py\n",
    "                https://www.python-course.eu/matplotlib_contour_plot.php\n",
    "                https://jakevdp.github.io/PythonDataScienceHandbook/04.04-density-and-contour-plots.html\n",
    "                https://www.earthdatascience.org/tutorials/visualize-digital-elevation-model-contours-matplotlib/\n",
    "                https://alex.miller.im/posts/contour-plots-in-python-matplotlib-x-y-z/\n",
    "                \n",
    "                https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.contour.html\n",
    "                https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.tricontourf.html\n",
    "                https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.tricontour.html#matplotlib.pyplot.tricontour\n",
    "                \n",
    "                https://contextily.readthedocs.io/en/latest/providers_deepdive.html\n",
    "                https://stackoverflow.com/questions/3777861/setting-y-axis-limit-in-matplotlib\n",
    "                https://www.tutorialspoint.com/how-do-i-adjust-offset-the-colorbar-title-in-matplotlib\n",
    "                https://stackoverflow.com/questions/18195758/set-matplotlib-colorbar-size-to-match-graph\n",
    "                \n",
    "                https://stackoverflow.com/questions/3899980/how-to-change-the-font-size-on-a-matplotlib-plot\n",
    "                https://kaleidoscopicdiaries.wordpress.com/2015/05/30/distance-between-axes-label-and-axes-in-matplotlib/\n",
    "                https://geopandas.org/en/latest/gallery/matplotlib_scalebar.html\n",
    "                https://stackoverflow.com/questions/8263769/hide-contour-linestroke-on-pyplot-contourf-to-get-only-fills\n",
    "                \n",
    "                https://matplotlib.org/stable/gallery/axes_grid1/demo_colorbar_with_axes_divider.html\n",
    "                https://stackoverflow.com/questions/18195758/set-matplotlib-colorbar-size-to-match-graph\n",
    "    Arguments:\n",
    "                filtered_data_func:\n",
    "                                    Filtered dataset contains nodata values as -999\n",
    "                calculation_option:\n",
    "                                    \"mean\" means to calculate mean\n",
    "                                    \"sd\" means to calculate standard deviation\n",
    "                                    \"cv\" means to calculate coefficient of variation\n",
    "                                    \"cell\" means to calculate probability of each pixel being inundated\n",
    "                axis:\n",
    "                                    Subplot ordinal number of the contour map on the big plot\n",
    "                hex_list_func:\n",
    "                                    A list of hex code colors (including or not including #)\n",
    "                extend_colorbar:\n",
    "                                    Whether having or not having arrow to indicate the larger or smaller values in colorbar\n",
    "                colorbar_position:\n",
    "                                    \"horizontal\" or \"vertical\"\n",
    "    '''\n",
    "    # Titles and labels:\n",
    "    if calculation_option != 'cell':\n",
    "        # Title for colorbar\n",
    "        name_map = f\"{calculation_option.capitalize()} of water depth (m)\"\n",
    "        \n",
    "        # Title for contour map\n",
    "        axis.set_title(f\"{name_map} of water depth\", pad=25, fontsize=25, fontweight='bold')\n",
    "        axis.set_xlabel(\"NZTM, east (m)\", fontsize=20, labelpad=38)\n",
    "        axis.set_ylabel(\"NZTM, north (m)\", fontsize=20, labelpad=38, rotation=-270)\n",
    "        \n",
    "        # Level information\n",
    "        min_map_level = round_down(np.min(filtered_data_func[f'{calculation_option}'][filtered_data_func[f'{calculation_option}'] != -999]), 1)\n",
    "        max_map_level = np.max(filtered_data_func[f'{calculation_option}'][filtered_data_func[f'{calculation_option}'] != -999] - 1)\n",
    "        map_level = np.arange(min_map_level, max_map_level, 0.1)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Title for colorbar\n",
    "        name_map = \"Probability of each location being inundated (%)\"\n",
    "        \n",
    "        # Title for contour map\n",
    "        axis.set_title(\"Probability of each location being inundated\", pad=25, fontsize=25, fontweight='bold')\n",
    "        axis.set_xlabel(\"NZTM, east (m)\", fontsize=20, labelpad=38)\n",
    "        axis.set_ylabel(\"NZTM, north (m)\", fontsize=20, labelpad=38, rotation=-270)\n",
    "        \n",
    "        # Max level\n",
    "        min_map_level = 0\n",
    "        max_map_level = 102\n",
    "        map_level = np.arange(min_map_level, max_map_level, 1)\n",
    "    \n",
    "    # x, y, z coordinates information\n",
    "    x_func = filtered_data_func['x']\n",
    "    y_func = filtered_data_func['y']\n",
    "    z_func = filtered_data_func[f'{calculation_option}']\n",
    "    \n",
    "    # Build up contour map\n",
    "    contour_map_func = axis.tricontourf(x_func, y_func, z_func, levels=map_level,\n",
    "                                        cmap=get_gradient_cmap(hex_list_func),\n",
    "                                        alpha=1, antialiased=True, extend=extend_colorbar)\n",
    "    \n",
    "    # Improve visualisation of map (x, y) axes\n",
    "    axis.tick_params(direction='out', length=8, pad=10)                   # For x, y axes' ticks\n",
    "    axis.yaxis.offsetText.set_fontsize(12)                                # For 1e6 if there is no axis.ticklabel_format(useOffset=False, style='plain')\n",
    "    axis.xaxis.offsetText.set_fontsize(12)                                # For 1e6 if there is no axis.ticklabel_format(useOffset=False, style='plain')\n",
    "    \n",
    "    for item in (axis.get_xticklabels() + axis.get_yticklabels()):        # For x, y ticks' labels\n",
    "        item.set_fontsize(15)\n",
    "    \n",
    "    # Remove grid background lines (including x, y lines)\n",
    "    axis.grid(False)\n",
    "    axis.spines['top'].set_visible(False)\n",
    "    axis.spines['right'].set_visible(False)\n",
    "    axis.spines['bottom'].set_visible(False)\n",
    "    axis.spines['left'].set_visible(False)\n",
    "    \n",
    "    # Remove whitelines\n",
    "    for color_line in contour_map_func.collections:\n",
    "        color_line.set_edgecolor(\"face\")\n",
    "    \n",
    "    # Call the map\n",
    "    ctx.add_basemap(ax=axis, crs=2193, \n",
    "                    source=ctx.providers.OpenStreetMap.BlackAndWhite, \n",
    "                    attribution_size=10, zoom=17)\n",
    "    \n",
    "    # Scale bar\n",
    "    map_scalebar = ScaleBar(10, font_properties={'weight': 'bold', 'size': 15},\n",
    "                            pad=0.5,\n",
    "                            box_color=None,\n",
    "                            box_alpha=0,\n",
    "                            color='k',\n",
    "                            scale_formatter=lambda value, unit: f'{value} {unit}')\n",
    "\n",
    "    axis.add_artist(map_scalebar)\n",
    "    \n",
    "    # Colorbar\n",
    "    if colorbar_position == 'horizontal':\n",
    "        # Set up colorbar position\n",
    "        divider = make_axes_locatable(axis)\n",
    "        cax = divider.append_axes(\"bottom\", size=\"3%\", pad=1.8)\n",
    "        \n",
    "        map_colorbar = fig.colorbar(contour_map_func, orientation=colorbar_position, cax=cax, ax=axis)\n",
    "        map_colorbar.ax.tick_params(axis='x', direction='out', length=6, pad=10, labelsize=15)\n",
    "        \n",
    "        # Set up colorbar title\n",
    "        map_colorbar.set_label(name_map, labelpad=30, fontsize=20)\n",
    "        \n",
    "    else:\n",
    "        # Set up colorbar position\n",
    "        cax = fig.add_axes([ax.get_position().x1 + 0.02,\n",
    "                            ax.get_position().y0, 0.02,\n",
    "                            ax.get_position().height])\n",
    "        \n",
    "        map_colorbar = fig.colorbar(contour_map_func, cax=cax, pad=5, ax=axis)\n",
    "        map_colorbar.ax.tick_params(axis='y', direction='out', length=6, pad=10, labelsize=15)\n",
    "        \n",
    "        # Set up colorbar title\n",
    "        map_colorbar.set_label(name_map, rotation=270, labelpad=38, fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382fb57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_histogram(filtered_data_func, calculation_option, \n",
    "                       axis, hex_list_func):\n",
    "    '''This function is to plot histogram of information regarding water depth\n",
    "    Reference:  https://stackoverflow.com/questions/23061657/plot-histogram-with-colors-taken-from-colormap\n",
    "                https://stdworkflow.com/67/attributeerror-rectangle-object-has-no-property-normed-solution\n",
    "    Arguments:\n",
    "            filtered_data_func:\n",
    "                                Filtered dataset contains nodata values as -999\n",
    "            calculation_option:\n",
    "                                \"mean\" means to calculate mean\n",
    "                                \"sd\" means to calculate standard deviation\n",
    "                                \"cv\" means to calculate coefficient of variation\n",
    "                                \"cell\" means to calculate probability of each pixel being inundated\n",
    "            axis:\n",
    "                                Subplot ordinal number of the contour map on the big plot\n",
    "            hex_list_func:\n",
    "                                A list of hex code colors (including or not including #)    \n",
    "    '''\n",
    "    # Get z values\n",
    "    z_func = filtered_data_func[f'{calculation_option}']\n",
    "    \n",
    "    # Select colormap\n",
    "    hist_cm = get_gradient_cmap(hex_list_func)\n",
    "    \n",
    "    # Get the histogram\n",
    "    hist_y_axis, hist_x_axis = np.histogram(z_func[z_func != -999], 50, density=False)\n",
    "\n",
    "    hist_x_span = hist_x_axis.max() - hist_x_axis.min()\n",
    "\n",
    "    hist_color = [hist_cm(((hist_x_val - hist_x_axis.min()) / hist_x_span)) for hist_x_val in hist_x_axis]\n",
    "\n",
    "    axis.bar(hist_x_axis[:-1],\n",
    "             hist_y_axis,\n",
    "             color = hist_color,\n",
    "             width = hist_x_axis[1] - hist_x_axis[0])\n",
    "\n",
    "    for hist_item in (axis.get_xticklabels() + axis.get_yticklabels()):\n",
    "        hist_item.set_fontsize(15)\n",
    "    \n",
    "    # Remove grid background lines (including x, y lines)\n",
    "    axis.grid(False)\n",
    "    axis.spines['top'].set_visible(False)\n",
    "    axis.spines['right'].set_visible(False)\n",
    "    axis.spines['bottom'].set_visible(False)\n",
    "    axis.spines['left'].set_visible(False)\n",
    "    \n",
    "    # Set titles and labels\n",
    "    if calculation_option != 'cell':\n",
    "        # Title for colorbar\n",
    "        name_map = f\"{calculation_option.capitalize()} of water depth (m)\"\n",
    "        \n",
    "        # Title for contour map\n",
    "        axis.tick_params(direction='out', length=8, pad=10)\n",
    "        axis.set_title(f\"Histogram of {name_map} of water depth\", pad=25, fontsize=25, fontweight='bold')\n",
    "        axis.set_xlabel('Mean of depth values (m)', fontsize=20, labelpad=38)\n",
    "        axis.set_ylabel('Frequency', fontsize=20, labelpad=38)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Title for colorbar\n",
    "        name_map = \"Probability of each location being inundated (%)\"\n",
    "        \n",
    "        # Title for contour map\n",
    "        axis.tick_params(direction='out', length=8, pad=10)\n",
    "        axis.set_title(\"Histogram of probability of each location being inundated\", pad=25, fontsize=25, fontweight='bold')\n",
    "        axis.set_xlabel(\"Probability of each location being inundated (%)\", fontsize=20, labelpad=38)\n",
    "        axis.set_ylabel(\"Frequency\", fontsize=20, labelpad=38)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197710cf",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4897e5ff",
   "metadata": {},
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0db781",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "combination_number0 = f\"angle_0_x_0_y_0\"\n",
    "clipped_dataset = raster_array_to_shapefile(\"c\", combination_number0, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0580d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the angle\n",
    "angle_start = 0\n",
    "angle_end = 90\n",
    "angle_interval = 45\n",
    "\n",
    "# Set up the translation\n",
    "value_start = 0\n",
    "value_end = 0\n",
    "value_interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e1c85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = {\"x_coord\": clipped_dataset[:, 0],\n",
    "        \"y_coord\": clipped_dataset[:, 1]}\n",
    "\n",
    "for angle_value in range(angle_start, angle_end+1, angle_interval):\n",
    "    for value_x in range(value_start, value_end+1, value_interval):\n",
    "        for value_y in range(value_start, value_end+1, value_interval):\n",
    "            # Set the name of each translation\n",
    "            combination_number = f\"angle_{angle_value}_x_{value_x}_y_{value_y}\"\n",
    "            print(combination_number)\n",
    "            \n",
    "            start = time.time()\n",
    "            data[f\"{combination_number}\"] = get_flowdepth_value(\"c\", combination_number, 60)\n",
    "            end = time.time()\n",
    "            print(\"{0} angle: {1} and x: {2} and y: {3} {0}\".format(\"-\"*30, angle_value, value_x, value_y))\n",
    "            print(\"Running time:\", end-start)\n",
    "            print(\"-\"*90)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ccaacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data['angle_0_x_0_y_0']))\n",
    "print(len(data['angle_45_x_0_y_0']))\n",
    "print(len(data['angle_90_x_0_y_0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f405c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_data = pd.DataFrame(data = data)\n",
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c15337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = []\n",
    "for i in range(full_data.shape[0]):\n",
    "    a = full_data['angle_90_x_0_y_0'][i] - full_data['angle_0_x_0_y_0'][i]\n",
    "    if a !=0:\n",
    "        print(i)\n",
    "        dif.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967a142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "\n",
    "print(min(dif))\n",
    "print(max(dif))\n",
    "ax.hist(dif, bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f608b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['angle_90_x_0_y_0'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e5984",
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = []\n",
    "for i in range(full_data.shape[0]):\n",
    "    if full_data['angle_90_x_0_y_0'][i] != full_data['angle_0_x_0_y_0'][i]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc2ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(full_data.shape[0]):\n",
    "    if full_data['angle_90_x_0_y_0'][i] != full_data['angle_0_x_0_y_0'][i]:\n",
    "        text = \"{0:<20}         {1:<20}\"\n",
    "        print(text.format(full_data['angle_90_x_0_y_0'][i], full_data['angle_0_x_0_y_0'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ca189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183728ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['angle_90_x_0_y_0'][4768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8e12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['angle_0_x_0_y_0'][4768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f1d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the same length\n",
    "for angle_value in range(angle_start, angle_end+1, angle_interval):\n",
    "    for value_x in range(value_start, value_end+1, value_interval):\n",
    "        for value_y in range(value_start, value_end+1, value_interval):\n",
    "            if len(data[f\"angle_{angle_value}_x_{value_x}_y_{value_y}\"]) != 169728:\n",
    "                print(f\"angle_{angle_value}_x_{value_x}_y_{value_y}\")\n",
    "                print(len(data[f\"angle_{angle_value}_x_{value_x}_y_{value_y}\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ba5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write into csv file\n",
    "csv_generation('c', full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6f53f7",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if it's correct unrotation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(clipped_dataset[:,0], clipped_dataset[:,1], c=np.array(full_data['angle_90_x_0_y_0']), cmap=\"Blues\", s=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977c32f",
   "metadata": {},
   "source": [
    "### Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5074d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_check1 = pd.read_csv(r'Y:\\7_results\\un_combination\\uncom_csv\\version_1\\un_combined_file_1_no.csv')\n",
    "data_check2 = pd.read_csv(r'Y:\\7_results\\un_combination\\uncom_csv\\version_1\\un_combined_file_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad13764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_check1['angle_0_x_0_y_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_check2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e00c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full data from csv\n",
    "full_data = pd.read_csv(r'T:\\\\7_results\\un_combination\\uncom_csv\\version_1\\\\un_combined_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dataset = filter_dataset(full_data, 'mean', 0.1)\n",
    "sd_dataset = filter_dataset(full_data, 'sd', 0.1)\n",
    "cv_dataset = filter_dataset(full_data, 'cv', 0.1)\n",
    "cell_dataset = filter_dataset(full_data, 'cell', 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c68593",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dataset[mean_dataset['mean']==-999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a3f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_generation('c', cell_dataset['x'], cell_dataset['y'], cell_dataset['cell'], 'cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1992ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_generation('c', cell_dataset, 'cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1aa0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "plotting_map(sd_dataset, 'sd', ax, hex_list0, \"vertical\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "plotting_histogram(sd_dataset, 'sd', ax, hex_list0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b42cba1",
   "metadata": {},
   "source": [
    "### Building up a map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7622a2",
   "metadata": {},
   "source": [
    "### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d45ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_plot(data, color_name, plot_name):\n",
    "    '''This function is to plot the contour map\n",
    "    References: https://stackoverflow.com/questions/41897544/make-a-contour-plot-by-using-three-1d-arrays-in-python\n",
    "                https://stackoverflow.com/questions/44669616/contour-in-matplotlib-does-not-plot-specified-number-of-contours\n",
    "                https://stackoverflow.com/questions/48487346/filled-contour-using-class-labels\n",
    "                https://matplotlib.org/3.1.1/gallery/images_contours_and_fields/tricontour_smooth_user.html#sphx-glr-gallery-images-contours-and-fields-tricontour-smooth-user-py\n",
    "                https://www.python-course.eu/matplotlib_contour_plot.php\n",
    "                https://jakevdp.github.io/PythonDataScienceHandbook/04.04-density-and-contour-plots.html\n",
    "                https://www.earthdatascience.org/tutorials/visualize-digital-elevation-model-contours-matplotlib/\n",
    "                https://alex.miller.im/posts/contour-plots-in-python-matplotlib-x-y-z/\n",
    "                \n",
    "                https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.contour.html\n",
    "                https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.tricontourf.html\n",
    "                https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.tricontour.html#matplotlib.pyplot.tricontour\n",
    "    Arguments:\n",
    "                data: \n",
    "                        dataset contained the values\n",
    "                color_name:\n",
    "                        name of color to show the values\n",
    "                        \n",
    "                plot_name:\n",
    "                        name of plot\n",
    "    '''\n",
    "    # Create size of plotting background\n",
    "    fig, ax = plt.subplots(figsize=(20, 15))\n",
    "    \n",
    "    # \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65088972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No lines\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "\n",
    "levels = np.arange(0.1, 7, 0.01)\n",
    "cmap = cm.get_cmap(name='viridis', lut=None)\n",
    "\n",
    "contour_sd = ax.tricontourf(data[\"x_coord\"], data[\"y_coord\"], mean_dataset[\"mean\"], levels=levels,\n",
    "                            cmap=cmap)\n",
    "\n",
    "plt.title(\"Mean Flowdepth\")\n",
    "# plt.colorbar(contour_mean)\n",
    "plt.colorbar(contour_sd)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705ff320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having lines, but no color for lines\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "\n",
    "levels = np.arange(0., np.ceil(np.max(mean_data['mean']))+0.5, 0.01)\n",
    "cmap = cm.get_cmap(name='terrain', lut=None)\n",
    "\n",
    "a = ax.tricontourf(data[\"x_coord\"], data[\"y_coord\"], mean_data[\"mean\"], levels=levels, cmap=cmap)\n",
    "ax.tricontour(data[\"x_coord\"], data[\"y_coord\"], mean_data[\"mean\"], levels=levels, cmap=cmap,\n",
    "              linestyles='dashdot')\n",
    "\n",
    "plt.title(\"Depth contour\")\n",
    "plt.colorbar(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794685d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_length = np.arange(0., 8., 0.1).shape[0]\n",
    "color_range = np.linspace(0., 1., color_length).tolist()\n",
    "color = [str(color_range[i]) for i in range(len(color_range))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca4503",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Having lines, but no color for lines\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "\n",
    "levels = np.arange(0., np.ceil(np.max(mean_data['mean']))+0.5, 0.1)\n",
    "linewidths = np.arange(1.5, 0., -0.1)\n",
    "cmap = cm.get_cmap(name='terrain_r', lut=None)\n",
    "\n",
    "a = ax.tricontourf(data[\"x_coord\"], data[\"y_coord\"], mean_data['mean'], levels=levels, cmap=cmap)\n",
    "ax.tricontour(data[\"x_coord\"], data[\"y_coord\"], mean_data['mean'], levels=levels, colors=color,\n",
    "              linestyles='dashdot',\n",
    "              linewidths=linewidths)\n",
    "\n",
    "plt.title(\"Standard deviation Flowdepth Contour\")\n",
    "plt.colorbar(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e84d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.min(mean_data['mean'][mean_data['mean']>np.min(mean_data['mean'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31d6e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.min(mean_data['mean'][mean_data['mean']>a])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.min(mean_data['mean'][mean_data['mean']>b])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11f90d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(mean_data['mean'][mean_data['mean']>0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe6ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have lines and colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import contextily as ctx\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30, 30))\n",
    "\n",
    "levels = np.arange(0, np.ceil(np.max(mean_data['mean']))+0.5, 0.1)\n",
    "linewidths = np.arange(1.5, 0.5, -0.1)\n",
    "cmap = cm.get_cmap(name='Blues', lut=None)\n",
    "\n",
    "a = ax.tricontourf(data[\"x_coord\"], data[\"y_coord\"], copy_mean_data[\"mean\"], levels=levels, cmap=cmap, alpha=0.6, antialiased = True)\n",
    "ax.tricontour(data[\"x_coord\"], data[\"y_coord\"], copy_mean_data[\"mean\"], levels=levels, colors=['0', '0.125', '0.25', '0.375',\n",
    "                                                                                               '0.5', '0.675', '0.75', '0.875', '1'], \n",
    "              linestyles='dashdot',\n",
    "              linewidths=linewidths,\n",
    "              alpha=0.3)\n",
    "\n",
    "\n",
    "\n",
    "ctx.add_basemap(ax=ax, crs=2193, source=ctx.providers.OpenTopoMap)\n",
    "cax = fig.add_axes([ax.get_position().x1+0.01,ax.get_position().y0,0.02,ax.get_position().height])\n",
    "\n",
    "ax.set_title(\"Water Depth (Mean) Contour Map - Area: Waikanae River\", pad=25, fontsize=30)\n",
    "cbar = plt.colorbar(a, cax=cax)\n",
    "cbar.set_label(\"Depth values (m)\", rotation=270, labelpad=38, fontsize=28)\n",
    "cbar.ax.tick_params(axis = 'y', direction='out', length=6, pad=10, labelsize=18)\n",
    "\n",
    "ax.set_xlabel(\"NZTM, east (m)\", fontsize=28, labelpad=38)\n",
    "ax.set_ylabel(\"NZTM, north (m)\", fontsize=28, labelpad=38, rotation=-270)\n",
    "ax.tick_params(direction='out', length=8, pad=10)\n",
    "\n",
    "\n",
    "# ax.rc('xtick', labelsize=18)\n",
    "# ax.rc('ytick', labelsize=18)\n",
    "\n",
    "for item in (ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(18)\n",
    "\n",
    "ax.ticklabel_format(useOffset=False, style='plain')\n",
    "\n",
    "scalebar = ScaleBar(10, font_properties={'size': 25},\n",
    "                    pad=1,\n",
    "                    box_color=None,\n",
    "                    box_alpha=0,\n",
    "                    color='mediumblue',\n",
    "                    scale_formatter=lambda value, unit: f'{value} {unit}')\n",
    "ax.add_artist(scalebar)\n",
    "\n",
    "plt.savefig('Z:\\\\Trial\\\\Example\\\\foo.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0feeca",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc82f16",
   "metadata": {},
   "source": [
    "### Zero to nodata value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6600dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_mean_data = mean_data.copy()\n",
    "\n",
    "copy_mean_data.loc[copy_mean_data['mean'] == 0, ['mean']] = -999\n",
    "\n",
    "copy_mean_data[32:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e9479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have lines and colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "\n",
    "cmap = cm.get_cmap(name='YlOrRd', lut=None)\n",
    "\n",
    "a = ax.scatter(data[\"x_coord\"], data[\"y_coord\"], c=copy_mean_data['mean'], marker='s', cmap=cmap, s=80, linewidth=0.3, edgecolor='k', alpha=0.3)\n",
    "\n",
    "ax.set_xlim([np.min(data['x_coord']), np.max(data['x_coord'])])\n",
    "ax.set_ylim([np.min(data['y_coord']), np.max(data['y_coord'])])\n",
    "\n",
    "ctx.add_basemap(ax=ax, crs=2193, source=ctx.providers.OpenTopoMap)\n",
    "\n",
    "plt.title(\"Mean Flowdepth Contour\")\n",
    "plt.colorbar(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8666d990",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4bee9c",
   "metadata": {},
   "source": [
    "### Create raster/polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8342a19",
   "metadata": {},
   "source": [
    "### Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7287a",
   "metadata": {},
   "source": [
    "### Polygon - Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e8f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_origin = rasterio.open(fr\"{combined_nc_raster_path}\\\\generated_dem_no_padding.nc\")\n",
    "rc_origin_array = rc_origin.read(1)\n",
    "rc_origin_transform = rc_origin.transform\n",
    "rc_origin_crs = rc_origin.crs\n",
    "\n",
    "# Extract parameters: id and depth\n",
    "id_pixels = np.arange(rc_origin_array.size).reshape(rc_origin_array.shape)\n",
    "mean_list = copy_mean_data['mean'].tolist()\n",
    "\n",
    "\n",
    "# Vectorise features\n",
    "vectors = rasterio.features.shapes(source = id_pixels.astype(np.int16),\n",
    "                                   transform = rc_origin_transform)\n",
    "\n",
    "vectors_list = list(vectors)\n",
    "\n",
    "# Get geometry\n",
    "polygons_geometry = [shape(polygon) for polygon, value in vectors_list]\n",
    "\n",
    "\n",
    "# Get id\n",
    "id_polygon = [id_val for id_poly, id_val in vectors_list]\n",
    "\n",
    "\n",
    "# Create database\n",
    "polygon_mean = {'id': id_polygon,\n",
    "                \"mean\": mean_list}\n",
    "\n",
    "polygon_pdf = gpd.GeoDataFrame(data = polygon_mean,\n",
    "                               geometry = polygons_geometry,\n",
    "                               crs = rc_origin_crs)\n",
    "polygon_pdf.plot(column='mean', cmap='terrain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f82cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_sample = polygon_pdf.to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762df334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as ctx\n",
    "# from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "p1 = polygon_pdf.plot(ax=ax, column='mean', cmap='YlOrRd', alpha=0.7, legend=True)\n",
    "ctx.add_basemap(ax=ax, crs=2193, source=ctx.providers.OpenTopoMap)\n",
    "\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99792e1",
   "metadata": {},
   "source": [
    "### Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba10c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_array_1d = np.dstack((full_data['x_coord'], full_data['y_coord'], mean_data['mean']))\n",
    "pd_data = pd.DataFrame(dict(x=mean_array_1d[0][:,0], \n",
    "                            y=mean_array_1d[0][:,1], \n",
    "                            z=mean_array_1d[0][:,2]))\n",
    "xcol, ycol, zcol = 'x', 'y', 'z'\n",
    "\n",
    "pd_data_sorted = pd_data.sort_values(by=[xcol, ycol])\n",
    "xvals = np.round(pd_data_sorted[xcol].unique(), 3)\n",
    "yvals = np.round(pd_data_sorted[ycol].unique(), 3)\n",
    "zvals = pd_data_sorted[zcol].values.reshape(len(xvals), len(yvals)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b0b1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = xarray.DataArray(\n",
    "    data=zvals,\n",
    "    dims=['y', 'x'],\n",
    "    coords={\n",
    "        \"x\": (['x'], xvals2),\n",
    "        \"y\": (['y'], yvals2)\n",
    "    },\n",
    "    attrs=rc_nc.attrs\n",
    ")\n",
    "arr.rio.write_crs(2193)\n",
    "arr.rio.write_nodata(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.rio.to_raster(r\"Z:\\\\Trial\\\\Example\\\\flowdepth_raster4.tiff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92876f96",
   "metadata": {},
   "source": [
    "### Another plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1efe47",
   "metadata": {},
   "source": [
    "### mean and coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d6500",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b84416",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_coordinates = [Point(full_data['y_coord'][i], full_data['x_coord'][i]) for i in range(full_data.shape[0])]\n",
    "\n",
    "new_data = {\"mean\": mean_data['mean']}\n",
    "\n",
    "point_dataframe = gpd.GeoDataFrame(data = new_data,\n",
    "                                   geometry = point_coordinates,\n",
    "                                   crs = 2193)\n",
    "point_dataframe.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66c6464",
   "metadata": {},
   "source": [
    "### Folium to plot raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81daf62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = {'y': xvals}\n",
    "y_range = {'x': yvals}\n",
    "\n",
    "y_df = pd.DataFrame(x_range)\n",
    "x_df = pd.DataFrame(y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28466efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = p(y_df['y'], inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa12f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "\n",
    "p = pyproj.Proj(\"+proj=tmerc +lat_0=0 +lon_0=173 +k=0.9996 +x_0=1600000 +y_0=10000000 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\")\n",
    "\n",
    "def convert_to_latlon(df, p):\n",
    "    lon, lat = p(df['x'], df['y'], inverse=True)\n",
    "    df['lat'] = lat\n",
    "    df['lon'] = lon\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3266dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df_convert = mean_df.apply(convert_to_latlon, p=p, axis=1)\n",
    "mean_df_convert['lat'] = np.round(mean_df_convert['lat'], 4)\n",
    "mean_df_convert['lon'] = np.round(mean_df_convert['lon'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551a281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_array_lonlat = np.dstack((mean_df_convert['lat'], mean_df_convert['lon'], mean_df_convert['mean']))\n",
    "pd_data1 = pd.DataFrame(dict(x=mean_array_lonlat[0][:,0], \n",
    "                             y=mean_array_lonlat[0][:,1],\n",
    "                             z=mean_array_lonlat[0][:,2]))\n",
    "\n",
    "xcol, ycol, zcol = 'x', 'y', 'z'\n",
    "\n",
    "pd_data_sorted1 = pd_data1.sort_values(by=[xcol, ycol])\n",
    "xvals1 = pd_data_sorted1[xcol].unique()\n",
    "yvals1 = pd_data_sorted1[ycol].unique()\n",
    "zvals1 = pd_data_sorted1[zcol].values.reshape(len(xvals), len(yvals)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b28a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "yvals1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72831b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6aea9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "m = folium.Map(location=[-40.88, 175.04500], zoom_start=14)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1006ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "\n",
    "levels = np.arange(0., np.ceil(np.max(mean_data['mean']))+0.5, 0.1)\n",
    "linewidths = np.arange(1.5, 0., -0.1)\n",
    "cmap = cm.get_cmap(name='Blues', lut=None)\n",
    "\n",
    "contour_mean = ax.contourf(xvals1, yvals1, zvals1, cmap=cmap)\n",
    "\n",
    "plt.title(\"Mean Flowdepth Contour\")\n",
    "plt.colorbar(contour_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d708a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojsoncontour\n",
    "\n",
    "# Convert matplotlib contourf to geojson\n",
    "geojson = geojsoncontour.contourf_to_geojson(\n",
    "    contourf=contour_m\n",
    ")\n",
    "\n",
    "# Set up the map placeholder\n",
    "geomap1 = folium.Map(location=[-40.88, 175.04500], zoom_start=14)\n",
    "\n",
    "# Plot the contour on Folium map\n",
    "folium.GeoJson(\n",
    "    geojson\n",
    ").add_to(geomap1)\n",
    "\n",
    "\n",
    "\n",
    "# Add the legend to the map\n",
    "plugins.Fullscreen(position='topright', force_separate_button=True).add_to(geomap1)\n",
    "geomap1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ac2d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coord_data = {'y': full_data['y_coord'],\n",
    "              'x': full_data['x_coord'],\n",
    "              'mean': mean_data['mean']}\n",
    "\n",
    "coord_df = pd.DataFrame(coord_data)\n",
    "\n",
    "coord_df_0 = coord_df.loc[~((coord_df['mean']==np.nan))]\n",
    "\n",
    "coord_df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7837fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587dcd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj\n",
    "\n",
    "p = pyproj.Proj(\"+proj=tmerc +lat_0=0 +lon_0=173 +k=0.9996 +x_0=1600000 +y_0=10000000 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\")\n",
    "\n",
    "def convert_to_latlon(df, p):\n",
    "    lon, lat = p(df['x'], df['y'], inverse=True)\n",
    "    df['lat'] = lat\n",
    "    df['lon'] = lon\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7b754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_df_0_convert = coord_df_0.apply(convert_to_latlon, p=p, axis=1)\n",
    "coord_df_0_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f6e2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_df[['lat', 'lon']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc49323f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from folium import plugins\n",
    "coord_array = coord_df_0_convert[['lat', 'lon']].values\n",
    "m = folium.Map(location=[-40.88, 175.04500], zoom_start=15)\n",
    "m.add_children(plugins.HeatMap(coord_array, radius=11))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c5bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(coord_df_0_convert['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31f8a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have lines and colors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "\n",
    "levels = np.arange(0, np.ceil(np.max(mean_data['mean']))+0.5, 0.1)\n",
    "linewidths = np.arange(1.5, 0.1, -0.1)\n",
    "cmap = cm.get_cmap(name='Blues', lut=None)\n",
    "\n",
    "a = ax.tricontourf(coord_df_0_convert[\"x\"], coord_df_0_convert[\"y\"], coord_df_0_convert['mean'], levels=levels, cmap=cmap)\n",
    "ax.tricontour(coord_df_0_convert[\"x\"], coord_df_0_convert[\"y\"], coord_df_0_convert['mean'], levels=levels, colors=['0', '0.125', '0.25', '0.375',\n",
    "                                                                                                                   '0.5', '0.675', '0.75', '0.875', '1'], \n",
    "              linestyles='dashdot',\n",
    "              linewidths=linewidths)\n",
    "\n",
    "plt.title(\"Mean Flowdepth Contour\")\n",
    "plt.colorbar(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0e68fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.add_children(folium.raster_layers.ImageOverlay(dataframe, opacity=0.5,\n",
    "                                                 bounds = [[-40.88576, 175.03205], [-40.87013, 175.05304]]))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb6f9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import folium\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf3af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = gpd.datasets.get_path('nybb')\n",
    "df = gpd.read_file(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c8fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(figsize=(6, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19158153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use WGS 84 (epsg:4326) as the geographic coordinate system\n",
    "df = df.to_crs(epsg=4326)\n",
    "print(df.crs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e22d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = folium.Map(location=[40.70, -73.94], zoom_start=10, tiles='CartoDB positron')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d2cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, r in df.iterrows():\n",
    "    # Without simplifying the representation of each borough,\n",
    "    # the map might not be displayed\n",
    "    sim_geo = gpd.GeoSeries(r['geometry']).simplify(tolerance=0.001)\n",
    "#     geo_j = sim_geo.to_json()\n",
    "#     geo_j = folium.GeoJson(data=geo_j,\n",
    "#                            style_function=lambda x: {'fillColor': 'orange'})\n",
    "#     folium.Popup(r['BoroName']).add_to(geo_j)\n",
    "#     geo_j.add_to(f)\n",
    "# f\n",
    "    print(sim_geo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22a4156",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa88db",
   "metadata": {},
   "source": [
    "### Fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f1ae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona\n",
    "from shapely.geometry import shape\n",
    "\n",
    "polygons_check = fiona.open(fr\"{unrotated_path}\\shapefile_45\\flowdepth_unrotated_45_at_5.shp\")\n",
    "values_polygons_check = [poly for poly in polygons_check]\n",
    "\n",
    "points_check = fiona.open(fr\"Z:\\Trial\\Example\\Point_clip.shp\")\n",
    "values_points_check = [pt for pt in points_check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c31afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for position, polygon in enumerate(values_polygons_check):\n",
    "    print(shape(polygon['geometry']).bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eb0a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in idx.intersection(point.coords[0]):\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a259ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "point.intersects(shape(values_polygons_check[j]['geometry']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4b1a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_polygons_check[8244][\"properties\"]['depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1af009",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape(values_polygons_check[8244]['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f72abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pts in enumerate(values_points_check):\n",
    "    point = shape(pts['geometry'])\n",
    "    print(point.coords[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aedac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from rtree import index\n",
    "idx = index.Index()\n",
    "for position, polygon in enumerate(values_polygons_check):\n",
    "    idx.insert(position, shape(polygon['geometry']).bounds)\n",
    "a = []\n",
    "for i, pts in enumerate(values_points_check):\n",
    "    point = shape(pts['geometry'])\n",
    "    \n",
    "    for j in idx.intersection(point.coords[0]):\n",
    "        if point.within(shape(values_polygons_check[j]['geometry'])):\n",
    "#             print(\"index i - point\", i, \":\", point)\n",
    "#             print(\"index j - polygon\", j, \":\", shape(values_polygons_check[j]['geometry']))\n",
    "#             print(point.intersects(shape(values_polygons_check[j]['geometry'])))\n",
    "            print(values_polygons_check[j][\"properties\"]['depth'])\n",
    "            a.append(values_polygons_check[j][\"properties\"]['depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2350cb8",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f22bcf",
   "metadata": {},
   "source": [
    "### Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8186f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if it's correct unrotation\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_dataset(dataset_plot, clip_value=True):\n",
    "    '''Plotting\n",
    "    '''\n",
    "    if clip_value:\n",
    "        fig, axes = plt.subplots(figsize=(20,20))\n",
    "        plot = plt.scatter(dataset_plot[:,0],\n",
    "                           dataset_plot[:,1],\n",
    "                           c=dataset_plot[:,2], cmap=\"Blues\", s=200)\n",
    "        fig.colorbar(plot)    \n",
    "    else:\n",
    "        fig, axes = plt.subplots(figsize=(20,20))\n",
    "        plot = plt.scatter(dataset_plot[:,0],\n",
    "                           dataset_plot[:,1],\n",
    "                           c=dataset_plot[:,2], cmap=\"Blues\", s=200)\n",
    "        fig.colorbar(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9e275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset(zero_raster_clip, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geofabrics34]",
   "language": "python",
   "name": "conda-env-geofabrics34-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83d962a3",
   "metadata": {},
   "source": [
    "# 0. PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b762fb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary packages\n",
    "# Package for downloading data from open topography website\n",
    "# Both geoapis and geofabrics to read the boundaries and download the files from open topography API\n",
    "import geoapis\n",
    "import geoapis.lidar\n",
    "import geofabrics\n",
    "import glob                                                    # For getting all files' names in a certain path\n",
    "\n",
    "# Package for reading las/laz file and handling lidar point cloud\n",
    "import numpy as np                                             # For all calculation and data array/matrices manipulation\n",
    "import pdal                                                    # For reading and writing las/laz file and handling lidar point cloud data\n",
    "\n",
    "# Packages for transformation\n",
    "from numba import njit, guvectorize, float64                   # For speeding up the time of the code running\n",
    "\n",
    "# Packages for converting lidar point cloud las/laz file into DEM raster netcdf file\n",
    "import os                                                      # For manipulating the directory path (create/change/move folders) and to execute commands\n",
    "import pathlib                                                 # For manipulating the directory path\n",
    "from pathlib import Path                                       # For creating folders\n",
    "import shapely.geometry                                        # For creating a polygon object\n",
    "import geopandas                                               # For creating a series to store the shapely geometry object\n",
    "import shutil                                                  # For copying file/folder\n",
    "import xarray                                                  # For creating and manipulating an array of raster\n",
    "import rioxarray                                               # For manipulating spatial data under xarray array format (open and write .nc/.tiff files and set crs)\n",
    "import json                                                    # For creating json text data format\n",
    "from geofabrics import processor                               # For executing the command of converting lidar point cloud into a DEM raster\n",
    "\n",
    "# Packages for unrotating and untranslating\n",
    "from osgeo import gdal                                         # For manipulating rasters (calculating centers)\n",
    "import rasterio.features                                       # For vectorising features in array\n",
    "from shapely.geometry import shape                             # For manipulating spatial information (geometry) under GeoJSON format\n",
    "from shapely.geometry import Polygon                           # For creating polygons to change raster values\n",
    "import geopandas as gpd                                        # For manupulating shape files\n",
    "from pyogrio import write_dataframe                            # For writing out shape file (twice faster than geopandas)\n",
    "\n",
    "# Package for manipulating spatial data\n",
    "import rasterio                                                # For reading and manipulating spatial data\n",
    "\n",
    "# Package for running software from outside of Python (commandline or PowerShell)\n",
    "import subprocess                                              # For mainly running BG_Flood model\n",
    "\n",
    "# Package for timing steps\n",
    "import time                                                    # For timing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c96cd844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all warnings\n",
    "# Reference: https://numba.pydata.org/numba-doc/dev/reference/deprecation.html#suppressing-deprecation-warnings\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning, NumbaWarning\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "990c54c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the name you have just created for the drive\n",
    "drive = \"S\"\n",
    "main_folder = \"MULTIPLE_TILES_Monte_Carlo_BGFLOOD\"\n",
    "version = \"version_1\"\n",
    "header = f\"{drive}:\\\\{main_folder}\\\\{version}\"\n",
    "\n",
    "# Create header path\n",
    "pathlib.Path(f\"{header}\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e145ce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move into the folder where all the data are stored\n",
    "# Reference: https://social.technet.microsoft.com/Forums/en-US/cef10e47-2fe1-482b-be62-ae74116a4e5f/mapped-network-drive-is-offline?forum=win10itpronetworking\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(f\"{header}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "32bad674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create paths\n",
    "\n",
    "#--------------------------------------------------- This is for TRANSFORMATION PART -------------------------------------------\n",
    "\n",
    "\n",
    "# 0_open_topography: Folder stores ownloaded lidar point cloud data from open topography website\n",
    "# Reference: https://portal.opentopography.org/datasets\n",
    "original_lidar_path = f\"{header}\\\\0_open_topography\"\n",
    "\n",
    "# 1_modified_lidar: Folder stores ownloaded lidar point cloud data from open topography website\n",
    "modified_lidar_path = f\"{header}\\\\1_modified_lidar\"\n",
    "\n",
    "# 2_transformation: Folder stores transformed lidar point cloud data\n",
    "rotated_lidar_path = f\"{header}\\\\2_transformation\\\\rotated_lidar\"\n",
    "translated_lidar_path = f\"{header}\\\\2_transformation\\\\translated_lidar\"\n",
    "combined_lidar_path = f\"{header}\\\\2_transformation\\\\combined_lidar\"\n",
    "\n",
    "# 3_dem_raster: Folder stores DEM rasters\n",
    "# Rotation\n",
    "# Netcdf\n",
    "rotated_nc_raster_path = f\"{header}\\\\3_dem_raster\\\\rotated_dem_raster\\\\rot_dem_raster\\\\rot_netcdf\"\n",
    "# GeoTiff\n",
    "rotated_tiff_raster_path = f\"{header}\\\\3_dem_raster\\\\rotated_dem_raster\\\\rot_dem_raster\\\\rot_tiff\"\n",
    "# Ascii\n",
    "rotated_asc_raster_path = f\"{header}\\\\3_dem_raster\\\\rotated_dem_raster\\\\rot_dem_raster\\\\rot_ascii\"\n",
    "rotated_elements_path = f\"{header}\\\\3_dem_raster\\\\rotated_dem_raster\\\\rot_elements\"\n",
    "\n",
    "# Translation\n",
    "# Netcdf\n",
    "translated_nc_raster_path = f\"{header}\\\\3_dem_raster\\\\translated_dem_raster\\\\tra_dem_raster\\\\tra_netcdf\"\n",
    "# GeoTiff\n",
    "translated_tiff_raster_path = f\"{header}\\\\3_dem_raster\\\\translated_dem_raster\\\\tra_dem_raster\\\\tra_tiff\"\n",
    "# Ascii\n",
    "translated_asc_raster_path = f\"{header}\\\\3_dem_raster\\\\translated_dem_raster\\\\tra_dem_raster\\\\tra_ascii\"\n",
    "translated_elements_path = f\"{header}\\\\3_dem_raster\\\\translated_dem_raster\\\\tra_elements\"\n",
    "\n",
    "# Combination\n",
    "# Netcdf\n",
    "combined_nc_raster_path = f\"{header}\\\\3_dem_raster\\\\combined_dem_raster\\\\com_dem_raster\\\\com_netcdf\"\n",
    "# GeoTiff\n",
    "combined_tiff_raster_path = f\"{header}\\\\3_dem_raster\\\\combined_dem_raster\\\\com_dem_raster\\\\com_tiff\"\n",
    "# Ascii\n",
    "combined_asc_raster_path = f\"{header}\\\\3_dem_raster\\\\combined_dem_raster\\\\com_dem_raster\\\\com_ascii\"\n",
    "combined_elements_path = f\"{header}\\\\3_dem_raster\\\\combined_dem_raster\\\\com_elements\"\n",
    "\n",
    "# 4_BG_Flood: Folder stores BG_Flood outputs and Flowdepth outputs\n",
    "# BG_Flood output\n",
    "rotated_BGoutput_path = f\"{header}\\\\4_BG_Flood\\\\BG_Flood_output\\\\rotation\\\\rotated_BGoutput\"\n",
    "translated_BGoutput_path = f\"{header}\\\\4_BG_Flood\\\\BG_Flood_output\\\\translation\\\\translated_BGoutput\"\n",
    "combined_BGoutput_path = f\"{header}\\\\4_BG_Flood\\\\BG_Flood_output\\\\combination\\\\combined_BGoutput\"\n",
    "\n",
    "# BG_Flood param\n",
    "rotated_BGparam_path = f\"{header}\\\\4_BG_Flood\\\\BG_Flood_output\\\\rotation\\\\rotated_BGparam\"\n",
    "translated_BGparam_path = f\"{header}\\\\4_BG_Flood\\\\BG_Flood_output\\\\translation\\\\translated_BGparam\"\n",
    "combined_BGparam_path = f\"{header}\\\\4_BG_Flood\\\\BG_Flood_output\\\\combination\\\\combined_BGparam\"\n",
    "\n",
    "# 5_flowdepth: Folder stores flowdepth extracted from BG-FLOOD output\n",
    "rotated_flowdepth_path = f\"{header}\\\\5_flowdepth\\\\rotated_flowdepth\"\n",
    "translated_flowdepth_path = f\"{header}\\\\5_flowdepth\\\\translated_flowdepth\"\n",
    "combined_flowdepth_path = f\"{header}\\\\5_flowdepth\\\\combined_flowdepth\"\n",
    "\n",
    "# 6_un_transformation: Folder stores un-transformed raster\n",
    "# un_rotation\n",
    "unrotated_crs_path = f\"{header}\\\\6_un_transformation\\\\un_rotation\\\\unrotated_crs\"\n",
    "unrotated_path = f\"{header}\\\\6_un_transformation\\\\un_rotation\\\\unrotated_shp\"\n",
    "\n",
    "# un_translation\n",
    "untranslated_crs_path = f\"{header}\\\\6_un_transformation\\\\un_translation\\\\untranslated_crs\"\n",
    "untranslated_path = f\"{header}\\\\6_un_transformation\\\\un_translation\\\\untranslated_shp\"\n",
    "\n",
    "# un_combination\n",
    "uncombined_crs_path = f\"{header}\\\\6_un_transformation\\\\un_combination\\\\uncombined_crs\"\n",
    "uncombined_path = f\"{header}\\\\6_un_transformation\\\\un_combination\\\\uncombined_shp\"\n",
    "\n",
    "#--------------------------------------------------- This is for ANALYSIS PART ------------------------------------------------\n",
    "\n",
    "# 7_results: Folder stores mean and standard deviation\n",
    "# Un_rotation\n",
    "csv_rotation = f\"{header}\\\\7_results\\\\un_rotation\\\\unrot_csv\"\n",
    "raster_rotation = f\"{header}\\\\7_results\\\\un_rotation\\\\unrot_raster\"\n",
    "polygon_rotation = f\"{header}\\\\7_results\\\\un_rotation\\\\unrot_polygon\"\n",
    "plot_rotation = f\"{header}\\\\7_results\\\\un_rotation\\\\unrot_plot\"\n",
    "\n",
    "# Un_translation\n",
    "csv_translation = f\"{header}\\\\7_results\\\\un_translation\\\\untra_csv\"\n",
    "raster_translation = f\"{header}\\\\7_results\\\\un_trfanslation\\\\untra_raster\"\n",
    "polygon_translation = f\"{header}\\\\7_results\\\\un_translation\\\\untra_polygon\"\n",
    "plot_translation = f\"{header}\\\\7_results\\\\un_translation\\\\untra_plot\"\n",
    "\n",
    "# Un_combination\n",
    "csv_combination = f\"{header}\\\\7_results\\\\un_combination\\\\uncom_csv\"\n",
    "raster_combination = f\"{header}\\\\7_results\\\\un_combination\\\\uncom_raster\"\n",
    "polygon_combination = f\"{header}\\\\7_results\\\\un_combination\\\\uncom_polygon\"\n",
    "plot_combination = f\"{header}\\\\7_results\\\\un_combination\\\\uncom_plot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a9ae791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all paths\n",
    "neccessary_files = [\n",
    "    # 0_open_topography\n",
    "    original_lidar_path,\n",
    "    \n",
    "    # 1_modified_lidar\n",
    "    modified_lidar_path,\n",
    "    \n",
    "    # 2_transformation\n",
    "    rotated_lidar_path,\n",
    "    translated_lidar_path,\n",
    "    combined_lidar_path,\n",
    "    \n",
    "    # 3_dem_raster\n",
    "    # Rotation\n",
    "    rotated_nc_raster_path,\n",
    "    rotated_tiff_raster_path,\n",
    "    rotated_asc_raster_path,\n",
    "    rotated_elements_path,\n",
    "    \n",
    "    # Translation\n",
    "    translated_nc_raster_path,\n",
    "    translated_tiff_raster_path,\n",
    "    translated_asc_raster_path,\n",
    "    translated_elements_path,\n",
    "    \n",
    "    # Combination\n",
    "    combined_nc_raster_path,\n",
    "    combined_tiff_raster_path,\n",
    "    combined_asc_raster_path,\n",
    "    combined_elements_path,\n",
    "    \n",
    "    # 4_BG_FLOOD\n",
    "    rotated_BGoutput_path,\n",
    "    translated_BGoutput_path,\n",
    "    combined_BGoutput_path,\n",
    "    \n",
    "    # 5_flowdepth\n",
    "    rotated_flowdepth_path,\n",
    "    translated_flowdepth_path,\n",
    "    combined_flowdepth_path,\n",
    "    \n",
    "    # 6_un_transformation\n",
    "    # Unrotation\n",
    "    unrotated_crs_path,\n",
    "    unrotated_path,\n",
    "    \n",
    "    # Untranslation\n",
    "    untranslated_crs_path,\n",
    "    untranslated_path,\n",
    "    \n",
    "    # Uncombination\n",
    "    uncombined_crs_path,\n",
    "    uncombined_path,\n",
    "    \n",
    "    # 7_results\n",
    "    # Unrotation\n",
    "    csv_rotation,\n",
    "    raster_rotation,\n",
    "    polygon_rotation,\n",
    "    plot_rotation,\n",
    "    \n",
    "    # Untranslation\n",
    "    csv_translation,\n",
    "    raster_translation,\n",
    "    polygon_translation,\n",
    "    plot_translation,\n",
    "    \n",
    "    # Uncombination\n",
    "    csv_combination,\n",
    "    raster_combination,\n",
    "    polygon_combination,\n",
    "    plot_combination\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f27772a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder\n",
    "# Reference: https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory-in-python\n",
    "for each_folder in neccessary_files:\n",
    "    pathlib.Path(f\"{each_folder}\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46594d2a",
   "metadata": {},
   "source": [
    "# 1. DOWNLOADING LIDAR POINTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b27bfc9",
   "metadata": {},
   "source": [
    "## 1.1. Downloading LiDAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b3486947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to download las/laz files from open topography\n",
    "def download_lidar(boundary_coordinates_func, lidar_number):\n",
    "    '''This function is to download las/laz files from Open Topography\n",
    "    \n",
    "    Arguments:\n",
    "                boundary_coordinates_func:\n",
    "                                        A list of xmin, ymin, xmax, ymax of rectangular boundary\n",
    "                lidar_number:\n",
    "                                        Ordinal number of lidar folder\n",
    "    '''\n",
    "    # Get crs\n",
    "    h_crs = 2193\n",
    "    v_crs = 7839\n",
    "    \n",
    "    # Get xmin, ymin, xmax, ymax of rectangular boundary\n",
    "    x0_func = boundary_coordinates_func[0]\n",
    "    y0_func = boundary_coordinates_func[1]\n",
    "    x1_func = boundary_coordinates_func[2]\n",
    "    y1_func = boundary_coordinates_func[3]\n",
    "    \n",
    "    # Assign those coordinates into shapely geometry polygon and store under geopandas format\n",
    "    lidar_bound_coordinates = shapely.geometry.Polygon([(x0_func, y0_func), (x1_func, y0_func), (x1_func, y1_func), (x0_func, y1_func)])\n",
    "    lidar_bound_coordinates = geopandas.GeoSeries([lidar_bound_coordinates])\n",
    "    lidar_bound_coordinates = lidar_bound_coordinates.set_crs(h_crs)\n",
    "    \n",
    "    # Create lidar folder to store neccessary files\n",
    "    lidar_folder_dir = pathlib.Path(os.getcwd()) / pathlib.Path(f\"{original_lidar_path}\\\\lidar_{lidar_number}\")\n",
    "    if not os.path.exists(lidar_folder_dir):\n",
    "        os.mkdir(lidar_folder_dir)\n",
    "    \n",
    "    # Create test file to store test_catchment.zip file (one of neccessary files for downloading las/laz files)\n",
    "    test_dir = pathlib.Path(os.getcwd()) / pathlib.Path(f\"{original_lidar_path}\\\\lidar_{lidar_number}\\\\test\")\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.mkdir(test_dir)\n",
    "        \n",
    "    # Create test_catchment.zip\n",
    "    test_path = pathlib.Path(f\"{original_lidar_path}\\\\lidar_{lidar_number}\\\\test\\\\test_catchment\")\n",
    "    lidar_bound_coordinates.to_file(test_path)\n",
    "    shutil.make_archive(base_name=test_path, format='zip', root_dir=test_path)\n",
    "    shutil.rmtree(test_path)\n",
    "    lidar_bound_path = pathlib.Path(str(test_path) + \".zip\")\n",
    "    \n",
    "    # Create polygon\n",
    "    lidar_polygon = geopandas.read_file(lidar_bound_path)\n",
    "    lidar_polygon.to_crs(h_crs)\n",
    "    \n",
    "    # Download lidar\n",
    "    lidar_fetcher = geoapis.lidar.OpenTopography(cache_path = fr\"{original_lidar_path}\\\\lidar_{lidar_number}\",\n",
    "                                                 search_polygon = lidar_polygon,\n",
    "                                                 verbose = True)\n",
    "    lidar_fetcher.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8125313f",
   "metadata": {},
   "source": [
    "## 1.2. Modifying LiDAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d06f04c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_lidar(lidar_number, method=\"statistical\", parameter1=100, parameter2=40):\n",
    "    '''This function is to modify the LiDAR data before DEM generation process. \n",
    "       In this process, the noise/outliers in LiDAR data will be removed by one of two selected methods and boundary range.\n",
    "       Method 1: Statistical outlier methods requires two parameters - mean_k (parameter1) and multiplier (parameter2)\n",
    "       Method 2: Radius method requires two parameters - radius (parameter1) and min_k (parameter2)\n",
    "       Boundary range: There are still some noise/outliers that cannot be caught properly by the seleted method\n",
    "                       and thus another boundary range should be developed to remove them. The range is set from -150 to 3000 (meters)\n",
    "       Please refer the reference part for more information\n",
    "       \n",
    "    Reference: https://pdal.io/stages/filters.outlier.html\n",
    "               https://pdal.io/pipeline.html\n",
    "               https://pdal.io/apps/translate.html\n",
    "               \n",
    "    Arguments:\n",
    "               lidar_number:\n",
    "                                Ordinal number of lidar folder\n",
    "               method:\n",
    "                                Name of the method - \"statistical\" and \"radius\"\n",
    "                                The default is \"statistical\"\n",
    "               parameter1:\n",
    "                                if \"statistical\", parameter1 is figure for \"mean_k\", else it is figure for \"radius\".\n",
    "                                The default is 100 for \"mean_k\"\n",
    "               parameter2:\n",
    "                                if \"statistical\", parameter2 is figure for \"multiplier\", else it is figure for \"min_k\".\n",
    "                                The default is 40 for \"multiplier\"\n",
    "    \n",
    "    '''\n",
    "    # Create folder for storing modified LiDAR data\n",
    "    pathlib.Path(fr\"{modified_lidar_path}\\\\lidar_{lidar_number}\\\\Wellington_2013\").mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get lists of tile paths and names\n",
    "    # Tile paths\n",
    "    list_tile_paths = glob.glob(f\"{original_lidar_path}\\\\lidar_{lidar_number}\\\\Wellington_2013\\*.laz\")\n",
    "    # Tile names\n",
    "    length_list = len(list_tile_paths)\n",
    "    list_tile_names = [os.path.basename(list_tile_paths[name]) for name in range(length_list)]\n",
    "    \n",
    "    # Check and remove noise/outliers\n",
    "    for each_tile in range(length_list):\n",
    "        # Start timing modifying\n",
    "        start_modifying = time.time()\n",
    "        \n",
    "        # Set the path of input file\n",
    "        input_file_func = list_tile_paths[each_tile]\n",
    "        \n",
    "        # Set the path of output file\n",
    "        output_filename = list_tile_names[each_tile]\n",
    "        output_file_func = fr\"{modified_lidar_path}\\\\lidar_{lidar_number}\\\\Wellington_2013\\\\{output_filename}\"\n",
    "        \n",
    "        # Develop method under dictionary format with string contents\n",
    "        if method == \"statistical\":\n",
    "            method_content = {\n",
    "                \"type\": \"filters.outlier\",\n",
    "                \"method\": \"statistical\",\n",
    "                \"mean_k\": parameter1,\n",
    "                \"multiplier\": parameter2\n",
    "            }\n",
    "        else:\n",
    "            method_content = {\n",
    "                \"type\": \"filters.outlier\",\n",
    "                \"method\": \"radius\",\n",
    "                \"radius\": parameter1,\n",
    "                \"min_k\": parameter2\n",
    "            }\n",
    "        \n",
    "        # Set instruction to remove noise/outliers under json format\n",
    "        remove_outliers_json = [\n",
    "            input_file_func,\n",
    "            method_content,\n",
    "            {\n",
    "                \"type\": \"filters.range\",\n",
    "                \"limits\": \"Classification![7:7],Z[-100:1000]\"\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"writers.las\",\n",
    "                \"filename\": f\"{output_file_func}\",\n",
    "                \"compression\": \"laszip\"\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        remove_outliers_instruction = {\"pipeline\": remove_outliers_json}\n",
    "        \n",
    "        # Execute the command\n",
    "        pdal_remove_outliers = pdal.Pipeline(json.dumps(remove_outliers_instruction))\n",
    "        pdal_remove_outliers.execute()\n",
    "        \n",
    "        # End timing modifying\n",
    "        end_modifying = time.time()\n",
    "        \n",
    "        # Separator\n",
    "        modifying_time = end_modifying - start_modifying\n",
    "        print(\"* Tile\", each_tile, \"-\", list_tile_names[each_tile], \":                      \",\n",
    "              modifying_time/60)\n",
    "        \n",
    "    # Copy the tile index\n",
    "    shutil.copy2(fr\"{original_lidar_path}\\\\lidar_{lidar_number}\\\\Wellington_2013\\\\Wellington_2013_TileIndex.zip\",\n",
    "                 fr\"{modified_lidar_path}\\\\lidar_{lidar_number}\\\\Wellington_2013\\\\Wellington_2013_TileIndex.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd60b91f",
   "metadata": {},
   "source": [
    "# 2. REFERENCE DEM RASTER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7651f32d",
   "metadata": {},
   "source": [
    "## 2.1. Padding box coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7529185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate the distance of two points\n",
    "def distance_calculation(point_1, point_2):\n",
    "    '''This function is to calculate the distance of two points\n",
    "    Reference: https://orion.math.iastate.edu/dept/links/formulas/form2.pdf\n",
    "    Arguments:\n",
    "                point_1:\n",
    "                        First point\n",
    "                point_2:\n",
    "                        Second point\n",
    "    Returns:\n",
    "                distance:\n",
    "                        Euclidean distance between two points \n",
    "    '''\n",
    "    # Calculating the euclidean distance between two points\n",
    "    distance = np.sqrt(np.power((point_1[0] - point_2[0]),2) + np.power((point_1[1] - point_2[1]),2))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1190b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_divisible_number(changed_number, divisible_number=16):\n",
    "    '''This function is to find the padding number that is divisible by 16\n",
    "    Reference: https://stackoverflow.com/questions/8002217/how-do-you-check-whether-a-number-is-divisible-by-another-number-python\n",
    "    Arguments:\n",
    "                changed_number:\n",
    "                                Number that needs changing into the number that can be divisible by 16\n",
    "                divisible_number:\n",
    "                                Default is 16\n",
    "    Return:\n",
    "                changed_number:\n",
    "                                A new number that can divisible by 16\n",
    "    '''\n",
    "    # Get the number that is divisible by 16\n",
    "    while changed_number % divisible_number != 0:\n",
    "        changed_number = changed_number + 1\n",
    "        \n",
    "    return changed_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cf0e9415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_combination(coordinates_func, transformation_selection, addition):\n",
    "    '''This function is to create the coordinates of padding/grid size\n",
    "    Argument:\n",
    "                coordinates_func:\n",
    "                                        A list of xmin, ymin, xmax, ymax.\n",
    "                transformation_selection:\n",
    "                                        \"r\" means rotation\n",
    "                                        \"t\" means translation\n",
    "                                        \"c\" means combination\n",
    "                addition:\n",
    "                                        A number used to extend the padding\n",
    "                            \n",
    "    Returns:\n",
    "                padding_func:\n",
    "                                        A list of x min, x max, y min and y max\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        transformed_nc_raster_path = rotated_nc_raster_path\n",
    "    elif transformation_selection == 't':\n",
    "        transformed_nc_raster_path = translated_nc_raster_path\n",
    "    else:\n",
    "        transformed_nc_raster_path = combined_nc_raster_path\n",
    "            \n",
    "    x_min = coordinates_func[0]\n",
    "    y_min = coordinates_func[1]\n",
    "    x_max = coordinates_func[2]\n",
    "    y_max = coordinates_func[3]\n",
    "\n",
    "    center_x_func = ((x_min + x_max)/2)\n",
    "    center_y_func = ((y_min + y_max)/2)\n",
    "    center_padding_func = np.array([center_x_func, center_y_func])\n",
    "\n",
    "    # Calculate the radius\n",
    "    radius = distance_calculation(np.array([x_min, y_min]), center_padding_func) # Choose randomly a corner coordinates of rectangle point cloud to calculate the distance with center point\n",
    "    \n",
    "    # Get the coordinates of middle points of 4 sides of the rectangle point cloud\n",
    "    middle_point_1 = np.array([x_min, center_y_func])\n",
    "    middle_point_2 = np.array([center_x_func, y_max])\n",
    "    middle_point_3 = np.array([x_max, center_y_func])\n",
    "    middle_point_4 = np.array([center_x_func, y_min])\n",
    "    \n",
    "    # Calculate the distances between these points and the center point\n",
    "    distance_center_1 = distance_calculation(middle_point_1, center_padding_func)\n",
    "    distance_center_2 = distance_calculation(middle_point_2, center_padding_func)\n",
    "    distance_center_3 = distance_calculation(middle_point_3, center_padding_func)\n",
    "    distance_center_4 = distance_calculation(middle_point_4, center_padding_func)\n",
    "    \n",
    "    # Calculate the distances between the above middle points and the middle points of 4 sides of the padding\n",
    "    distance_1 = radius - distance_center_1\n",
    "    distance_2 = radius - distance_center_2\n",
    "    distance_3 = radius - distance_center_3\n",
    "    distance_4 = radius - distance_center_4\n",
    "    \n",
    "    # Convert into numbers which will be divisible by 16\n",
    "    distance_padding_1 = get_divisible_number(np.ceil(distance_1))\n",
    "    distance_padding_2 = get_divisible_number(np.ceil(distance_2))\n",
    "    distance_padding_3 = get_divisible_number(np.ceil(distance_3))\n",
    "    distance_padding_4 = get_divisible_number(np.ceil(distance_2))\n",
    "    \n",
    "    # Calculate the coordinates of the middle points of 4 sides of the padding\n",
    "    padding_middle_point_1 = np.array((middle_point_1[0] - distance_padding_1, center_y_func))\n",
    "    padding_middle_point_2 = np.array((center_x_func, middle_point_2[1] + distance_padding_2))\n",
    "    padding_middle_point_3 = np.array((middle_point_3[0] + distance_padding_3, center_y_func))\n",
    "    padding_middle_point_4 = np.array((center_x_func, middle_point_4[1] - distance_padding_4))\n",
    "    \n",
    "    # Calculate the coordinates of 4 corners of the padding\n",
    "    padding_x_min = np.min(np.array([padding_middle_point_1[0],\n",
    "                                     padding_middle_point_2[0],\n",
    "                                     padding_middle_point_3[0],\n",
    "                                     padding_middle_point_4[0]])) - addition\n",
    "\n",
    "    padding_x_max = np.max(np.array([padding_middle_point_1[0],\n",
    "                                     padding_middle_point_2[0],\n",
    "                                     padding_middle_point_3[0],\n",
    "                                     padding_middle_point_4[0]])) + addition\n",
    "\n",
    "    padding_y_min = np.min(np.array([padding_middle_point_1[1],\n",
    "                                     padding_middle_point_2[1],\n",
    "                                     padding_middle_point_3[1],\n",
    "                                     padding_middle_point_4[1]])) - addition\n",
    "\n",
    "    padding_y_max = np.max(np.array([padding_middle_point_1[1],\n",
    "                                     padding_middle_point_2[1],\n",
    "                                     padding_middle_point_3[1],\n",
    "                                     padding_middle_point_4[1]])) + addition\n",
    "    padding_func = [padding_x_min, padding_y_min, padding_x_max, padding_y_max]\n",
    "    \n",
    "    return padding_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fea964",
   "metadata": {},
   "source": [
    "## 2.2. Reference DEM raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a45a6e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to create a DEM raster from transformed lidar data\n",
    "def dem_raster_reference(transformation_selection, filename_lidar_opentopo, padding_func, padding=True):\n",
    "    ''' This function is to create a raster file from a las/laz file\n",
    "    \n",
    "    Arguments:\n",
    "                transformation_selection:\n",
    "                                            \"r\" means rotation\n",
    "                                            \"t\" means translation\n",
    "                                            \"c\" means combination\n",
    "                filename_lidar_opentopo:\n",
    "                                            Name of the folder storing LiDAR data downloaded from Opentopography\n",
    "                padding_func:\n",
    "                                            A list of x min, x max, y min and y max\n",
    "                padding:\n",
    "                                            if True, padding, else, no padding. Default is True\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        transformed_lidar_path = rotated_lidar_path\n",
    "        nc_raster_path_func = rotated_nc_raster_path\n",
    "        elements_path_func = rotated_elements_path\n",
    "        transformed = \"rotated\"\n",
    "    elif transformation_selection == 't':\n",
    "        transformed_lidar_path = translated_lidar_path\n",
    "        nc_raster_path_func = translated_nc_raster_path\n",
    "        elements_path_func = translated_elements_path\n",
    "        transformed = \"translated\"\n",
    "    else:\n",
    "        transformed_lidar_path = combined_lidar_path\n",
    "        nc_raster_path_func = combined_nc_raster_path\n",
    "        elements_path_func = combined_elements_path\n",
    "        transformed = \"combined\"\n",
    "    \n",
    "    # Name of output\n",
    "    if padding:\n",
    "        output_name = \"generated_dem_reference.nc\"\n",
    "        catchment_boundary = \"catchment_boundary_reference\"\n",
    "    else:\n",
    "        output_name = \"generated_dem_no_padding.nc\"\n",
    "        catchment_boundary = \"catchment_boundary_no_padding\"\n",
    "    \n",
    "    # Set crs\n",
    "    h_crs = 2193\n",
    "    v_crs = 7839\n",
    "    resolution = 10\n",
    "    \n",
    "    # Create folder for storing data materials\n",
    "    data_dir = pathlib.Path(os.getcwd()) / pathlib.Path(f\"{elements_path_func}\\\\data_{transformed}_ref\")\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.mkdir(data_dir)\n",
    "    \n",
    "    # Bounding box\n",
    "    x0 = padding_func[0]; y0 = padding_func[1]; x1 = padding_func[2]; y1 = padding_func[3];\n",
    "    catchment = shapely.geometry.Polygon([(x0, y0), (x1, y0), (x1, y1), (x0, y1)])\n",
    "    catchment = geopandas.GeoSeries([catchment])\n",
    "    catchment = catchment.set_crs(h_crs)\n",
    "\n",
    "    catchment_path = pathlib.Path(f\"{elements_path_func}\\\\data_{transformed}_ref\\\\{catchment_boundary}\")\n",
    "    catchment.to_file(catchment_path)\n",
    "    shutil.make_archive(base_name=catchment_path, format='zip', root_dir=catchment_path)\n",
    "    shutil.rmtree(catchment_path)\n",
    "\n",
    "    \n",
    "    # Design JSON instructions\n",
    "    instructions = {\"instructions\":\n",
    "                    {\n",
    "                        \"output\": {\n",
    "                            \"crs\": {\n",
    "                                \"horizontal\": h_crs,\n",
    "                                \"vertical\": v_crs\n",
    "                            },\n",
    "                            \"grid_params\": {\n",
    "                                \"resolution\": resolution\n",
    "                            }\n",
    "                        },\n",
    "                        \"apis\": {\n",
    "                            \"open_topography\": {\n",
    "                                \"Wellington_2013\": {\n",
    "                                    \"crs\": {\n",
    "                                        \"horizontal\": h_crs,\n",
    "                                        \"vertical\": v_crs\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"processing\": {\n",
    "                            \"chunk_size\": 100,\n",
    "                            \"number_of_cores\": 4\n",
    "                        },\n",
    "                        \"data_paths\": {\n",
    "                            \"local_cache\": f\"{modified_lidar_path}\\\\{filename_lidar_opentopo}\",\n",
    "                            \"catchment_boundary\": f\"{elements_path_func}\\\\data_{transformed}_ref\\\\{catchment_boundary}.zip\",\n",
    "                            \"land\": f\"{elements_path_func}\\\\data_{transformed}_ref\\\\{catchment_boundary}.zip\",\n",
    "                            \"dense_dem_extents\": f\"{elements_path_func}\\\\data_{transformed}_ref\\\\extents.geojson\",\n",
    "                            \"result_dem\": f\"{nc_raster_path_func}\\\\{output_name}\"\n",
    "                        },\n",
    "                        \"general\": {\n",
    "                            \"set_dem_shoreline\": True,\n",
    "                            \"drop_offshore_lidar\": True,\n",
    "                            \"keep_only_ground_lidar\": False,\n",
    "                            \"interpolation_missing_values\": True\n",
    "                        }\n",
    "                    }\n",
    "                   }\n",
    "    \n",
    "    \n",
    "    # Create DEM raster\n",
    "    runner = processor.DemGenerator(instructions)\n",
    "    runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf4179f",
   "metadata": {},
   "source": [
    "# 3. TRANSFORMATION PROCESS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00146394",
   "metadata": {},
   "source": [
    "## 3.1. Reading las/laz files of tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c63f5704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to read las/laz file\n",
    "def read_las_file(filename_tile):\n",
    "    ''' This function is to read the las/las file into arrays\n",
    "    Reference: https://pythonhosted.org/laspy/file.html\n",
    "               https://pythonhosted.org/laspy/tut_part_1.html\n",
    "    Arguments:\n",
    "                filename_tile:\n",
    "                                Name of las/laz files of tiles\n",
    "\n",
    "    Returns:\n",
    "                points_classification_func:\n",
    "                                An array includes classification information (int format)\n",
    "                coordinates_func:\n",
    "                                An array includes x, y, z coordinates values of points as rows\n",
    "    '''\n",
    "    # Set up horizontal and vertical crs\n",
    "    h_crs = 2193\n",
    "    v_crs = 7839\n",
    "\n",
    "    \n",
    "    # Write las/las file into arrays\n",
    "    pdal_pipeline_instructions = [{\"type\":\"readers.las\", \"filename\": fr\"{filename_tile}\"},\n",
    "                                  {\"type\":\"filters.reprojection\",\"in_srs\":f\"EPSG:{h_crs}+{v_crs}\",\n",
    "                                   \"out_srs\":f\"EPSG:{h_crs}+{v_crs}\"}]\n",
    "\n",
    "    pdal_pipeline = pdal.Pipeline(json.dumps(pdal_pipeline_instructions))\n",
    "    pdal_pipeline.execute()\n",
    "\n",
    "    # Call out arrays\n",
    "    points_full_func = pdal_pipeline.arrays # note is shape [1,nx,ny]\n",
    "    \n",
    "    # Assign x, y , z (values in meters)\n",
    "    x_func = points_full_func[0][\"X\"]\n",
    "    y_func = points_full_func[0][\"Y\"]\n",
    "    z_func = points_full_func[0][\"Z\"]\n",
    "    \n",
    "    # Get classification\n",
    "    point_classification_func = points_full_func[0]['Classification']\n",
    "    \n",
    "    \n",
    "    # Write x, y, z into arrays with each row as (x, y, z) (meters as unit)\n",
    "    coordinates_func = np.vstack((x_func, y_func, z_func)).transpose().astype('float64')\n",
    "    \n",
    "    return point_classification_func, coordinates_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69bc555",
   "metadata": {},
   "source": [
    "## 3.2. Transformation method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d1233c",
   "metadata": {},
   "source": [
    "### 3.2.1. Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "24a4470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_calculation(transformation_selection, lidar=True):\n",
    "    '''This function is to calculate the center of reference DEM raster which will be used in the whole process\n",
    "    Reference: https://gis.stackexchange.com/questions/104362/how-to-get-extent-out-of-geotiff\n",
    "               https://rasterio.readthedocs.io/en/latest/quickstart.html\n",
    "    Arguments:\n",
    "                transformation_selection:\n",
    "                                        \"r\" means rotation\n",
    "                                        \"t\" means translation\n",
    "                                        \"c\" means combination\n",
    "                lidar:\n",
    "                                        True means doing rotation on LiDAR data\n",
    "                                        False means doing unrotation on model outputs\n",
    "    Return:\n",
    "                A tuple of x, y coordinates of center raster\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        transformed_nc_raster_path = rotated_nc_raster_path\n",
    "    elif transformation_selection == 't':\n",
    "        transformed_nc_raster_path = translated_nc_raster_path\n",
    "    else:\n",
    "        transformed_nc_raster_path = combined_nc_raster_path\n",
    "            \n",
    "    raster_reference_func = gdal.Open(fr\"{transformed_nc_raster_path}\\\\generated_dem_reference.nc\")\n",
    "    if lidar:\n",
    "        xmin, xpixel, _, ymax, _, ypixel = raster_reference_func.GetGeoTransform()\n",
    "        width, height = raster_reference_func.RasterXSize, raster_reference_func.RasterYSize\n",
    "        xmax = xmin + width * xpixel\n",
    "        ymin = ymax + height * ypixel\n",
    "        center_x_func = ((xmin + xmax)/2)\n",
    "        center_y_func = ((ymin + ymax)/2)\n",
    "        center_func = np.array([center_x_func, center_y_func])\n",
    "    else:\n",
    "        center_func = ((raster_reference_func.RasterXSize)/2, (raster_reference_func.RasterYSize)/2)\n",
    "    return center_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "529c6890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a command for guvectorize() decorator\n",
    "# In that, float64[:,:] stands for the format of the array and float64 stands for the format of other parameters\n",
    "# (m,n) signature stands for the matrix of the array and () signature stands for other parameters\n",
    "gu_rotation = guvectorize([(float64[:,:], float64, float64, float64, float64, float64[:,:])], '(m,n),(),(),(),()->(m,n)')\n",
    "\n",
    "# Create a point rotation function\n",
    "def point_rotation(coordinates_func, angle, center_x_func, center_y_func, clockwise, new_coordinates_func):\n",
    "    '''This function is to calculate the rotated coordinates of lidar data\n",
    "    Reference: https://www.youtube.com/watch?v=RqZH-7hlI48\n",
    "               https://stackoverflow.com/questions/14607640/rotating-a-vector-in-3d-space\n",
    "               https://stackoverflow.com/questions/5954603/transposing-a-1d-numpy-array\n",
    "               https://en.wikipedia.org/wiki/Rotation_matrix\n",
    "               https://math.stackexchange.com/questions/270194/how-to-find-the-vertices-angle-after-rotation\n",
    "               \n",
    "               https://github.com/numba/numba/issues/3312\n",
    "               https://numba.pydata.org/numba-doc/latest/user/vectorize.html\n",
    "               https://numba.pydata.org/numba-doc/latest/cuda/ufunc.html\n",
    "               http://numba.pydata.org/numba-doc/0.20.0/reference/compilation.html\n",
    "               http://numba.pydata.org/numba-doc/0.12/tutorial_numpy_and_numba.html\n",
    "               https://numba.pydata.org/numba-doc/dev/reference/types.html\n",
    "    Arguments:\n",
    "               coordinates_func:\n",
    "                                An array of the coordinates of the point will be rotated\n",
    "               angle: \n",
    "                                The value of angle to rotate\n",
    "               center_x_func and center_y_func:\n",
    "                                Values of the coordinates of center of the point cloud\n",
    "               clockwise:\n",
    "                                Rotating the points in clockwise (1) or anti_clockwise (0) directions\n",
    "               new_coordinates_func:\n",
    "                                A new array of rotated x, y, z coordinates values of a point\n",
    "    '''\n",
    "    # Convert degree to radian and calculate cosine and sine\n",
    "    radian = np.deg2rad(angle)\n",
    "    cosine = np.cos(radian)\n",
    "    sine = np.sin(radian)\n",
    "    \n",
    "    # Create a for loop to manipulate each row of the array\n",
    "    for i in range(coordinates_func.shape[0]):\n",
    "        # Do substraction with center coordinates\n",
    "        diff_x = coordinates_func[i, 0] - center_x_func\n",
    "        diff_y = coordinates_func[i, 1] - center_y_func\n",
    "\n",
    "        # Calculate the rotated point coordinates\n",
    "        if clockwise == 0:                                                                  # Rotating in anti-clockwise direction\n",
    "            new_coordinates_func[i, 0] = diff_x*cosine - diff_y*sine + center_x_func\n",
    "            new_coordinates_func[i, 1] = diff_x*sine + diff_y*cosine + center_y_func\n",
    "            new_coordinates_func[i, 2] = coordinates_func[i, 2]\n",
    "        else:                                                                               # Rotating in clockwise direction\n",
    "            new_coordinates_func[i, 0] = diff_x*cosine + diff_y*sine + center_x_func\n",
    "            new_coordinates_func[i, 1] = diff_x*(-sine) + diff_y*cosine + center_y_func\n",
    "            new_coordinates_func[i, 2] = coordinates_func[i, 2]\n",
    "\n",
    "# Wrapping function to map later\n",
    "wrapping_point_rotation = gu_rotation(point_rotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ea1088",
   "metadata": {},
   "source": [
    "### 3.2.2. Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4dba455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a command for guvectorize() decorator\n",
    "# In that, float64[:,:] stands for the format of the array and float64 stands for the format of other parameters\n",
    "# (m,n) signature stands for the matrix of the array and () signature stands for other parameters\n",
    "gu_translation = guvectorize([(float64[:,:], float64, float64, float64[:,:])], '(m,n),(),()->(m,n)')\n",
    "\n",
    "# Create a point translation function\n",
    "def point_translation(coordinates_func, x_translation_func, y_translation_func, new_coordinates_func):\n",
    "    '''This function is to calculate the translated coordinates of lidar data\n",
    "    Arguments:\n",
    "                coordinates_func:\n",
    "                                An array of the coordinates of the point will be rotated\n",
    "                x_translation and y_translation:\n",
    "                                Distances to translate x and y coordinates values\n",
    "                new_coordinates_func:\n",
    "                                A new array of translated x, y, z coordinates values of a point\n",
    "    '''\n",
    "    for i in range(coordinates_func.shape[0]):\n",
    "        new_coordinates_func[i, 0] = coordinates_func[i, 0] + x_translation_func\n",
    "        new_coordinates_func[i, 1] = coordinates_func[i, 1] + y_translation_func\n",
    "        new_coordinates_func[i, 2] = coordinates_func[i, 2]\n",
    "\n",
    "# Wrapping function to map later\n",
    "wrapping_point_translation = gu_translation(point_translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2653e761",
   "metadata": {},
   "source": [
    "## 3.3. Writing transformed las/laz files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9942b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to write transformed las/laz file\n",
    "def writing_las_file(transformation_selection, point_classification_func, number_simulation, transformed_array, filename_code):\n",
    "    '''This function is to create a new lidar las/laz file the same as the old lidar las/laz file with different coordinates\n",
    "    Arguments:\n",
    "                transformation_selection:\n",
    "                                            \"r\" means rotation\n",
    "                                            \"t\" means translation\n",
    "                                            \"c\" means combination\n",
    "                point_classification_func:\n",
    "                                            An array contains points' classification\n",
    "                number_simulation:\n",
    "                                            Ordinal number_simulation of simulation\n",
    "                transformed_array:\n",
    "                                            A transformed array\n",
    "                filename_code:\n",
    "                                            Code of file name (the same as original lidar tiles' names)\n",
    "    '''\n",
    "    # Set up horizontal and vertical crs\n",
    "    h_crs = 2193\n",
    "    v_crs = 7839\n",
    "    \n",
    "    # Output file\n",
    "    if transformation_selection == 'r':\n",
    "        pathlib.Path(fr\"{rotated_lidar_path}\\\\rotated_lidar_{number_simulation}\\\\Wellington_2013\").mkdir(parents=True, exist_ok=True)\n",
    "        outfile = fr\"{rotated_lidar_path}\\\\rotated_lidar_{number_simulation}\\\\Wellington_2013\\\\{filename_code}\"\n",
    "    elif transformation_selection == 't':\n",
    "        pathlib.Path(fr\"{translated_lidar_path}\\\\translated_lidar_{number_simulation}\\\\Wellington_2013\").mkdir(parents=True, exist_ok=True)\n",
    "        outfile = fr\"{translated_lidar_path}\\\\translated_lidar_{number_simulation}\\\\Wellington_2013\\\\{filename_code}\"\n",
    "    else:\n",
    "        pathlib.Path(fr\"{combined_lidar_path}\\\\combined_lidar_{number_simulation}\\\\Wellington_2013\").mkdir(parents=True, exist_ok=True)\n",
    "        outfile = fr\"{combined_lidar_path}\\\\combined_lidar_{number_simulation}\\\\Wellington_2013\\\\{filename_code}\"\n",
    "    \n",
    "    # Get the shape of transformed LiDAR array\n",
    "    lidar_arr_shape = len(point_classification_func)\n",
    "    \n",
    "    # Create empty transformed LiDAR array\n",
    "    lidar_arr = np.empty([lidar_arr_shape], dtype=[('X', '<f8'), ('Y', '<f8'), ('Z', '<f8'), ('Classification', 'u1')])\n",
    "    \n",
    "    # Overwrite the X, Y, and Z values in the points array with the rotated values\n",
    "    lidar_arr['X'] = (transformed_array[:, 0]).flatten()\n",
    "    lidar_arr['Y'] = (transformed_array[:, 1]).flatten()\n",
    "    lidar_arr['Z'] = (transformed_array[:, 2]).flatten()\n",
    "    lidar_arr['Classification'] = point_classification_func\n",
    "    \n",
    "    # Save the file\n",
    "    pdal_pipeline_instructions = [\n",
    "        {\"type\":  \"writers.las\",\n",
    "         \"scale_x\":\"auto\",\n",
    "         \"scale_y\":\"auto\",\n",
    "         \"offset_x\":\"auto\",\n",
    "         \"offset_y\":\"auto\",\n",
    "         \"a_srs\": f\"EPSG:{h_crs}+{v_crs}\",\n",
    "         \"filename\": str(outfile),\n",
    "         \"compression\": \"laszip\"}\n",
    "    ]\n",
    "    \n",
    "    # Run\n",
    "    pdal_pipeline = pdal.Pipeline(json.dumps(pdal_pipeline_instructions), [lidar_arr])\n",
    "    pdal_pipeline.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ddab8b",
   "metadata": {},
   "source": [
    "## 3.4. Writing tile index file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ef3b8b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(lidar_number, filename_tile):\n",
    "    '''This function is to extract the URL of each tile from original tile index file\n",
    "    \n",
    "    Arguments:\n",
    "                lidar_number:\n",
    "                                Ordinal number of lidar folder\n",
    "                filename_tile:\n",
    "                                Name of each tile\n",
    "    \n",
    "    Return:\n",
    "                url_file:\n",
    "                                URL of the specific tile\n",
    "                                \n",
    "    '''\n",
    "    # Read the shape file to have geopandas dataframe\n",
    "    full_file = gpd.read_file(fr\"{modified_lidar_path}\\\\lidar_{lidar_number}\\\\Wellington_2013\\\\Wellington_2013_TileIndex.zip\")\n",
    "    \n",
    "    # Get the row with the file name the same as given 'filename_tile'\n",
    "    file_info = full_file[full_file['Filename'] == filename_tile]\n",
    "    \n",
    "    # Get the index of that row\n",
    "    url_index = file_info.index[0]\n",
    "    \n",
    "    # Use the extracted index to get the correct URL\n",
    "    url_file = full_file['URL'][url_index]\n",
    "    \n",
    "    return url_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "50239b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_index_polygon(transformation_selection, number_simulation, filename_tile):\n",
    "    '''This function is to create transformed tile index polygon for each original tile\n",
    "    \n",
    "    Arguments:\n",
    "                transformation_selection:\n",
    "                                        \"r\" means rotation\n",
    "                                        \"t\" means translation\n",
    "                                        \"c\" means combination\n",
    "                number_simulation:\n",
    "                                        Ordinal number of simulation\n",
    "                filename_tile:\n",
    "                                        Name of each tile\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        transformed_lidar_path = rotated_lidar_path\n",
    "        transformed = \"rotated\"\n",
    "    elif transformation_selection == 't':\n",
    "        transformed_lidar_path = translated_lidar_path\n",
    "        transformed = \"translated\"\n",
    "    else:\n",
    "        transformed_lidar_path = combined_lidar_path\n",
    "        transformed = \"combined\"\n",
    "    \n",
    "    # Get information of each tile las/laz file\n",
    "    tile_info_func = subprocess.run(['pdal', 'info',\n",
    "                                      fr\"{transformed_lidar_path}\\\\{transformed}_lidar_{number_simulation}\\\\Wellington_2013\\\\{filename_tile}\"],\n",
    "                                    stdout = subprocess.PIPE)\n",
    "    \n",
    "    # Read by json\n",
    "    json_tile_func = json.loads(tile_info_func.stdout.decode('utf-8'))\n",
    "    \n",
    "    # Extract boundary coordinates\n",
    "    tile_boundary_func = np.array(json_tile_func['stats']['bbox']['native']['boundary']['coordinates'][0]).astype('float64')\n",
    "    \n",
    "    # Drop z column\n",
    "    tile_boundary_adjusted_func = np.delete(tile_boundary_func, [2], 1)\n",
    "    \n",
    "    # Convert to polygon\n",
    "    tile_boundary_polygon_func = Polygon(tile_boundary_adjusted_func)\n",
    "    \n",
    "    return tile_boundary_polygon_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9e4464",
   "metadata": {},
   "source": [
    "## 3.5. Transformation on tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9e8d817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformed_tiles_generation(transformation_selection, lidar_number,\n",
    "                                 angle_func, x_translation_func, y_translation_func,\n",
    "                                 center_x_func, center_y_func,\n",
    "                                 number_simulation):\n",
    "    '''This function is to create transformed tiles\n",
    "    \n",
    "    Arguments:\n",
    "                transformation_selection:\n",
    "                                                \"r\" means rotation\n",
    "                                                \"t\" means translation\n",
    "                                                \"c\" means combination\n",
    "                lidar_number:\n",
    "                                                Ordinal number of lidar folder\n",
    "                angle_func, x_translation_func, y_translation_func:\n",
    "                                                Angle, x, and y coordinates that are used to transform LiDAR data\n",
    "                center_x_func, center_y_func:\n",
    "                                                x and y coordinates of center point used to transform (particularly rotate)\n",
    "                number_simulation:\n",
    "                                                Ordinal number of simulation\n",
    "                                            \n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        transformed_lidar_path = rotated_lidar_path\n",
    "        transformed = \"rotated\"\n",
    "    elif transformation_selection == 't':\n",
    "        transformed_lidar_path = translated_lidar_path\n",
    "        transformed = \"translated\"\n",
    "    else:\n",
    "        transformed_lidar_path = combined_lidar_path\n",
    "        transformed = \"combined\"\n",
    "        \n",
    "    # Get list of tiles names\n",
    "    list_tile_paths = glob.glob(f\"{modified_lidar_path}\\\\lidar_{lidar_number}\\\\Wellington_2013\\*.laz\")\n",
    "    length_list = len(list_tile_paths)\n",
    "    list_tile_names = [os.path.basename(list_tile_paths[name]) for name in range(length_list)]\n",
    "    \n",
    "    # Geometry list of tile index\n",
    "    tile_index_list = []\n",
    "    tile_url_list = []\n",
    "    \n",
    "    # Transform each tile\n",
    "    for each_tile in range(length_list):\n",
    "\n",
    "        # Start timing the whole transformation process ----------------------------------------------------------------\n",
    "        start_transformation_process = time.time()\n",
    "        \n",
    "        # Reading tiles\n",
    "        points_tiles, coordinates_tiles = read_las_file(list_tile_paths[each_tile])\n",
    "        \n",
    "        # Transform tiles\n",
    "        rotated_array_func = wrapping_point_rotation(coordinates_tiles, angle_func, center_x_func, center_y_func, 0)\n",
    "        combined_array_func = wrapping_point_translation(rotated_array_func, x_translation_func, y_translation_func)\n",
    "        \n",
    "        # Write LiDAR tiles into las/laz file\n",
    "        writing_las_file(transformation_selection, points_tiles, \n",
    "                         number_simulation, combined_array_func, list_tile_names[each_tile])\n",
    "        \n",
    "        \n",
    "        # Write tile index polygon\n",
    "        tile_polygon = tile_index_polygon(transformation_selection, number_simulation, list_tile_names[each_tile])\n",
    "        tile_index_list.append(tile_polygon)\n",
    "        \n",
    "        # Write tile url polygon\n",
    "        tile_url = get_url(lidar_number, list_tile_names[each_tile])\n",
    "        tile_url_list.append(tile_url)\n",
    "        \n",
    "        # End timing the whole transformation process -----------------------------------------------------------------\n",
    "        end_transformation_process = time.time()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # PRINT -------------------------------------------------------------------------------------------------------\n",
    "        # Print the running time of whole transformation process\n",
    "        writing_transformation_process_time = end_transformation_process - start_transformation_process\n",
    "        \n",
    "        print(\"*\", \"Tile\", each_tile, \"-\", list_tile_names[each_tile], \":                         \",\n",
    "              writing_transformation_process_time/60)\n",
    "        \n",
    "        # End printing ------------------------------------------------------------------------------------------------\n",
    "        \n",
    "    print(\"-\"*20)\n",
    "    \n",
    "    # Create geopandas dataframe containing tile index information\n",
    "    tile_info = {\n",
    "        \"Filename\": list_tile_names,\n",
    "        \"URL\": tile_url_list\n",
    "                }\n",
    "    tile_data_index = gpd.GeoDataFrame(data = tile_info,\n",
    "                                       geometry = tile_index_list,\n",
    "                                       crs = 2193)\n",
    "    \n",
    "    # Create tiles shapefile\n",
    "    tile_index_path = pathlib.Path(fr\"{transformed_lidar_path}\\\\{transformed}_lidar_{number_simulation}\\\\Wellington_2013\\\\Wellington_2013_TileIndex\")\n",
    "    tile_data_index.to_file(tile_index_path)\n",
    "    shutil.make_archive(base_name=tile_index_path, format='zip', root_dir=tile_index_path)\n",
    "    shutil.rmtree(tile_index_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398242f7",
   "metadata": {},
   "source": [
    "# 4. DERIVING DEM RASTER FROM LIDAR DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a5dc83",
   "metadata": {},
   "source": [
    "## 4.1. Deriving DEM raster from LiDAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5061be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to create a DEM raster from transformed lidar data\n",
    "def dem_raster(transformation_selection, number, padding_func):\n",
    "    ''' This function is to create a raster file from a las/laz file\n",
    "    \n",
    "    Arguments:\n",
    "                transformation_selection:\n",
    "                            \"r\" means rotation\n",
    "                            \"t\" means translation\n",
    "                            \"c\" means combination\n",
    "                transformed_las_file:\n",
    "                            A path to the transformed las/laz file\n",
    "                padding_func:\n",
    "                            A list of x min, x max, y min and y max\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        transformed_lidar_path = rotated_lidar_path\n",
    "        nc_raster_path_func = rotated_nc_raster_path\n",
    "        elements_path_func = rotated_elements_path\n",
    "        transformed = \"rotated\"\n",
    "    elif transformation_selection == 't':\n",
    "        transformed_lidar_path = translated_lidar_path\n",
    "        nc_raster_path_func = translated_nc_raster_path\n",
    "        elements_path_func = translated_elements_path\n",
    "        transformed = \"translated\"\n",
    "    else:\n",
    "        transformed_lidar_path = combined_lidar_path\n",
    "        nc_raster_path_func = combined_nc_raster_path\n",
    "        elements_path_func = combined_elements_path\n",
    "        transformed = \"combined\"\n",
    "    \n",
    "    \n",
    "    # Set crs\n",
    "    h_crs = 2193\n",
    "    v_crs = 7839\n",
    "    resolution = 10\n",
    "    \n",
    "    # Create folder for storing data materials\n",
    "    data_dir = pathlib.Path(os.getcwd()) / pathlib.Path(f\"{elements_path_func}\\\\data_{transformed}_{number}\")\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.mkdir(data_dir)\n",
    "    \n",
    "    # Bounding box\n",
    "    x0 = padding_func[0]; y0 = padding_func[1]; x1 = padding_func[2]; y1 = padding_func[3];\n",
    "    catchment = shapely.geometry.Polygon([(x0, y0), (x1, y0), (x1, y1), (x0, y1)])\n",
    "    catchment = geopandas.GeoSeries([catchment])\n",
    "    catchment = catchment.set_crs(h_crs)\n",
    "\n",
    "    catchment_path = pathlib.Path(f\"{elements_path_func}\\\\data_{transformed}_{number}\\\\catchment_boundary\")\n",
    "    catchment.to_file(catchment_path)\n",
    "    shutil.make_archive(base_name=catchment_path, format='zip', root_dir=catchment_path)\n",
    "    shutil.rmtree(catchment_path)\n",
    "    \n",
    "    \n",
    "    # Design JSON instructions\n",
    "    instructions = {\"instructions\":\n",
    "                    {\n",
    "                        \"output\": {\n",
    "                            \"crs\": {\n",
    "                                \"horizontal\": h_crs,\n",
    "                                \"vertical\": v_crs\n",
    "                            },\n",
    "                            \"grid_params\": {\n",
    "                                \"resolution\": resolution\n",
    "                            }\n",
    "                        },\n",
    "                        \"apis\": {\n",
    "                            \"open_topography\": {\n",
    "                                \"Wellington_2013\": {\n",
    "                                    \"crs\": {\n",
    "                                        \"horizontal\": h_crs,\n",
    "                                        \"vertical\": v_crs\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"processing\": {\n",
    "                            \"chunk_size\": 100,\n",
    "                            \"number_of_cores\": 4\n",
    "                        },\n",
    "                        \"data_paths\": {\n",
    "                            \"local_cache\": f\"{transformed_lidar_path}\\\\{transformed}_lidar_{number}\",\n",
    "                            \"catchment_boundary\": f\"{elements_path_func}\\\\data_{transformed}_{number}\\\\catchment_boundary.zip\",\n",
    "                            \"land\": f\"{elements_path_func}\\\\data_{transformed}_{number}\\\\catchment_boundary.zip\",\n",
    "                            \"dense_dem_extents\": f\"{elements_path_func}\\\\data_{transformed}_{number}\\\\extents.geojson\",\n",
    "                            \"result_dem\": f\"{nc_raster_path_func}\\\\generated_dem_{transformed}_{number}.nc\"\n",
    "                        },\n",
    "                        \"general\": {\n",
    "                            \"set_dem_shoreline\": True,\n",
    "                            \"drop_offshore_lidar\": True,\n",
    "                            \"keep_only_ground_lidar\": False,\n",
    "                            \"interpolation_missing_values\": True\n",
    "                        }\n",
    "                    }\n",
    "                   }\n",
    "    \n",
    "    # Create DEM raster\n",
    "    runner = processor.DemGenerator(instructions)\n",
    "    runner.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf3292d",
   "metadata": {},
   "source": [
    "## 4.2. Creating polygon boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b4fd1634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to create a polygon layer to change values\n",
    "def polygon_generation(polygon_boundary, transformation_selection, number_simulation,\n",
    "                       angle_func, x_translation_func, y_translation_func,\n",
    "                       center_x_func, center_y_func,\n",
    "                       filename_output_polygon):\n",
    "    '''This function is to create polygon layer to change the pixel values\n",
    "    \n",
    "    Arguments:\n",
    "                polygon_boundary:\n",
    "                                        A list of coordinates of \n",
    "                transformation_selection:\n",
    "                                        \"r\" means rotation\n",
    "                                        \"t\" means translation\n",
    "                                        \"c\" means combination\n",
    "                number_simulation:\n",
    "                                        Ordinal number of simulation\n",
    "                angle_func, x_translation_func, y_translation_func:\n",
    "                                                Angle, x, and y coordinates that are used to transform LiDAR data\n",
    "                center_x_func, center_y_func:\n",
    "                                                x and y coordinates of center point used to transform (particularly rotate)\n",
    "                filename_output_polygon:\n",
    "                                        Output file name\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        nc_raster_path_func = rotated_nc_raster_path\n",
    "        tiff_raster_path_func = rotated_tiff_raster_path\n",
    "        transformed = \"rotated\"\n",
    "    elif transformation_selection == 't':\n",
    "        nc_raster_path_func = translated_nc_raster_path\n",
    "        tiff_raster_path_func = translated_tiff_raster_path\n",
    "        transformed = \"translated\"\n",
    "    else:\n",
    "        nc_raster_path_func = combined_nc_raster_path\n",
    "        tiff_raster_path_func = combined_tiff_raster_path\n",
    "        transformed = \"combined\"\n",
    "        \n",
    "    # Create storing folder to store the file\n",
    "    polygon_dir = pathlib.Path(os.getcwd()) / pathlib.Path(f\"{tiff_raster_path_func}\\\\{transformed}_{number_simulation}\")\n",
    "    if not os.path.exists(polygon_dir):\n",
    "        os.mkdir(polygon_dir)\n",
    "        \n",
    "    # Convert the list into array to do transformation\n",
    "    boundary_coordinates = np.array(polygon_boundary).astype('float64')\n",
    "    \n",
    "    # Transform\n",
    "    rotated_boundary = wrapping_point_rotation(boundary_coordinates, angle_func, center_x_func, center_y_func, 0)\n",
    "    translated_boundary = wrapping_point_translation(rotated_boundary, x_translation_func, y_translation_func)\n",
    "    transformed_boundary = translated_boundary\n",
    "    \n",
    "    # Convert into shapely geometry Polygon\n",
    "    shapely_polygon = Polygon(transformed_boundary)\n",
    "    \n",
    "    # Create geopandas dataframe\n",
    "    polygon_dataframe = gpd.GeoDataFrame(geometry = [shapely_polygon],\n",
    "                                         crs = 2193)\n",
    "    \n",
    "    # Write into shape file\n",
    "    polygon_dataframe.to_file(fr\"{filename_output_polygon}.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ac777843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to create polygon boundaries by using polygon_generation() function\n",
    "def polygon_boundaries(transformation_selection, number_simulation,\n",
    "                       angle_func, x_translation_func, y_translation_func,\n",
    "                       center_x_func, center_y_func):\n",
    "    '''This function is to create polygon boundaries by using polygon_generation() function.\n",
    "       These polygons will be used to change the pixel values inside or outside.\n",
    "       \n",
    "    Reference: https://gis.stackexchange.com/questions/414194/changing-raster-pixel-values-outside-of-polygon-box-using-rioxarray\n",
    "    \n",
    "    Arguments:\n",
    "                transformation_selection:\n",
    "                                        \"r\" means rotation\n",
    "                                        \"t\" means translation\n",
    "                                        \"c\" means combination\n",
    "                number_simulation:\n",
    "                                        Ordinal number of simulation\n",
    "                angle_func, x_translation_func, y_translation_func:\n",
    "                                                Angle, x, and y coordinates that are used to transform LiDAR data\n",
    "                center_x_func, center_y_func:\n",
    "                                                x and y coordinates of center point used to transform (particularly rotate)\n",
    "                file_name:\n",
    "                                        Output file name\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        nc_raster_path_func = rotated_nc_raster_path\n",
    "        tiff_raster_path_func = rotated_tiff_raster_path\n",
    "        transformed = \"rotated\"\n",
    "    elif transformation_selection == 't':\n",
    "        nc_raster_path_func = translated_nc_raster_path\n",
    "        tiff_raster_path_func = translated_tiff_raster_path\n",
    "        transformed = \"translated\"\n",
    "    else:\n",
    "        nc_raster_path_func = combined_nc_raster_path\n",
    "        tiff_raster_path_func = combined_tiff_raster_path\n",
    "        transformed = \"combined\"\n",
    "        \n",
    "    # Define the path for output\n",
    "    output_path = fr\"{tiff_raster_path_func}\\\\{transformed}_{number_simulation}\"\n",
    "        \n",
    "    # PADDING #####################################################\n",
    "    # Get extent information of original no-padding raster\n",
    "    raster_no_padding = rasterio.open(fr\"{nc_raster_path_func}\\\\generated_dem_no_padding.nc\")\n",
    "    no_padding_xmin, no_padding_ymin, no_padding_xmax, no_padding_ymax = raster_no_padding.bounds\n",
    "    \n",
    "    # Create polygon to remove PADDING values\n",
    "    # Set up polygon coordinates into a list\n",
    "    polygon_padding = [(no_padding_xmax, no_padding_ymax),\n",
    "                       (no_padding_xmax, no_padding_ymin),\n",
    "                       (no_padding_xmin, no_padding_ymin),\n",
    "                       (no_padding_xmin, no_padding_ymax),\n",
    "                       (no_padding_xmax, no_padding_ymax)]\n",
    "    \n",
    "    # Create polygon padding layer under shape file\n",
    "    polygon_generation(polygon_padding, \n",
    "                       transformation_selection,\n",
    "                       number_simulation,\n",
    "                       angle_func, x_translation_func, y_translation_func,\n",
    "                       center_x_func, center_y_func,\n",
    "                       f\"{output_path}\\\\polygon_padding_{number_simulation}\")\n",
    "    \n",
    "    \n",
    "#     # BOUNDARY 1 ###################################################\n",
    "#     # Get extent information for first boundary\n",
    "#     boundary_1_ymin = no_padding_ymin + 10*8\n",
    "#     boundary_1_xmax = no_padding_xmax\n",
    "#     boundary_1_ymax = boundary_1_ymin + 10*10\n",
    "#     boundary_1_xmin = no_padding_xmax - 10\n",
    "    \n",
    "#     # Write into a list\n",
    "#     polygon_boundary_1 = [(boundary_1_xmax, boundary_1_ymax),\n",
    "#                           (boundary_1_xmax, boundary_1_ymin),\n",
    "#                           (boundary_1_xmin, boundary_1_ymin),\n",
    "#                           (boundary_1_xmin, boundary_1_ymax),\n",
    "#                           (boundary_1_xmax, boundary_1_ymax)]\n",
    "    \n",
    "#     # Create polygon boundary 1 under shape file\n",
    "#     polygon_generation(polygon_boundary_1, \n",
    "#                        transformation_selection,\n",
    "#                        number_simulation,\n",
    "#                        angle_func, x_translation_func, y_translation_func,\n",
    "#                        center_x_func, center_y_func,\n",
    "#                        f\"{output_path}\\\\polygon_boundary_1_{number_simulation}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # BOUNDARY 2 ###################################################\n",
    "#     # Get extent information from raster including padding\n",
    "#     raster_padding = rasterio.open(fr\"{nc_raster_path_func}\\\\generated_dem_reference.nc\")\n",
    "#     padding_xmin, padding_ymin, padding_xmax, padding_ymax = raster_padding.bounds\n",
    "    \n",
    "#     # Get coordinates of boundary 2\n",
    "#     boundary_2_ymax = no_padding_ymin\n",
    "#     boundary_2_xmax = padding_xmax\n",
    "#     boundary_2_ymin = padding_ymin\n",
    "#     boundary_2_xmin = padding_xmin\n",
    "    \n",
    "#     # Write into a list\n",
    "#     polygon_boundary_2 = [(boundary_2_xmax, boundary_2_ymax),\n",
    "#                           (boundary_2_xmax, boundary_2_ymin),\n",
    "#                           (boundary_2_xmin, boundary_2_ymin),\n",
    "#                           (boundary_2_xmin, boundary_2_ymax),\n",
    "#                           (boundary_2_xmax, boundary_2_ymax)]\n",
    "    \n",
    "    \n",
    "#     # Create polygon boundary 2 under shape file\n",
    "#     polygon_generation(polygon_boundary_2, \n",
    "#                        transformation_selection,\n",
    "#                        number_simulation,\n",
    "#                        angle_func, x_translation_func, y_translation_func,\n",
    "#                        center_x_func, center_y_func,\n",
    "#                        f\"{output_path}\\\\polygon_boundary_2_{number_simulation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c12e320",
   "metadata": {},
   "source": [
    "## 4.3. Changing values based on polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "34e9d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to changing values inside or outside polygons\n",
    "def value_change(shapefile_func, file_need_changing_func, value_func, inside=True):\n",
    "    '''This function is to change pixel values inside or outside polygons\n",
    "    \n",
    "    Reference: https://corteva.github.io/rioxarray/html/rioxarray.html\n",
    "               https://corteva.github.io/rioxarray/stable/examples/convert_to_raster.html\n",
    "               https://gis.stackexchange.com/questions/414194/changing-raster-pixel-values-outside-of-polygon-box-using-rioxarray\n",
    "               https://automating-gis-processes.github.io/CSC/notebooks/L2/geopandas-basics.html\n",
    "               https://corteva.github.io/rioxarray/stable/getting_started/nodata_management.html\n",
    "               https://gdal.org/programs/gdal_translate.html\n",
    "               https://gis.stackexchange.com/questions/390438/replacing-nodata-values-by-a-constant-using-gdal-cli-tools\n",
    "               \n",
    "    Arguments:\n",
    "                shapefile_func:\n",
    "                                Polygon boundaries\n",
    "                file_need_changing:\n",
    "                                File contains values that need changing\n",
    "                value_func:\n",
    "                                Values used to replace\n",
    "                inside:\n",
    "                                If True, change values inside, else, change values outside\n",
    "    '''\n",
    "    if inside:\n",
    "        inside_command = fr\"gdal_rasterize -burn {value_func} {shapefile_func} {file_need_changing_func}\"\n",
    "        os.system(inside_command)\n",
    "    else:\n",
    "        outside_command = fr\"gdal_rasterize -i -burn {value_func} {shapefile_func} {file_need_changing_func}\"\n",
    "        os.system(outside_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "11a47551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to execute the value changes\n",
    "def value_change_execution(transformation_selection, number_simulation):\n",
    "    ''' This function is to apply value_change() function on a certain raster\n",
    "    \n",
    "    Arguments:\n",
    "                transformation_selection:\n",
    "                                        \"r\" means rotation\n",
    "                                        \"t\" means translation\n",
    "                                        \"c\" means combination\n",
    "                number_simulation:\n",
    "                                        Ordinal number of simulation\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        nc_raster_path_func = rotated_nc_raster_path\n",
    "        tiff_raster_path_func = rotated_tiff_raster_path\n",
    "        transformed = \"rotated\"\n",
    "    elif transformation_selection == 't':\n",
    "        nc_raster_path_func = translated_nc_raster_path\n",
    "        tiff_raster_path_func = translated_tiff_raster_path\n",
    "        transformed = \"translated\"\n",
    "    else:\n",
    "        nc_raster_path_func = combined_nc_raster_path\n",
    "        tiff_raster_path_func = combined_tiff_raster_path\n",
    "        transformed = \"combined\"\n",
    "    \n",
    "    # Convert NetCDF file into GeoTiff file\n",
    "    raster_nc = rioxarray.open_rasterio(fr\"{nc_raster_path_func}\\\\generated_dem_{transformed}_{number_simulation}.nc\")\n",
    "    raster_nc.rio.to_raster(fr\"{tiff_raster_path_func}\\\\{transformed}_{number_simulation}\\\\generated_dem_{transformed}_{number_simulation}.tif\")\n",
    "    \n",
    "    # Get polygon shape_file and file that has values need changing\n",
    "    file_path = fr\"{tiff_raster_path_func}\\\\{transformed}_{number_simulation}\"\n",
    "    shapefile_padding_dir = fr\"{file_path}\\\\polygon_padding_{number_simulation}.shp\"\n",
    "    shapefile_boundary_1_dir = fr\"{file_path}\\\\polygon_boundary_1_{number_simulation}.shp\"\n",
    "    shapefile_boundary_2_dir = fr\"{file_path}\\\\polygon_boundary_2_{number_simulation}.shp\"\n",
    "    file_need_changing_dir = fr\"{file_path}\\\\generated_dem_{transformed}_{number_simulation}.tif\"\n",
    "    \n",
    "    ## Changing the value\n",
    "    # Changing padding values into -999\n",
    "    value_change(shapefile_padding_dir, file_need_changing_dir, 999, False)\n",
    "    \n",
    "#     # Changing boundary 1 values into 100\n",
    "#     value_change(shapefile_boundary_1_dir, file_need_changing_dir, 100, True)\n",
    "    \n",
    "#     # Changing boundary 2 values into 100\n",
    "#     value_change(shapefile_boundary_2_dir, file_need_changing_dir, 100, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2354f833",
   "metadata": {},
   "source": [
    "## 4.4. Convert file into ASCII file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "845af0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to convert GeoTiff file into ASCII file\n",
    "def convert_to_asc(transformation_selection, number_simulation):\n",
    "    '''This function is to convert GeoTiff file into ASCII file\n",
    "    \n",
    "    Arguments:\n",
    "                transformation_selection:\n",
    "                                        \"r\" means rotation\n",
    "                                        \"t\" means translation\n",
    "                                        \"c\" means combination\n",
    "                number_simulation:\n",
    "                                        Ordinal number of simulation\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        tiff_raster_path_func = rotated_tiff_raster_path\n",
    "        asc_raster_path_func = rotated_asc_raster_path\n",
    "        transformed = \"rotated\"\n",
    "    elif transformation_selection == 't':\n",
    "        tiff_raster_path_func = translated_tiff_raster_path\n",
    "        asc_raster_path_func = translated_asc_raster_path\n",
    "        transformed = \"translated\"\n",
    "    else:\n",
    "        tiff_raster_path_func = combined_tiff_raster_path\n",
    "        asc_raster_path_func = combined_asc_raster_path\n",
    "        transformed = \"combined\"\n",
    "        \n",
    "    # Convert GeoTiff file into ASCII file\n",
    "    tiff_raster_func = rioxarray.open_rasterio(fr\"{tiff_raster_path_func}\\\\{transformed}_{number_simulation}\\\\generated_dem_{transformed}_{number_simulation}.tif\")\n",
    "    \n",
    "#     nodata_tiff_raster_func = tiff_raster_func.rio.write_nodata(-999, inplace=True)\n",
    "#     crs_tiff_raster_func = nodata_tiff_raster_func.rio.write_crs(2193)\n",
    "    \n",
    "    crs_tiff_raster_func = tiff_raster_func.rio.write_crs(2193)\n",
    "    crs_tiff_raster_func.rio.to_raster(fr\"{asc_raster_path_func}\\\\generated_dem_{transformed}_{number_simulation}.asc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d1f1bc",
   "metadata": {},
   "source": [
    "# 5. BG-FLOOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9a972c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to write river and BG_Flood parameters into text files\n",
    "def river_and_param(transformation_selection, number_simulation, river_box_transformation):\n",
    "    ''' This function is to create two text files including river text file and BG param text file\n",
    "    \n",
    "    Reference: https://www.pythontutorial.net/python-basics/python-write-text-file/\n",
    "    \n",
    "    Arguments:\n",
    "                transformation_selection:\n",
    "                                         \"r\" means rotation\n",
    "                                         \"t\" means translation\n",
    "                                         \"c\" means combination\n",
    "                number_simulation:\n",
    "                                         Ordinal number of simulation\n",
    "                river_box_transformation:\n",
    "                                         An array of a transformed x and y array\n",
    "    '''\n",
    "    # River information\n",
    "    river = ['0.0,150.0',\n",
    "             '300.0,300.0',\n",
    "             '1800.0,300.0']\n",
    "    \n",
    "    river = [\n",
    "        '0.0,10.0',\n",
    "        '100.0,15.0',\n",
    "        '200.0,10.0',\n",
    "        '300.0,20.0',\n",
    "        '400.0,25.0',\n",
    "        '500.0,30.0',\n",
    "        '600.0,50.0',\n",
    "        '700.0,75.0',\n",
    "        '800.0,80.0',\n",
    "        '900.0,100.0',\n",
    "        '1000.0,150.0',\n",
    "        '1200.0,40.0',\n",
    "        '1400.0,50.0',\n",
    "        '1800.0,55.0',\n",
    "        '2000.0,100.0',\n",
    "        '2500.0,150.0',\n",
    "        '2600.0,80.0',\n",
    "        '2700.0,75.0',\n",
    "        '2800.0,50.0',\n",
    "        '3000.0,25.0',\n",
    "        '3600.0,20.0',\n",
    "        '3700.0,10.0',\n",
    "        '3800.0,15.0',\n",
    "        '3900.0,10.0',\n",
    "        '4000.0,20.0',\n",
    "        '4100.0,25.0',\n",
    "        '4200.0,30.0',\n",
    "        '4300.0,50.0',\n",
    "        '4500.0,75.0',\n",
    "        '4700.0,80.0',\n",
    "        '4800.0,35.0',\n",
    "        '5000.0,45.0',\n",
    "        '5100.0,40.0',\n",
    "        '5200.0,50.0',\n",
    "        '5500.0,55.0',\n",
    "        '5800.0,100.0',\n",
    "        '6000.0,250.0',\n",
    "        '6200.0,80.0',\n",
    "        '6500.0,75.0',\n",
    "        '6800.0,50.0',\n",
    "        '7000.0,25.0',\n",
    "        '7200.0,20.0'\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    river_param_path = r'P:\\Courses\\PhD\\BG_flood2\\BG-Flood_Win10_v0.6-a'\n",
    "\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == \"r\":\n",
    "        trans = 'rot'\n",
    "        dem_raster_path_func = f\"{rotated_asc_raster_path}\\\\generated_dem_rotated_{number_simulation}.asc\"\n",
    "        output_path = fr\"{rotated_BGoutput_path}\\\\Output_rotated_{number_simulation}.nc\"\n",
    "        param_path = rotated_BGparam_path\n",
    "    elif transformation_selection == \"t\":\n",
    "        trans = 'tra'\n",
    "        dem_raster_path_func = f\"{translated_asc_raster_path}\\\\generated_dem_translated_{number_simulation}.asc\"\n",
    "        output_path = fr\"{translated_BGoutput_path}\\\\Output_translated_{number_simulation}.nc\"\n",
    "        param_path = translated_BGparam_path\n",
    "    else:\n",
    "        trans = 'com'\n",
    "        dem_raster_path_func = f\"{combined_asc_raster_path}\\\\generated_dem_combined_{number_simulation}.asc\"\n",
    "        output_path = fr\"{combined_BGoutput_path}\\\\Output_combined_{number_simulation}.nc\"\n",
    "        param_path = combined_BGparam_path\n",
    "        \n",
    "    # Check values of xmin and xmax\n",
    "    if river_box_transformation[0, 0] < river_box_transformation[1, 0]:\n",
    "        xmin_river = river_box_transformation[0, 0]\n",
    "        xmax_river = river_box_transformation[1, 0]\n",
    "    else:\n",
    "        xmin_river = river_box_transformation[1, 0]\n",
    "        xmax_river = river_box_transformation[0, 0]\n",
    "        \n",
    "    # Check values of ymin and ymax\n",
    "    if river_box_transformation[0, 1] < river_box_transformation[1, 1]:\n",
    "        ymin_river = river_box_transformation[0, 1]\n",
    "        ymax_river = river_box_transformation[1, 1]\n",
    "    else:\n",
    "        ymin_river = river_box_transformation[1, 1]\n",
    "        ymax_river = river_box_transformation[0, 1]\n",
    "        \n",
    "    # BG parameters\n",
    "    BG_param = [f'bathy = {dem_raster_path_func}?idw;',\n",
    "                'gpudevice = 0;',\n",
    "                'mask = 1500.0;',\n",
    "                'dx = 10;',\n",
    "                'smallnc = 0;',\n",
    "                'outputtimestep = 100.0;',\n",
    "                'endtime = 7200.0;',\n",
    "                f'river = RiverDis.txt, {xmin_river}, {xmax_river}, {ymin_river}, {ymax_river};',\n",
    "                f'outfile = {output_path};']\n",
    "        \n",
    "    # Write river text file\n",
    "    with open(f'{river_param_path}\\\\RiverDis.txt', 'w') as riv:\n",
    "        riv.write('\\n'.join(river))\n",
    "        \n",
    "    # Write param text file\n",
    "    with open(f'{river_param_path}\\\\BG_param.txt', 'w') as param:\n",
    "        param.write('\\n'.join(BG_param))\n",
    "    \n",
    "    # Copy the text files for later checking\n",
    "    # Create the file\n",
    "    pathlib.Path(f'{param_path}\\\\param_{number_simulation}').mkdir(parents=True, exist_ok=True)\n",
    "    # River\n",
    "    shutil.copy2(f'{river_param_path}\\\\BG_param.txt', f'{param_path}\\\\param_{number_simulation}\\\\RiverDis.txt')\n",
    "    # BG param\n",
    "    shutil.copy2(f'{river_param_path}\\\\BG_param.txt', f'{param_path}\\\\param_{number_simulation}\\\\BG_param.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6a6fb837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_BG_Flood(transformation_selection, number_simulation, river_box_transformation):\n",
    "    '''This function is to run BG_Flood\n",
    "    \n",
    "    Arguments:\n",
    "                transformation_selection:\n",
    "                                         \"r\" means rotation\n",
    "                                         \"t\" means translation\n",
    "                                         \"c\" means combination\n",
    "                number_simulation:\n",
    "                                         Ordinal number of simulation\n",
    "                river_box_transformation:\n",
    "                                         An array of a transformed x and y array\n",
    "    '''    \n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == \"r\":\n",
    "        river_and_param(transformation_selection, number_simulation, river_box_transformation)\n",
    "        os.chdir(r'P:\\\\Courses\\\\PhD\\\\BG_flood2\\\\BG-Flood_Win10_v0.6-a')\n",
    "        subprocess.check_output([\".\\\\BG_Flood_Cleanup.exe\"])\n",
    "    elif transformation_selection == \"t\":\n",
    "        river_and_param(transformation_selection, number_simulation, river_box_transformation)\n",
    "        os.chdir(r'P:\\\\Courses\\\\PhD\\\\BG_flood2\\\\BG-Flood_Win10_v0.6-a')\n",
    "        subprocess.check_output([\".\\\\BG_Flood_Cleanup.exe\"])\n",
    "    else:\n",
    "        river_and_param(transformation_selection, number_simulation, river_box_transformation)\n",
    "        os.chdir(r'P:\\\\Courses\\\\PhD\\\\BG_flood2\\\\BG-Flood_Win10_v0.6-a')\n",
    "        pathlib.Path('BG_log.txt').unlink(missing_ok=True)\n",
    "        subprocess.check_output([\".\\BG_Flood_Cleanup.exe\"])\n",
    "    \n",
    "    # Change the path back to origin\n",
    "    os.chdir(f\"{drive}:\\\\{main_folder}\\\\{version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9272e3",
   "metadata": {},
   "source": [
    "# 6. EXTRACTING FLOWDEPTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "eac1d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to extract the flowdepth from BG_Flood output\n",
    "def flowdepth_extraction(transformation_selection, number, flowdepth_rate_func, time):\n",
    "    '''This function is to extract the flowdepth from BG_Flood output\n",
    "    Arguments:\n",
    "                transformation_selection:\n",
    "                            \"r\" means rotation\n",
    "                            \"t\" means translation\n",
    "                            \"c\" means combination\n",
    "                number:\n",
    "                            Ordinal number of simulation\n",
    "                \n",
    "                flowdepth_rate_func:\n",
    "                            Threshold for flowdepth\n",
    "                \n",
    "                time:\n",
    "                            Amount of time that BG_flood model predicted\n",
    "    '''\n",
    "    # Setting up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        BGoutput = rotated_BGoutput_path\n",
    "        flowdepth_path_func = rotated_flowdepth_path\n",
    "        transformed = \"rotated\"\n",
    "    elif transformation_selection == 't':\n",
    "        BGoutput = translated_BGoutput_path\n",
    "        flowdepth_path_func = translated_flowdepth_path\n",
    "        transformed = \"translated\"\n",
    "    else:\n",
    "        BGoutput = combined_BGoutput_path\n",
    "        flowdepth_path_func = combined_flowdepth_path\n",
    "        transformed = \"combined\"\n",
    "    \n",
    "\n",
    "    output = f'Output_{transformed}_{number}.nc'\n",
    "    \n",
    "    command = f'gmt grdmath {BGoutput}\\\\{output}?h_P0[{time}] DUP {flowdepth_rate_func} GT MUL = {flowdepth_path_func}\\\\flowdepth_{transformed}_{number}_at_{time}.nc'\n",
    "    print(command)\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7538e4c7",
   "metadata": {},
   "source": [
    "# 7. UN-TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "50439090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_crs(transformation_selection, number, time):\n",
    "    '''This function is to add crs into flowdepth extraction raster\n",
    "    \n",
    "    Arguments:  transformation_selection:\n",
    "                        \"r\" means rotation\n",
    "                        \"t\" means translation\n",
    "                        \"c\" means combination\n",
    "                angle:\n",
    "                        Angle to unrotate\n",
    "                time:\n",
    "                        Amount of time that BG_flood model predicted\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        transformed = \"rotated\"\n",
    "        flowdepth_path = rotated_flowdepth_path\n",
    "        crs_path = unrotated_crs_path\n",
    "        transformed_path = unrotated_path\n",
    "    elif transformation_selection == 't':\n",
    "        transformed = \"translated\"\n",
    "        flowdepth_path = translated_flowdepth_path\n",
    "        crs_path = untranslated_crs_path\n",
    "        transformed_path = untranslated_path\n",
    "    else:\n",
    "        transformed = \"combined\"\n",
    "        flowdepth_path = combined_flowdepth_path\n",
    "        crs_path = uncombined_crs_path\n",
    "        transformed_path = uncombined_path\n",
    "    \n",
    "    \n",
    "    # Add crs to ROTATED raster (flowdepth files extracted from model outputs)\n",
    "    raster_add_crs = xarray.open_dataset(fr\"{flowdepth_path}\\\\flowdepth_{transformed}_{number}_at_{time}.nc\")\n",
    "    raster_add_crs = raster_add_crs.rio.write_crs(2193)\n",
    "    raster_add_crs.rio.to_raster(fr\"{crs_path}\\\\flowdepth_{transformed}_{number}_at_{time}.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "097a70e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygons_uncombination(transformation_selection, number_simulation, angle_func, x_translation_func, y_translation_func, time):\n",
    "    '''This function is to unrotate and write rasters into shapefiles\n",
    "    \n",
    "    Reference: https://docs.dea.ga.gov.au/notebooks/Frequently_used_code/Polygonise_pixel_edges.html\n",
    "               https://gis.stackexchange.com/questions/187877/how-to-polygonize-raster-to-shapely-polygons/\n",
    "               \n",
    "               https://github.com/sgillies/affine/blob/master/affine/__init__.py#L178\n",
    "               https://gis.stackexchange.com/questions/408386/rotating-raster-using-python\n",
    "               https://pythonhosted.org/PyAgg/affine.m.html\n",
    "               \n",
    "               https://gis.stackexchange.com/questions/408386/rotating-raster-using-python\n",
    "               https://gis.stackexchange.com/questions/350526/gdal-setgeotransform-issue\n",
    "               https://corteva.github.io/rioxarray/stable/examples/convert_to_raster.html\n",
    "               https://gdal.org/tutorials/geotransforms_tut.html#geotransforms-tut\n",
    "               https://gdal.org/tutorials/raster_api_tut.html\n",
    "               \n",
    "    Arguments:  transformation_selection:\n",
    "                                                \"r\" means rotation\n",
    "                                                \"t\" means translation\n",
    "                                                \"c\" means combination\n",
    "                number_simulation:\n",
    "                        Ordinal number of simulation\n",
    "                angle_func, x_translation_func, y_translation_func:\n",
    "                                                Angle, x, and y coordinates that are used to transform LiDAR data\n",
    "                center_x_func, center_y_func:\n",
    "                                                x and y coordinates of center point used to transform (particularly rotate)\n",
    "                time:\n",
    "                                                Amount of time that BG_flood model predicted\n",
    "    '''\n",
    "    # Set up the path for transformation_selection\n",
    "    # Set up the path for transformation_selection\n",
    "    if transformation_selection == 'r':\n",
    "        transformed = \"rotated\"\n",
    "        flowdepth_path = rotated_flowdepth_path\n",
    "        crs_path = unrotated_crs_path\n",
    "        untransformed_path = unrotated_path\n",
    "    elif transformation_selection == 't':\n",
    "        transformed = \"translated\"\n",
    "        flowdepth_path = translated_flowdepth_path\n",
    "        crs_path = untranslated_crs_path\n",
    "        untransformed_path = untranslated_path\n",
    "    else:\n",
    "        transformed = \"combined\"\n",
    "        flowdepth_path = combined_flowdepth_path\n",
    "        crs_path = uncombined_crs_path\n",
    "        untransformed_path = uncombined_path\n",
    "    \n",
    "    # Extract the array from COMBINED raster\n",
    "    raster_poly = rasterio.open(fr\"{crs_path}\\\\flowdepth_{transformed}_{number_simulation}_at_{time}.nc\")\n",
    "    raster_array = raster_poly.read(1)\n",
    "    raster_transform = raster_poly.transform\n",
    "    raster_crs = raster_poly.crs\n",
    "    \n",
    "    # Extract parameters: id and depth\n",
    "    id_pixels = np.arange(raster_array.size).reshape(raster_array.shape)\n",
    "    depth_list = list(raster_array.flatten())\n",
    "    \n",
    "    \n",
    "    # UNCOMBINE 1 (untranslate) affine transformation\n",
    "    uncombined1_transform = raster_transform * raster_transform.translation(x_translation_func, y_translation_func)\n",
    "    \n",
    "    # Find out centers\n",
    "    raster_center = center_calculation('c', False)\n",
    "    \n",
    "    # UNCOMBINE 2 (unrotate) affine transformation\n",
    "    uncombined2_transform = uncombined1_transform * uncombined1_transform.rotation(angle_func, raster_center)\n",
    "    \n",
    "    # Change the name\n",
    "    uncombined_transform = uncombined2_transform\n",
    "    \n",
    "    # Vectorise features\n",
    "    uncombined_vectors = rasterio.features.shapes(source = id_pixels.astype(np.int16),\n",
    "                                                    transform = uncombined_transform)\n",
    "    \n",
    "    # List the UNCOMBINED polygons to extract neccessary parameters\n",
    "    uncombined_vectors_list = list(uncombined_vectors)\n",
    "    \n",
    "    # Get geometry\n",
    "    polygons_geometry_values = [shape(polygon_geometry) for polygon_geometry, value_geometry in uncombined_vectors_list]\n",
    "    \n",
    "    # Get id\n",
    "    id_uncombined_pixels_values = [id_value for id_polygon, id_value in uncombined_vectors_list]\n",
    "    \n",
    "    # Create UNCOMBINED database under geopandas dataframe (gdf) format\n",
    "    uncombined_data = {\"id\": id_uncombined_pixels_values,\n",
    "                      \"depth\": depth_list}\n",
    "    uncombined_raster_poly_gdf = gpd.GeoDataFrame(data = uncombined_data,\n",
    "                                                  geometry = polygons_geometry_values,\n",
    "                                                  crs = raster_crs)\n",
    "    shapefile_dir = pathlib.Path(os.getcwd()) / pathlib.Path(f\"{untransformed_path}\\\\shapefile_{number_simulation}\")\n",
    "    if not os.path.exists(shapefile_dir):\n",
    "        os.mkdir(shapefile_dir)\n",
    "    \n",
    "    # Write geopandas dataframe to shape file\n",
    "    write_dataframe(uncombined_raster_poly_gdf, fr\"{untransformed_path}\\\\shapefile_{number_simulation}\\\\flowdepth_un{transformed}_{number_simulation}_at_{time}.shp\", \n",
    "                    driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e854d5ca",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75992cc0",
   "metadata": {},
   "source": [
    "# EXECUTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b9f99ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 997 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# GET NECCESSARY INFORMATION\n",
    "\n",
    "# LiDAR number file\n",
    "num_lidar_file = 0\n",
    "\n",
    "# Construct a list of boundary\n",
    "resolution = 10\n",
    "number_pixel_x = 16*9                                   # multiple of 16\n",
    "number_pixel_y = 16*6                                   # multiple of 16\n",
    "\n",
    "xmin = 1771385\n",
    "ymin = 5472254\n",
    "xmax = xmin + resolution * number_pixel_x\n",
    "ymax = ymin + resolution * number_pixel_y\n",
    "\n",
    "# Boundary for the area of interest\n",
    "boundary_1 = [xmin, ymin, xmax, ymax]\n",
    "\n",
    "# Padding boundary for DEMs (use this boundary to create padding)\n",
    "addition_2 = 16*5\n",
    "boundary_2 = padding_combination(boundary_1, \"c\", addition_2)\n",
    "\n",
    "# Boundary for tiles (use this boundary to download LiDAR)\n",
    "addition_3 = 16*5\n",
    "boundary_3 = padding_combination(boundary_2, \"c\", addition_3)\n",
    "\n",
    "# Extracting flowdepth rate (for flowdepth_extraction() function)\n",
    "flowdepth_rate = 0\n",
    "\n",
    "# Time to extract flowdepth (for flowdepth_extraction() function)\n",
    "time_extract = 72\n",
    "\n",
    "# Rivers\n",
    "river_xy_coordinates = np.array([[1772824, 5472314.684], [1772825, 5472315.684]]).astype('float64')\n",
    "\n",
    "# Set up the angle for rotation\n",
    "angle_start = 0\n",
    "angle_end = 90\n",
    "angle_interval = 45\n",
    "\n",
    "# Set up the translation\n",
    "value_start = 0\n",
    "value_end = 0\n",
    "value_interval = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "87f9fd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1771385, 5472254, 1772825, 5473214]\n",
      "[1771145.0, 5471774.0, 1773065.0, 5473694.0]\n",
      "[1770665.0, 5471294.0, 1773545.0, 5474174.0]\n"
     ]
    }
   ],
   "source": [
    "# Check boundaries\n",
    "print(boundary_1)\n",
    "print(boundary_2)\n",
    "print(boundary_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c251fb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check files in dataset Wellington_2013\n",
      "checking size: Wellington_2013\\ot_CL1_WLG_2013_1km_089038.laz: 22160061, total (GB): 0.020638165064156055\n",
      "checking size: Wellington_2013\\ot_CL1_WLG_2013_1km_087038.laz: 25236171, total (GB): 0.04414118081331253\n",
      "checking size: Wellington_2013\\ot_CL1_WLG_2013_1km_089040.laz: 25801639, total (GB): 0.06817082967609167\n",
      "checking size: Wellington_2013\\ot_CL1_WLG_2013_1km_088038.laz: 25857820, total (GB): 0.09225280117243528\n",
      "checking size: Wellington_2013\\ot_CL1_WLG_2013_1km_086039.laz: 25949694, total (GB): 0.11642033699899912\n",
      "checking size: Wellington_2013\\ot_CL1_WLG_2013_1km_088039.laz: 25792909, total (GB): 0.14044185541570187\n",
      "checking size: Wellington_2013\\ot_CL1_WLG_2013_1km_086040.laz: 22502212, total (GB): 0.16139867343008518\n",
      "checking size: Wellington_2013\\ot_CL1_WLG_2013_1km_086041.laz: 25329480, total (GB): 0.18498858995735645\n",
      "checking size: Wellington_2013\\ot_CL1_WLG_2013_1km_089041.laz: 24493969, total (GB): 0.20780037622898817\n",
      "checking size: Wellington_2013\\ot_CL1_WLG_2013_1km_089039.laz: 25459249, total (GB): 0.23151114955544472\n",
      "checking size: Wellington_2013\\ot_CL1_WLG_2013_1km_086038.laz: 26543487, total (GB): 0.2562316982075572\n",
      "checking size: Wellington_2013\\ot_CL1_WLG_2013_1km_088041.laz: 25012217, total (GB): 0.27952614054083824\n",
      "checking size: Wellington_2013\\ot_CL1_WLG_2013_1km_087040.laz: 24940246, total (GB): 0.30275355465710163\n",
      "checking size: Wellington_2013\\ot_CL1_WLG_2013_1km_088040.laz: 24813063, total (GB): 0.3258625203743577\n",
      "checking size: Wellington_2013\\ot_CL1_WLG_2013_1km_087041.laz: 26291440, total (GB): 0.3503483319655061\n",
      "checking size: Wellington_2013\\ot_CL1_WLG_2013_1km_087039.laz: 24868157, total (GB): 0.373508607968688\n",
      "Downloading file: Wellington_2013\\ot_CL1_WLG_2013_1km_089038.laz\n",
      "Downloading file: Wellington_2013\\ot_CL1_WLG_2013_1km_087038.laz\n",
      "Downloading file: Wellington_2013\\ot_CL1_WLG_2013_1km_089040.laz\n",
      "Downloading file: Wellington_2013\\ot_CL1_WLG_2013_1km_088038.laz\n",
      "Downloading file: Wellington_2013\\ot_CL1_WLG_2013_1km_086039.laz\n",
      "Downloading file: Wellington_2013\\ot_CL1_WLG_2013_1km_088039.laz\n",
      "Downloading file: Wellington_2013\\ot_CL1_WLG_2013_1km_086040.laz\n",
      "Downloading file: Wellington_2013\\ot_CL1_WLG_2013_1km_086041.laz\n",
      "Downloading file: Wellington_2013\\ot_CL1_WLG_2013_1km_089041.laz\n",
      "Downloading file: Wellington_2013\\ot_CL1_WLG_2013_1km_089039.laz\n",
      "Downloading file: Wellington_2013\\ot_CL1_WLG_2013_1km_086038.laz\n",
      "Downloading file: Wellington_2013\\ot_CL1_WLG_2013_1km_088041.laz\n",
      "Downloading file: Wellington_2013\\ot_CL1_WLG_2013_1km_087040.laz\n",
      "Downloading file: Wellington_2013\\ot_CL1_WLG_2013_1km_088040.laz\n",
      "Downloading file: Wellington_2013\\ot_CL1_WLG_2013_1km_087041.laz\n",
      "Downloading file: Wellington_2013\\ot_CL1_WLG_2013_1km_087039.laz\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Download LiDAR\n",
    "download_lidar(boundary_3, num_lidar_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "268a8d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Tile 0 - ot_CL1_WLG_2013_1km_086038.laz :                       2.3156893094380697\n",
      "* Tile 1 - ot_CL1_WLG_2013_1km_086039.laz :                       2.270197856426239\n",
      "* Tile 2 - ot_CL1_WLG_2013_1km_086040.laz :                       2.234510107835134\n",
      "* Tile 3 - ot_CL1_WLG_2013_1km_086041.laz :                       2.403064012527466\n",
      "* Tile 4 - ot_CL1_WLG_2013_1km_087038.laz :                       2.2254531542460123\n",
      "* Tile 5 - ot_CL1_WLG_2013_1km_087039.laz :                       2.1897761106491087\n",
      "* Tile 6 - ot_CL1_WLG_2013_1km_087040.laz :                       2.1427695115407306\n",
      "* Tile 7 - ot_CL1_WLG_2013_1km_087041.laz :                       2.2150489886601767\n",
      "* Tile 8 - ot_CL1_WLG_2013_1km_088038.laz :                       2.1979863047599792\n",
      "* Tile 9 - ot_CL1_WLG_2013_1km_088039.laz :                       2.1867376883824665\n",
      "* Tile 10 - ot_CL1_WLG_2013_1km_088040.laz :                       2.3433727741241457\n",
      "* Tile 11 - ot_CL1_WLG_2013_1km_088041.laz :                       2.0726473768552145\n",
      "* Tile 12 - ot_CL1_WLG_2013_1km_089038.laz :                       1.9010897397994995\n",
      "* Tile 13 - ot_CL1_WLG_2013_1km_089039.laz :                       2.1605282068252563\n",
      "* Tile 14 - ot_CL1_WLG_2013_1km_089040.laz :                       2.1696060140927633\n",
      "* Tile 15 - ot_CL1_WLG_2013_1km_089041.laz :                       2.113408958911896\n",
      "Wall time: 35min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Modify LiDAR\n",
    "modified_lidar(num_lidar_file, \"statistical\", 100, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "64aa093c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check files in dataset Wellington_2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\geofabrics39\\lib\\site-packages\\distributed\\node.py:160: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 63833 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:63834' processes=4 threads=4, memory=31.69 GiB>\n",
      "Check files in dataset Wellington_2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\geofabrics39\\lib\\site-packages\\distributed\\node.py:160: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 63939 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:63940' processes=4 threads=4, memory=31.69 GiB>\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Generating reference DEMs\n",
    "# Reference DEM without padding\n",
    "dem_raster_reference(\"c\", f\"lidar_{num_lidar_file}\", boundary_1, False)\n",
    "\n",
    "# Reference DEM with padding\n",
    "dem_raster_reference(\"c\", f\"lidar_{num_lidar_file}\", boundary_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0c342e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate coordinates of center point\n",
    "center_point = center_calculation('c', True)\n",
    "center_x = center_point[0]                     # Extract x coordinate of center point\n",
    "center_y = center_point[1]                     # Extract y coordinate of center point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8cce9cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ angle: 0 and x: 0 and y: 0 ------------------------------\n",
      "* Tile 0 - ot_CL1_WLG_2013_1km_086038.laz :                          0.3093505342801412\n",
      "* Tile 1 - ot_CL1_WLG_2013_1km_086039.laz :                          0.2939431548118591\n",
      "* Tile 2 - ot_CL1_WLG_2013_1km_086040.laz :                          0.24449899991353352\n",
      "* Tile 3 - ot_CL1_WLG_2013_1km_086041.laz :                          0.25724332332611083\n",
      "* Tile 4 - ot_CL1_WLG_2013_1km_087038.laz :                          0.2570426066716512\n",
      "* Tile 5 - ot_CL1_WLG_2013_1km_087039.laz :                          0.2644611239433289\n",
      "* Tile 6 - ot_CL1_WLG_2013_1km_087040.laz :                          0.25711582899093627\n",
      "* Tile 7 - ot_CL1_WLG_2013_1km_087041.laz :                          0.26151430209477744\n",
      "* Tile 8 - ot_CL1_WLG_2013_1km_088038.laz :                          0.2562392036120097\n",
      "* Tile 9 - ot_CL1_WLG_2013_1km_088039.laz :                          0.2546016653378805\n",
      "* Tile 10 - ot_CL1_WLG_2013_1km_088040.laz :                          0.2504816214243571\n",
      "* Tile 11 - ot_CL1_WLG_2013_1km_088041.laz :                          0.24745978116989137\n",
      "* Tile 12 - ot_CL1_WLG_2013_1km_089038.laz :                          0.22428439060846964\n",
      "* Tile 13 - ot_CL1_WLG_2013_1km_089039.laz :                          0.2602031389872233\n",
      "* Tile 14 - ot_CL1_WLG_2013_1km_089040.laz :                          0.26414599816004436\n",
      "* Tile 15 - ot_CL1_WLG_2013_1km_089041.laz :                          0.25072906017303465\n",
      "--------------------\n",
      "Check files in dataset Wellington_2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\geofabrics39\\lib\\site-packages\\distributed\\node.py:160: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 49346 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:49347' processes=4 threads=4, memory=31.69 GiB>\n",
      "* Running time of transforming tiles:                                4.161394476890564\n",
      "* Running time of generating DEM process:                            0.7056979417800904\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------ angle: 45 and x: 0 and y: 0 ------------------------------\n",
      "* Tile 0 - ot_CL1_WLG_2013_1km_086038.laz :                          0.2710619568824768\n",
      "* Tile 1 - ot_CL1_WLG_2013_1km_086039.laz :                          0.26555747191111245\n",
      "* Tile 2 - ot_CL1_WLG_2013_1km_086040.laz :                          0.24273114999135334\n",
      "* Tile 3 - ot_CL1_WLG_2013_1km_086041.laz :                          0.25582668781280515\n",
      "* Tile 4 - ot_CL1_WLG_2013_1km_087038.laz :                          0.2594075520833333\n",
      "* Tile 5 - ot_CL1_WLG_2013_1km_087039.laz :                          0.2575612187385559\n",
      "* Tile 6 - ot_CL1_WLG_2013_1km_087040.laz :                          0.2531712134679159\n",
      "* Tile 7 - ot_CL1_WLG_2013_1km_087041.laz :                          0.25772480567296346\n",
      "* Tile 8 - ot_CL1_WLG_2013_1km_088038.laz :                          0.25657692352930705\n",
      "* Tile 9 - ot_CL1_WLG_2013_1km_088039.laz :                          0.2576640168825785\n",
      "* Tile 10 - ot_CL1_WLG_2013_1km_088040.laz :                          0.25481884876887\n",
      "* Tile 11 - ot_CL1_WLG_2013_1km_088041.laz :                          0.2447455088297526\n",
      "* Tile 12 - ot_CL1_WLG_2013_1km_089038.laz :                          0.22330513795216878\n",
      "* Tile 13 - ot_CL1_WLG_2013_1km_089039.laz :                          0.2548332571983337\n",
      "* Tile 14 - ot_CL1_WLG_2013_1km_089040.laz :                          0.2555663665135702\n",
      "* Tile 15 - ot_CL1_WLG_2013_1km_089041.laz :                          0.24717217286427814\n",
      "--------------------\n",
      "Check files in dataset Wellington_2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\geofabrics39\\lib\\site-packages\\distributed\\node.py:160: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 49860 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:49861' processes=4 threads=4, memory=31.69 GiB>\n",
      "* Running time of transforming tiles:                                4.0651137669881185\n",
      "* Running time of generating DEM process:                            0.7703202684720357\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------ angle: 90 and x: 0 and y: 0 ------------------------------\n",
      "* Tile 0 - ot_CL1_WLG_2013_1km_086038.laz :                          0.26850149234135945\n",
      "* Tile 1 - ot_CL1_WLG_2013_1km_086039.laz :                          0.26456689834594727\n",
      "* Tile 2 - ot_CL1_WLG_2013_1km_086040.laz :                          0.23741631507873534\n",
      "* Tile 3 - ot_CL1_WLG_2013_1km_086041.laz :                          0.2581955035527547\n",
      "* Tile 4 - ot_CL1_WLG_2013_1km_087038.laz :                          0.2553750912348429\n",
      "* Tile 5 - ot_CL1_WLG_2013_1km_087039.laz :                          0.25590330759684243\n",
      "* Tile 6 - ot_CL1_WLG_2013_1km_087040.laz :                          0.2538007100423177\n",
      "* Tile 7 - ot_CL1_WLG_2013_1km_087041.laz :                          0.2584318200747172\n",
      "* Tile 8 - ot_CL1_WLG_2013_1km_088038.laz :                          0.25461246967315676\n",
      "* Tile 9 - ot_CL1_WLG_2013_1km_088039.laz :                          0.2577294905980428\n",
      "* Tile 10 - ot_CL1_WLG_2013_1km_088040.laz :                          0.2474112351735433\n",
      "* Tile 11 - ot_CL1_WLG_2013_1km_088041.laz :                          0.24694358905156452\n",
      "* Tile 12 - ot_CL1_WLG_2013_1km_089038.laz :                          0.2246617039044698\n",
      "* Tile 13 - ot_CL1_WLG_2013_1km_089039.laz :                          0.25687191088994343\n",
      "* Tile 14 - ot_CL1_WLG_2013_1km_089040.laz :                          0.2573068579037984\n",
      "* Tile 15 - ot_CL1_WLG_2013_1km_089041.laz :                          0.24957930246988932\n",
      "--------------------\n",
      "Check files in dataset Wellington_2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\geofabrics39\\lib\\site-packages\\distributed\\node.py:160: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 50281 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:50282' processes=4 threads=4, memory=31.69 GiB>\n",
      "* Running time of transforming tiles:                                4.054940251509349\n",
      "* Running time of generating DEM process:                            0.6244746247927347\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for angle_value1 in range(angle_start, angle_end+1, angle_interval):\n",
    "    for value_x1 in range(value_start, value_end+1, value_interval):\n",
    "        for value_y1 in range(value_start, value_end+1, value_interval):\n",
    "            # Set up translation values for x and y coordinates.\n",
    "            # Apply translation values into lidar point cloud array (under meters unit)\n",
    "            x_translation_lidar = value_x1\n",
    "            y_translation_lidar = value_y1\n",
    "            \n",
    "            # Set the name of each transformation\n",
    "            combination_number1 = f\"angle_{angle_value1}_x_{value_x1}_y_{value_y1}\"\n",
    "            \n",
    "            # Print the header of the first running\n",
    "            print(\"{0} angle: {1} and x: {2} and y: {3} {0}\".format(\"-\"*30, angle_value1, value_x1, value_y1))\n",
    "            \n",
    "            \n",
    "            # Start timing tranforming process -------------------------------------------------------------\n",
    "            start_transform_tiles = time.time()\n",
    "            # Transform tiles\n",
    "            transformed_tiles_generation(\n",
    "                'c', num_lidar_file,\n",
    "                angle_value1, value_x1, value_y1,\n",
    "                center_x, center_y,\n",
    "                combination_number1\n",
    "            )\n",
    "            # End timing generating DEM process\n",
    "            end_transform_tiles = time.time()\n",
    "            \n",
    "            \n",
    "            # Start timing generating DEM process -----------------------------------------------------------\n",
    "            start_dem = time.time()\n",
    "            # Generate DEM\n",
    "            dem_raster(\"c\", combination_number1, boundary_2)\n",
    "            # Start timing generating DEM process\n",
    "            end_dem = time.time()\n",
    "            \n",
    "            \n",
    "            # PRINT -----------------------------------------------------------------------------------------\n",
    "            # Print the transforming tiles process \n",
    "            transform_tile_time = end_transform_tiles - start_transform_tiles\n",
    "            print(\"* Running time of transforming tiles:                               \",\n",
    "                  transform_tile_time/60)\n",
    "            \n",
    "            # Print the running time of generating DEM process\n",
    "            dem_time = end_dem - start_dem\n",
    "            print(\"* Running time of generating DEM process:                           \",\n",
    "                  dem_time/60)\n",
    "            \n",
    "            \n",
    "            # Print separator\n",
    "            print(\"-\"*90)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0e77742a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rasterio._env:CPLE_AppDefined in Recode from UTF-8 to CP_ACP failed with the error: \"Invalid argument\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ angle: 0 and x: 0 and y: 0 ------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rasterio._env:CPLE_AppDefined in Recode from UTF-8 to CP_ACP failed with the error: \"Invalid argument\".\n",
      "WARNING:rasterio._env:CPLE_AppDefined in Recode from UTF-8 to CP_ACP failed with the error: \"Invalid argument\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running time of the whole exchanging process:                  0.01874312957127889\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------ angle: 45 and x: 0 and y: 0 ------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rasterio._env:CPLE_AppDefined in Recode from UTF-8 to CP_ACP failed with the error: \"Invalid argument\".\n",
      "WARNING:rasterio._env:CPLE_AppDefined in Recode from UTF-8 to CP_ACP failed with the error: \"Invalid argument\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running time of the whole exchanging process:                  0.014667308330535889\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------ angle: 90 and x: 0 and y: 0 ------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rasterio._env:CPLE_AppDefined in Recode from UTF-8 to CP_ACP failed with the error: \"Invalid argument\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running time of the whole exchanging process:                  0.014353116353352865\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Wall time: 2.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Execute changing values code\n",
    "for angle_value2 in range(angle_start, angle_end+1, angle_interval):\n",
    "    for value_x2 in range(value_start, value_end+1, value_interval):\n",
    "        for value_y2 in range(value_start, value_end+1, value_interval):\n",
    "            # Set up translation values for x and y coordinates.\n",
    "            # Apply translation values into lidar point cloud array (under meters unit)\n",
    "            x_translation_lidar = value_x2\n",
    "            y_translation_lidar = value_y2\n",
    "            \n",
    "            # Set the name of each translation\n",
    "            combination_number2 = f\"angle_{angle_value2}_x_{value_x2}_y_{value_y2}\"\n",
    "            \n",
    "            # Print the header of the first running\n",
    "            print(\"{0} angle: {1} and x: {2} and y: {3} {0}\".format(\"-\"*30, angle_value2, value_x2, value_y2))\n",
    "            \n",
    "            # Start timing the whole process\n",
    "            start_changing_values = time.time()\n",
    "\n",
    "            # Create polygon boundaries\n",
    "            polygon_boundaries(\"c\", combination_number2,\n",
    "                               angle_value2, x_translation_lidar, y_translation_lidar,\n",
    "                               center_x, center_y)\n",
    "\n",
    "            # Changing pixels values\n",
    "            value_change_execution(\"c\", combination_number2)\n",
    "\n",
    "            # Convert to ASCII\n",
    "            convert_to_asc(\"c\", combination_number2)\n",
    "\n",
    "            # End timing the whole process\n",
    "            end_changing_values = time.time()\n",
    "\n",
    "            # Print the running time of the whole process\n",
    "            changing_values_time = end_changing_values - start_changing_values\n",
    "            print(\"* Running time of the whole exchanging process:                 \",\n",
    "                  changing_values_time/60)\n",
    "\n",
    "            # Print separator\n",
    "            print(\"-\"*90)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9b2b6951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ angle: 0 and x: 0 and y: 0 ------------------------------\n",
      "* Running time of running BG_Flood model: 10.311006593704224\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------ angle: 45 and x: 0 and y: 0 ------------------------------\n",
      "* Running time of running BG_Flood model: 11.742301805814106\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------ angle: 90 and x: 0 and y: 0 ------------------------------\n",
      "* Running time of running BG_Flood model: 10.154708206653595\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute BG_Flood model\n",
    "for angle_value3 in range(angle_start, angle_end+1, angle_interval):\n",
    "    for value_x3 in range(value_start, value_end+1, value_interval):\n",
    "        for value_y3 in range(value_start, value_end+1, value_interval):\n",
    "            # Set up translation values for x and y coordinates.\n",
    "            # Apply translation values into lidar point cloud array (under meters unit)\n",
    "            x_translation_lidar = value_x3\n",
    "            y_translation_lidar = value_y3\n",
    "\n",
    "            # Set the name of each translation\n",
    "            combination_number3 = f\"angle_{angle_value3}_x_{value_x3}_y_{value_y3}\"\n",
    "\n",
    "            # Print the header of the first running\n",
    "            print(\"{0} angle: {1} and x: {2} and y: {3} {0}\".format(\"-\"*30, angle_value3, value_x3, value_y3))\n",
    "\n",
    "            # Start timing the whole model running process\n",
    "            start_model = time.time()\n",
    "\n",
    "            # River box coordinates\n",
    "            rotated_river_xy_coordinates = wrapping_point_rotation(river_xy_coordinates, angle_value3, center_x, center_y, 0)\n",
    "            combined_river_xy_coordinates = wrapping_point_translation(rotated_river_xy_coordinates, x_translation_lidar, y_translation_lidar)\n",
    "            \n",
    "            # Run BG_Flood\n",
    "            run_BG_Flood(\"c\", combination_number3, combined_river_xy_coordinates)\n",
    "\n",
    "            # End timing the whole model running process\n",
    "            end_model = time.time()\n",
    "\n",
    "            # Print the running time of running BG_Flood model\n",
    "            model_time = end_model - start_model\n",
    "            print(\"* Running time of running BG_Flood model:\", \n",
    "                  model_time/60)\n",
    "\n",
    "            # Print separator\n",
    "            print(\"-\"*90)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "13caec1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ angle: 0 and x: 0 and y: 0 ------------------------------\n",
      "gmt grdmath S:\\MULTIPLE_TILES_Monte_Carlo_BGFLOOD\\version_1\\4_BG_Flood\\BG_Flood_output\\combination\\combined_BGoutput\\Output_combined_angle_0_x_0_y_0.nc?h_P0[72] DUP 0 GT MUL = S:\\MULTIPLE_TILES_Monte_Carlo_BGFLOOD\\version_1\\5_flowdepth\\combined_flowdepth\\flowdepth_combined_angle_0_x_0_y_0_at_72.nc\n",
      "* Running time of extracting flowdepth: 0.026252373059590658\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------ angle: 45 and x: 0 and y: 0 ------------------------------\n",
      "gmt grdmath S:\\MULTIPLE_TILES_Monte_Carlo_BGFLOOD\\version_1\\4_BG_Flood\\BG_Flood_output\\combination\\combined_BGoutput\\Output_combined_angle_45_x_0_y_0.nc?h_P0[72] DUP 0 GT MUL = S:\\MULTIPLE_TILES_Monte_Carlo_BGFLOOD\\version_1\\5_flowdepth\\combined_flowdepth\\flowdepth_combined_angle_45_x_0_y_0_at_72.nc\n",
      "* Running time of extracting flowdepth: 0.004171542326609294\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------ angle: 90 and x: 0 and y: 0 ------------------------------\n",
      "gmt grdmath S:\\MULTIPLE_TILES_Monte_Carlo_BGFLOOD\\version_1\\4_BG_Flood\\BG_Flood_output\\combination\\combined_BGoutput\\Output_combined_angle_90_x_0_y_0.nc?h_P0[72] DUP 0 GT MUL = S:\\MULTIPLE_TILES_Monte_Carlo_BGFLOOD\\version_1\\5_flowdepth\\combined_flowdepth\\flowdepth_combined_angle_90_x_0_y_0_at_72.nc\n",
      "* Running time of extracting flowdepth: 0.0049246271451314294\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute flowdepth extraction\n",
    "for angle_value4 in range(angle_start, angle_end+1, angle_interval):\n",
    "    for value_x4 in range(value_start, value_end+1, value_interval):\n",
    "        for value_y4 in range(value_start, value_end+1, value_interval):\n",
    "            # Set the name of each translation\n",
    "            combination_number4 = f\"angle_{angle_value4}_x_{value_x4}_y_{value_y4}\"\n",
    "\n",
    "            # Print the header of the first running\n",
    "            print(\"{0} angle: {1} and x: {2} and y: {3} {0}\".format(\"-\"*30, angle_value4, value_x4, value_y4))\n",
    "    \n",
    "            # Start timing the whole extracting process\n",
    "            start_extracting = time.time()\n",
    "\n",
    "            # Extract flowdepth\n",
    "            flowdepth_extraction(\"c\", combination_number4, flowdepth_rate, time_extract)\n",
    "\n",
    "            # End timing the whole extracting process\n",
    "            end_extracting = time.time()\n",
    "\n",
    "            # Print the running time of the extracting process\n",
    "            extracting_time = end_extracting - start_extracting\n",
    "            print(\"* Running time of extracting flowdepth:\", \n",
    "                  extracting_time/60)\n",
    "\n",
    "            # Print separator\n",
    "            print(\"-\"*90)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8ee07cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rasterio._env:CPLE_AppDefined in Recode from UTF-8 to CP_ACP failed with the error: \"Invalid argument\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ angle: 0 and x: 0 and y: 0 ------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rasterio._env:CPLE_AppDefined in Recode from UTF-8 to CP_ACP failed with the error: \"Invalid argument\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running time of extracting flowdepth: 0.004469041029612223\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------ angle: 45 and x: 0 and y: 0 ------------------------------\n",
      "* Running time of extracting flowdepth: 0.00346837838490804\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------ angle: 90 and x: 0 and y: 0 ------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rasterio._env:CPLE_AppDefined in Recode from UTF-8 to CP_ACP failed with the error: \"Invalid argument\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running time of extracting flowdepth: 0.0035988291104634604\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute adding crs function\n",
    "for angle_value5 in range(angle_start, angle_end+1, angle_interval):\n",
    "    for value_x5 in range(value_start, value_end+1, value_interval):\n",
    "        for value_y5 in range(value_start, value_end+1, value_interval):\n",
    "            # Set the name of each translation\n",
    "            combination_number5 = f\"angle_{angle_value5}_x_{value_x5}_y_{value_y5}\"\n",
    "\n",
    "            # Print the header of the first running\n",
    "            print(\"{0} angle: {1} and x: {2} and y: {3} {0}\".format(\"-\"*30, angle_value5, value_x5, value_y5))\n",
    "    \n",
    "            # Start timing the whole adding crs process\n",
    "            start_crs = time.time()\n",
    "\n",
    "            # Add crs\n",
    "            add_crs(\"c\", combination_number5, time_extract)\n",
    "\n",
    "            # End timing the whole adding crs process\n",
    "            end_crs = time.time()\n",
    "\n",
    "            # Print the running time of the adding crs process\n",
    "            crs_time = end_crs - start_crs\n",
    "            print(\"* Running time of extracting flowdepth:\", \n",
    "                  crs_time/60)\n",
    "\n",
    "            # Print separator\n",
    "            print(\"-\"*90)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "db2f2595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rasterio._env:CPLE_AppDefined in Recode from UTF-8 to CP_ACP failed with the error: \"Invalid argument\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------ angle: 0 and x: 0 and y: 0 ------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rasterio._env:CPLE_AppDefined in Recode from UTF-8 to CP_ACP failed with the error: \"Invalid argument\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running time of unrotation: 0.040973126888275146\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------ angle: 45 and x: 0 and y: 0 ------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rasterio._env:CPLE_AppDefined in Recode from UTF-8 to CP_ACP failed with the error: \"Invalid argument\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running time of unrotation: 0.03582177956899007\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------ angle: 90 and x: 0 and y: 0 ------------------------------\n",
      "* Running time of unrotation: 0.036017970244089766\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute un-rotation\n",
    "for angle_value6 in range(angle_start, angle_end+1, angle_interval):\n",
    "    for value_x6 in range(value_start, value_end+1, value_interval):\n",
    "        for value_y6 in range(value_start, value_end+1, value_interval):\n",
    "            # Set up translation values for x and y coordinates.\n",
    "            # Apply translation values into lidar point cloud array (under meters unit)\n",
    "            x_translation_raster = value_x6 / 10 * (-1)\n",
    "            y_translation_raster = value_y6 / 10\n",
    "\n",
    "            # Set the name of each translation\n",
    "            combination_number6 = f\"angle_{angle_value6}_x_{value_x6}_y_{value_y6}\"\n",
    "\n",
    "            # Print the header of the first running\n",
    "            print(\"{0} angle: {1} and x: {2} and y: {3} {0}\".format(\"-\"*30, angle_value6, value_x6, value_y6))\n",
    "\n",
    "            # Start timing the whole un-combination process\n",
    "            start_uncombination = time.time()\n",
    "\n",
    "            # Un-combination\n",
    "            polygons_uncombination('c', combination_number6, angle_value6, x_translation_raster, y_translation_raster, time_extract)\n",
    "\n",
    "            # End timing the whole un-rotation process\n",
    "            end_uncombination = time.time()            \n",
    "            \n",
    "            # Print the running time of the un-rotation process\n",
    "            unrotation_time = end_uncombination - start_uncombination\n",
    "            print(\"* Running time of unrotation:\", \n",
    "                  unrotation_time/60)\n",
    "\n",
    "            # Print separator\n",
    "            print(\"-\"*90)\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2243ce03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geofabrics39]",
   "language": "python",
   "name": "conda-env-geofabrics39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
